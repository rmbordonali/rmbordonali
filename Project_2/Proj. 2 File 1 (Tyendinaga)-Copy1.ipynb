{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab54a30-cdcf-435f-9c91-6c3488f82d5e",
   "metadata": {},
   "source": [
    "### Tyendinaga Data\n",
    "##### Notes:\n",
    "- data exported from 'Student' computer\n",
    "- using data with filename Tyendinaga1_001.asc as main data source to make plots with\n",
    "- Tyendinaga1_001.asc data was recorded on Oct. 26, 2025 from 18:07:12 to 18:27:12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c5960-c7b8-4338-ba99-e7f5eaa20084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import scipy.stats as ss\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.fft\n",
    "import pywt\n",
    "from scipy.signal.windows import hann\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage import uniform_filter\n",
    "from scipy.signal import ShortTimeFFT\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import hilbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da4c34-e3fa-4255-94d9-7741d34221ef",
   "metadata": {},
   "source": [
    "##### DataFrame --> File Name Legend:\n",
    "- df --> Tyendinaga_001.asc\n",
    "- df2 --> Tyendinaga2_001.asc\n",
    "- df3 --> Tyendinaga3_001.asc\n",
    "- df4 --> Tyendinaga4_001.asc\n",
    "- df5 --> Tyendinaga5_001.asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc908e75-6f77-4263-bf0c-49c927bdd6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename: Tyendinaga1\n",
    "column_names = ['NS', 'EW', 'Z', 'nsL', 'ewL', 'zL', 'aY', 'aX', 'aZ']\n",
    "df = pd.read_table('Tyendinaga1_001.asc', delimiter=r'\\s+', encoding='latin-1', skiprows=32, names=column_names)\n",
    "#df.head().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548547e0-eaea-4453-a806-e32edd8d9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename: Tyendinaga2\n",
    "# Loading the rest of the Tyendinaga files so can make comparitive plots between datasets\n",
    "column_names2 = ['NS', 'EW', 'Z', 'nsL', 'ewL', 'zL', 'aY', 'aX', 'aZ']\n",
    "df2 = pd.read_table('Tyendinaga2_001.asc', delimiter=r'\\s+', encoding='latin-1', skiprows=32, names=column_names2)\n",
    "#df2.head().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbf829-470b-4efe-8d4c-04aaf00d2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename: Tyendinaga3\n",
    "column_names3 = ['NS', 'EW', 'Z', 'nsL', 'ewL', 'zL', 'aY', 'aX', 'aZ']\n",
    "df3 = pd.read_table('Tyendinaga3_001.asc', delimiter=r'\\s+', encoding='latin-1', skiprows=32, names=column_names3)\n",
    "#df3.head().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b472d-7257-47a3-8c00-986e7faa6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename: Tyendinaga4\n",
    "column_names4 = ['NS', 'EW', 'Z', 'nsL', 'ewL', 'zL', 'aY', 'aX', 'aZ']\n",
    "df4 = pd.read_table('Tyendinaga4_001.asc', delimiter=r'\\s+', encoding='latin-1', skiprows=32, names=column_names4)\n",
    "#df4.head().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15e217-4f62-4924-a2cc-2512b93b0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename: Tyendinaga5\n",
    "column_names5 = ['NS', 'EW', 'Z', 'nsL', 'ewL', 'zL', 'aY', 'aX', 'aZ']\n",
    "df5 = pd.read_table('Tyendinaga5_001.asc', delimiter=r'\\s+', encoding='latin-1', skiprows=32, names=column_names5)\n",
    "#df5.head().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1c3f8-dfb6-4ee8-86df-ba1731f08fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_null = df.isnull().any().any()\n",
    "print(any_null) # Will show false if no null values\n",
    "#df.info()\n",
    "print(df2.isnull().any().any())\n",
    "print(df3.isnull().any().any())\n",
    "print(df4.isnull().any().any())\n",
    "print(df5.isnull().any().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79aecd9-3709-4a68-a42b-cdaf3960ae76",
   "metadata": {},
   "source": [
    "##### Columns of Interest:\n",
    "- NS: North-South component of motion\n",
    "- EW: East-West component of motion\n",
    "- Z: Vertical (Z-axis) component of motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1cc36c-a570-4d2e-9bec-6177d479836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.columns)\n",
    "# Want to make a time column:\n",
    "sampling_rate = 1024  # Hz (same for all data files)\n",
    "dataframes = [df, df2, df3, df4, df5]\n",
    "for i, dataframe in enumerate(dataframes):\n",
    "    time = dataframe.index/sampling_rate\n",
    "    dataframe['time (s)'] = time\n",
    "    print(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c4daa-434f-42fb-a5c9-a68af5efbcb9",
   "metadata": {},
   "source": [
    "***\n",
    "### Plotting the Time Series\n",
    "##### Notes:\n",
    "- Plot the NS, EW, and Z data separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72202704-9f75-4244-876a-50861abc8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder: dataframes = [df, df2, df3, df4, df5]\n",
    "for i, dframe in enumerate(dataframes):\n",
    "    if i==0:\n",
    "        print('dataframe: df')\n",
    "    else:\n",
    "        print(f'dataframe: df{i+1}')\n",
    "\n",
    "    # Plot:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
    "    time_minutes = dframe['time (s)']/60\n",
    "    # North-South data:\n",
    "    axes[0].plot(time_minutes, dframe['NS'], label='North-South', color='forestgreen')\n",
    "    axes[0].set_ylabel('North-South Component')\n",
    "    axes[0].set_title('North-South Data')\n",
    "    axes[0].set_xlabel('Time (min)')\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # East-West data:\n",
    "    axes[1].plot(time_minutes, dframe['EW'], label='East-West', color='rebeccapurple')\n",
    "    axes[1].set_ylabel('East-West Component')\n",
    "    axes[1].set_title('East-West Data')\n",
    "    axes[1].set_xlabel('Time (min)')\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Z data:\n",
    "    axes[2].plot(time_minutes, dframe['Z'], label='Z/Vertical Component', color='royalblue')\n",
    "    axes[2].set_ylabel('Z Component')\n",
    "    axes[2].set_title('Z-Component Data')\n",
    "    axes[2].set_xlabel('Time (min)')\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab11572-97c8-48cb-aa40-60d2c19fd0de",
   "metadata": {},
   "source": [
    "***\n",
    "### Normalizing, Detrending and Shifting Data\n",
    "##### Notes:\n",
    "- data range of time series was normalized using MinMaxScaler from sklearn\n",
    "- data was linearly detrended using signal.detrend from scipy\n",
    "- the mean of the data was shifted to approximately zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0da38-7d1c-4e5f-ae72-2f4fc2295153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearly detrend data, normalize and shift to zero mean:\n",
    "# reminder: dataframes = [df, df2, df3, df4, df5]\n",
    "for i, dframe in enumerate(dataframes):\n",
    "    if i==0:\n",
    "        print('dataframe: df')\n",
    "    else:\n",
    "        print(f'dataframe: df{i+1}')\n",
    "        \n",
    "    # Detrend\n",
    "    dframe['NS_Detrended'] = signal.detrend(dframe['NS'], type='linear') # North-South data\n",
    "    dframe['EW_Detrended'] = signal.detrend(dframe['EW'], type='linear') # East-West data\n",
    "    dframe['Z_Detrended'] = signal.detrend(dframe['Z'], type='linear') # Z-component data\n",
    "\n",
    "    # Normalize\n",
    "    scaler = MinMaxScaler()\n",
    "    dframe['NS_Normalized'] = scaler.fit_transform(dframe['NS_Detrended'].values.reshape(-1, 1)).flatten() # North-South\n",
    "    dframe['EW_Normalized'] = scaler.fit_transform(dframe['EW_Detrended'].values.reshape(-1, 1)).flatten() # East-West\n",
    "    dframe['Z_Normalized'] = scaler.fit_transform(dframe['Z_Detrended'].values.reshape(-1, 1)).flatten() # Z-component\n",
    "    print(f\"NS Min-Max normalized range: [{dframe['NS_Normalized'].min():.3f}, {dframe['NS_Normalized'].max():.3f}]\")\n",
    "    print(f\"EW Min-Max normalized range: [{dframe['EW_Normalized'].min():.3f}, {dframe['EW_Normalized'].max():.3f}]\")\n",
    "    print(f\"Z Min-Max normalized range: [{dframe['Z_Normalized'].min():.3f}, {dframe['Z_Normalized'].max():.3f}]\")\n",
    "\n",
    "    # Shift Mean:\n",
    "    dframe['NS_Normalized_Shifted'] = (dframe['NS_Normalized'] - 0.5)\n",
    "    dframe['EW_Normalized_Shifted'] = (dframe['EW_Normalized'] - 0.5)\n",
    "    dframe['Z_Normalized_Shifted'] = (dframe['Z_Normalized'] - 0.5)\n",
    "    print(f\"New range for NS: [{dframe['NS_Normalized_Shifted'].min():.3f}, {dframe['NS_Normalized_Shifted'].max():.3f}]\")\n",
    "    print(f\"New mean for NS: {dframe['NS_Normalized_Shifted'].mean():.6f}\")\n",
    "    print(f\"New range for EW: [{dframe['EW_Normalized_Shifted'].min():.3f}, {dframe['EW_Normalized_Shifted'].max():.3f}]\")\n",
    "    print(f\"New mean for EW: {dframe['EW_Normalized_Shifted'].mean():.6f}\")\n",
    "    print(f\"New range for Z: [{dframe['Z_Normalized_Shifted'].min():.3f}, {dframe['Z_Normalized_Shifted'].max():.3f}]\")\n",
    "    print(f\"New mean for Z: {dframe['Z_Normalized_Shifted'].mean():.6f}\")\n",
    "\n",
    "    # Plot:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
    "    time_minutes = dframe['time (s)']/60\n",
    "    # North-South data:\n",
    "    axes[0].plot(time_minutes, dframe['NS_Normalized_Shifted'], label='North-South', color='forestgreen')\n",
    "    axes[0].set_ylabel('North-South Component')\n",
    "    axes[0].set_title('DNS North-South Data')\n",
    "    axes[0].set_xlabel('Time (min)')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # East-West data:\n",
    "    axes[1].plot(time_minutes, dframe['EW_Normalized_Shifted'], label='East-West', color='rebeccapurple')\n",
    "    axes[1].set_ylabel('East-West Component')\n",
    "    axes[1].set_title('DNS East-West Data')\n",
    "    axes[1].set_xlabel('Time (min)')\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Z data:\n",
    "    axes[2].plot(time_minutes, dframe['Z_Normalized_Shifted'], label='Z/Vertical Component', color='royalblue')\n",
    "    axes[2].set_ylabel('Z Component')\n",
    "    axes[2].set_title('DNS Z-Component Data')\n",
    "    axes[2].set_xlabel('Time (min)')\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"DNS = Detrended, Normalized, Shifted\")\n",
    "    print(\"\")\n",
    "    # Stats for plots\n",
    "    print(\"North-South Stats:\")\n",
    "    print(ss.describe(dframe['NS_Normalized_Shifted']))\n",
    "    print(\"median:\", dframe[\"NS_Normalized_Shifted\"].median())\n",
    "    print(\"mode:\", ss.mode(df[\"NS_Normalized_Shifted\"])) \n",
    "    print(\"standard deviation:\", dframe[\"NS_Normalized_Shifted\"].std())\n",
    "    print(\"\")\n",
    "    print(\"East-West Stats:\")\n",
    "    print(ss.describe(dframe['EW_Normalized_Shifted']))\n",
    "    print(\"median:\", dframe[\"EW_Normalized_Shifted\"].median())\n",
    "    print(\"mode:\", ss.mode(dframe[\"EW_Normalized_Shifted\"])) \n",
    "    print(\"standard deviation:\", dframe[\"EW_Normalized_Shifted\"].std())\n",
    "    print(\"\")\n",
    "    print(\"Z-component Stats:\")\n",
    "    print(ss.describe(dframe['Z_Normalized_Shifted']))\n",
    "    print(\"median:\", dframe[\"Z_Normalized_Shifted\"].median())\n",
    "    print(\"mode:\", ss.mode(dframe[\"Z_Normalized_Shifted\"])) \n",
    "    print(\"standard deviation:\", dframe[\"Z_Normalized_Shifted\"].std())\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29531b-aa23-4010-9768-cc22096142e7",
   "metadata": {},
   "source": [
    "***\n",
    "### Subsampling the Time Series\n",
    "##### Notes:\n",
    "- the original sampling rate for the data is 1024 Hz\n",
    "- different step sizes were applied to the normalized, detrended and mean-shifted (DNS) data for subsampling\n",
    "- comment out certain series before plotting to focus on a specific step value\n",
    "- adjust x-axis limits to zoom in on certain times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ffdc5f-6fe9-4988-884f-ca0b3fba4576",
   "metadata": {},
   "source": [
    "#### \"percent_check\" Function for Choosing Subsampling Step Size:\n",
    "##### Notes:\n",
    "- this method uses interpolation to compare subsampled data to the full DNS data\n",
    "- the absolute error between the full DNS data and the reconstructed subsampled data is calculated and divided by the full data range\n",
    "- this result is then used determine if the error is within the selected threshold (i.e. 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904cc0c1-b70c-41bf-9228-239e60cd40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First use percent_check function to choose step-size (i.e. decimation_factor) to use for subsample function\n",
    "def percent_check(data, column, step, tolerance=0.05):\n",
    "    \"\"\"Determine if error for subsampled data is within 5% tolerance compared to full DNS data range\n",
    "    data: dataframe to use\n",
    "    column: column of interest for y values\n",
    "    step: data step to use for subsampling\n",
    "    tolerance: error tolerance expressed as a decimal\"\"\"\n",
    "    # Get original series\n",
    "    x_original = np.arange(len(data))\n",
    "    y_original = data[column].values\n",
    "    \n",
    "    # Get subsampled series\n",
    "    x_subsampled = np.arange(0, len(data), step)\n",
    "    y_subsampled = data[column].iloc[::step].values\n",
    "    \n",
    "    # Interpolate subsampled data back to original timestamps\n",
    "    f_interp = interpolate.interp1d(x_subsampled, y_subsampled, kind='linear', fill_value='extrapolate')\n",
    "    y_reconstructed = f_interp(x_original)\n",
    "    \n",
    "    # Calculate absolute errors\n",
    "    abs_errors = np.abs(y_original - y_reconstructed)\n",
    "    \n",
    "    # Calculate data range (the scale of the data)\n",
    "    data_range = np.max(y_original) - np.min(y_original)\n",
    "    #print(\"data_range:\", data_range)\n",
    "    # Normalize errors by data range instead of individual values\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    # Test if within tolerance\n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance)) * 100\n",
    "    \n",
    "    # Overall pass/fail\n",
    "    passes = pct_within >= 95  # At least 95% of points within tolerance\n",
    "    \n",
    "    results = {'step': step,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes': passes,\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'num_original_points': len(y_original),\n",
    "        'num_subsampled_points': len(y_subsampled),\n",
    "        'data_range': f'{data_range: .4f}',  \n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%' }\n",
    "    \n",
    "    return results\n",
    "# step_1 = 12\n",
    "# Results for df:\n",
    "NS_results_step_1 = percent_check(df, 'NS_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"NS results 1 (df):\", NS_results_step_1)\n",
    "EW_results_step_1 = percent_check(df, 'EW_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"EW results 1 (df):\", EW_results_step_1)\n",
    "Z_results_step_1 = percent_check(df, 'Z_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"Z results 1 (df):\", Z_results_step_1)\n",
    "print(\"\")\n",
    "# Results for df2:\n",
    "NS_results_step_1_df2 = percent_check(df2, 'NS_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"NS results 1 (df2):\", NS_results_step_1_df2)\n",
    "EW_results_step_1_df2 = percent_check(df2, 'EW_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"EW results 1 (df2):\", EW_results_step_1_df2)\n",
    "Z_results_step_1_df2 = percent_check(df2, 'Z_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"Z results 1 (df2):\", Z_results_step_1_df2)\n",
    "print(\"\")\n",
    "# Results for df3:\n",
    "NS_results_step_1_df3 = percent_check(df3, 'NS_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"NS results 1 (df3):\", NS_results_step_1_df3)\n",
    "EW_results_step_1_df3 = percent_check(df3, 'EW_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"EW results 1 (df3):\", EW_results_step_1_df3)\n",
    "Z_results_step_1_df3 = percent_check(df3, 'Z_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"Z results 1 (df3):\", Z_results_step_1_df3)\n",
    "print(\"\")\n",
    "# Results for df4:\n",
    "NS_results_step_1_df4 = percent_check(df4, 'NS_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"NS results 1 (df4):\", NS_results_step_1_df4)\n",
    "EW_results_step_1_df4 = percent_check(df4, 'EW_Normalized_Shifted', 7, tolerance=0.05) # passes with stepsizeof 10 but not 12\n",
    "print(\"EW results 1 (df4):\", EW_results_step_1_df4)\n",
    "Z_results_step_1_df4 = percent_check(df4, 'Z_Normalized_Shifted', 7, tolerance=0.05) # Z passes check with stepsize of 12 but not 10\n",
    "print(\"Z results 1 (df4):\", Z_results_step_1_df4)\n",
    "print(\"\")\n",
    "# Results for df5:\n",
    "NS_results_step_1_df5 = percent_check(df5, 'NS_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"NS results 1 (df5):\", NS_results_step_1_df5)\n",
    "EW_results_step_1_df5 = percent_check(df5, 'EW_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"EW results 1 (df5):\", EW_results_step_1_df5)\n",
    "Z_results_step_1_df5 = percent_check(df5, 'Z_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"Z results 1 (df5):\", Z_results_step_1_df5)\n",
    "print(\"\")\n",
    "# Note: 7 is the largest stepsize that passes the tolerance check everywhere (i.e. for all dataframes), simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f2038b-d384-476a-bcbe-bede23daf9e9",
   "metadata": {},
   "source": [
    "#### percent_check results:\n",
    "- The Z data consistently had the lowest amount of points within the error tolerance compared to NS and EW data\n",
    "- A step size of 7 was the largest that passed the percent_check test for NS, EW, and Z data simultaneously for all dataframes (plotted below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a0c56d-67e2-4055-8a81-79f49e7cb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting time series using percent_check step sizes to compare to full DNS plots\n",
    "for i, dframe in enumerate(dataframes):\n",
    "    if i==0:\n",
    "        print('dataframe: df')\n",
    "    else:\n",
    "        print(f'dataframe: df{i+1}')\n",
    "    # Plot:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
    "    time_minutes = dframe['time (s)']/60\n",
    "    # North-South data:\n",
    "    axes[0].plot(time_minutes, dframe['NS_Normalized_Shifted'], label='North-South (Full)', color='red')\n",
    "    axes[0].plot(time_minutes[::7], dframe['NS_Normalized_Shifted'][::7], label='North-South (Step=7)', color='forestgreen')\n",
    "    axes[0].set_ylabel('North-South Component')\n",
    "    axes[0].set_title('Subsampled and Full DNS North-South Data')\n",
    "    axes[0].set_xlabel('Time (min)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # East-West data:\n",
    "    axes[1].plot(time_minutes, dframe['EW_Normalized_Shifted'], label='East-West (Full)', color='red')\n",
    "    axes[1].plot(time_minutes[::7], dframe['EW_Normalized_Shifted'][::7], label='East-West (Step=7)', color='rebeccapurple')\n",
    "    axes[1].set_ylabel('East-West Component')\n",
    "    axes[1].set_title('Subsampled and Full DNS East-West Data')\n",
    "    axes[1].set_xlabel('Time (min)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Z data:\n",
    "    axes[2].plot(time_minutes, dframe['Z_Normalized_Shifted'], label='Z (Full)', color='red')\n",
    "    axes[2].plot(time_minutes[::7], dframe['Z_Normalized_Shifted'][::7], label='Z (Step=7)', color='royalblue')\n",
    "    axes[2].set_ylabel('Z Component')\n",
    "    axes[2].set_title('Subsampled and Full DNS Z-Component Data')\n",
    "    axes[2].set_xlabel('Time (min)')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abeabeb-81f7-4a00-b92b-a33e62a5f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using scipy.signal.decimate and compare to indexing results\n",
    "original_sampling_rate = 1024 # Hz\n",
    "def subsample(data, decimation_factor, sr):\n",
    "    \"\"\"Subsample data using scipy.signal.decimate with anti-aliasing filter.\n",
    "    data: input data (array)\n",
    "    decimation_factor: factor by which to reduce sampling rate\n",
    "    sr: Original sampling rate\"\"\"\n",
    "    # scipy.signal.decimate applies an anti-aliasing filter automatically\n",
    "    # Use a higher order filter for better anti-aliasing (default is 8)\n",
    "    decimated_data = scipy.signal.decimate(data, decimation_factor, ftype='iir', zero_phase=True)  \n",
    "    # get new sampling rate:\n",
    "    new_sr = sr / decimation_factor\n",
    "    #print(f\"New sampling rate: {new_sr} Hz\")\n",
    "    return decimated_data, new_sr\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Compute results for NS, EW, and Z data:\n",
    "# (Using stepsize of 7 for decimation_factor)\n",
    "# df:\n",
    "NS_sub_results_df, NS_new_sr_df = subsample(df['NS_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "EW_sub_results_df, EW_new_sr_df = subsample(df['EW_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "Z_sub_results_df, Z_new_sr_df = subsample(df['Z_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "#df2:\n",
    "NS_sub_results_df2, NS_new_sr_df2 = subsample(df2['NS_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "EW_sub_results_df2, EW_new_sr_df2 = subsample(df2['EW_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "Z_sub_results_df2, Z_new_sr_df2 = subsample(df2['Z_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "#df3:\n",
    "NS_sub_results_df3, NS_new_sr_df3 = subsample(df3['NS_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "EW_sub_results_df3, EW_new_sr_df3 = subsample(df3['EW_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "Z_sub_results_df3, Z_new_sr_df3 = subsample(df3['Z_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "#df4:\n",
    "NS_sub_results_df4, NS_new_sr_df4 = subsample(df4['NS_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "EW_sub_results_df4, EW_new_sr_df4 = subsample(df4['EW_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "Z_sub_results_df4, Z_new_sr_df4 = subsample(df4['Z_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "#df5:\n",
    "NS_sub_results_df5, NS_new_sr_df5 = subsample(df5['NS_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "EW_sub_results_df5, EW_new_sr_df5 = subsample(df5['EW_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "Z_sub_results_df5, Z_new_sr_df5 = subsample(df5['Z_Normalized_Shifted'].values, 7, original_sampling_rate)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "NS_subsampled_data = [NS_sub_results_df, NS_sub_results_df2, NS_sub_results_df3, NS_sub_results_df4, NS_sub_results_df5]\n",
    "EW_subsampled_data = [EW_sub_results_df, EW_sub_results_df2, EW_sub_results_df3, EW_sub_results_df4, EW_sub_results_df5]\n",
    "Z_subsampled_data = [Z_sub_results_df, Z_sub_results_df2, Z_sub_results_df3, Z_sub_results_df4, Z_sub_results_df5]\n",
    "\n",
    "for i, dframe in enumerate(dataframes):\n",
    "    # Plot:\n",
    "    time_minutes = dframe['time (s)']/60\n",
    "    # North-South data:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(time_minutes, dframe['NS_Normalized_Shifted'], label='North-South (Full)', color='red')\n",
    "    plt.plot(time_minutes[::7], NS_subsampled_data[i], label='North-South (Step=7)', color='forestgreen')\n",
    "    plt.ylabel('North-South Component')\n",
    "    plt.title('Subsampled and Full DNS North-South Data')\n",
    "    plt.xlabel('Time (min)')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # East-West data:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(time_minutes, dframe['EW_Normalized_Shifted'], label='East-West (Full)', color='red')\n",
    "    plt.plot(time_minutes[::7], EW_subsampled_data[i], label='East-West (Step=7)', color='rebeccapurple')\n",
    "    plt.ylabel('East-West Component')\n",
    "    plt.title('Subsampled and Full DNS East-West Data')\n",
    "    plt.xlabel('Time (min)')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Z data:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(time_minutes, dframe['Z_Normalized_Shifted'], label='Z (Full)', color='red')\n",
    "    plt.plot(time_minutes[::7], Z_subsampled_data[i], label='Z (Step=7)', color='royalblue')\n",
    "    plt.ylabel('Z Component')\n",
    "    plt.title('Subsampled and Full DNS Z-Component Data')\n",
    "    plt.xlabel('Time (min)')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Note: New sampling rate is 146.285714... Hz using decimation_factor of 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ca59d-6156-4e48-a3ae-e482404bfd23",
   "metadata": {},
   "source": [
    "#### percent_check function using scipy.signal.decimate for y_subsampled instead of indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a3b0b-f958-4ca1-9c4c-133b0dd13809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use percent_check for scipy decimate version of subsampling\n",
    "def percent_check_scipy_decimate(data, column, step, tolerance=0.05):\n",
    "    x_original = np.arange(len(data))\n",
    "    y_original = data[column].values\n",
    "    \n",
    "    # Get subsampled series\n",
    "    x_subsampled = np.arange(0, len(data), step)\n",
    "    y_subsampled=scipy.signal.decimate(data[column].values, step, ftype='iir', zero_phase=True)\n",
    "    \n",
    "    # Interpolate subsampled data back to original timestamps\n",
    "    f_interp = interpolate.interp1d(x_subsampled, y_subsampled, kind='linear', fill_value='extrapolate')\n",
    "    y_reconstructed = f_interp(x_original)\n",
    "    \n",
    "    # Calculate absolute errors\n",
    "    abs_errors = np.abs(y_original - y_reconstructed)\n",
    "    \n",
    "    # Calculate data range (the scale of the data)\n",
    "    data_range = np.max(y_original) - np.min(y_original)\n",
    "    #print(\"data_range:\", data_range)\n",
    "    # Normalize errors by data range instead of individual values\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    # Test if within tolerance\n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance)) * 100\n",
    "    \n",
    "    # Overall pass/fail\n",
    "    passes = pct_within >= 95  # At least 95% of points within tolerance\n",
    "    \n",
    "    results = {'step': step,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes': passes,\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'num_original_points': len(y_original),\n",
    "        'num_subsampled_points': len(y_subsampled),\n",
    "        'data_range': f'{data_range: .4f}',  \n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%' }\n",
    "    return results\n",
    "\n",
    "# results for df:\n",
    "NS_results_test_1_df = percent_check_scipy_decimate(df, 'NS_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"NS_results_test_1 (df):\", NS_results_test_1_df)\n",
    "EW_results_test_1_df = percent_check_scipy_decimate(df, 'EW_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"EW_results_test_1 (df):\", EW_results_test_1_df)\n",
    "Z_results_test_1_df = percent_check_scipy_decimate(df, 'Z_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"Z_results_test_1 (df):\", Z_results_test_1_df)\n",
    "print(\"\")\n",
    "# results for df2:\n",
    "NS_results_test_1_df2 = percent_check_scipy_decimate(df2, 'NS_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"NS_results_test_1 (df2):\", NS_results_test_1_df2)\n",
    "EW_results_test_1_df2 = percent_check_scipy_decimate(df2, 'EW_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"EW_results_test_1 (df2):\", EW_results_test_1_df2)\n",
    "Z_results_test_1_df2 = percent_check_scipy_decimate(df2, 'Z_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"Z_results_test_1 (df2):\", Z_results_test_1_df2)\n",
    "print(\"\")\n",
    "# results for df3:\n",
    "NS_results_test_1_df3 = percent_check_scipy_decimate(df3, 'NS_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"NS_results_test_1 (df3):\", NS_results_test_1_df3)\n",
    "EW_results_test_1_df3 = percent_check_scipy_decimate(df3, 'EW_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"EW_results_test_1 (df3):\", EW_results_test_1_df3)\n",
    "Z_results_test_1_df3 = percent_check_scipy_decimate(df3, 'Z_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"Z_results_test_1 (df3):\", Z_results_test_1_df3)\n",
    "print(\"\")\n",
    "# results for df4:\n",
    "NS_results_test_1_df4 = percent_check_scipy_decimate(df4, 'NS_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"NS_results_test_1 (df4):\", NS_results_test_1_df4)\n",
    "EW_results_test_1_df4 = percent_check_scipy_decimate(df4, 'EW_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"EW_results_test_1 (df4):\", EW_results_test_1_df4)\n",
    "Z_results_test_1_df4 = percent_check_scipy_decimate(df4, 'Z_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"Z_results_test_1 (df4):\", Z_results_test_1_df4)\n",
    "print(\"\")\n",
    "# results for df5:\n",
    "NS_results_test_1_df5 = percent_check_scipy_decimate(df5, 'NS_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"NS_results_test_1 (df5):\", NS_results_test_1_df5)\n",
    "EW_results_test_1_df5 = percent_check_scipy_decimate(df5, 'EW_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"EW_results_test_1 (df5):\", EW_results_test_1_df5)\n",
    "Z_results_test_1_df5 = percent_check_scipy_decimate(df5, 'Z_Normalized_Shifted', 7, tolerance=0.05)\n",
    "print(\"Z_results_test_1 (df5):\", Z_results_test_1_df5)\n",
    "print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92dc7f01-ef08-49e2-b383-5f5edcec5acb",
   "metadata": {},
   "source": [
    "#### Comparing percent_check results from scipy.signal.decimate and indexing for y_subsampled\n",
    "- Using ftype='fir' instead of 'iir' for the scipy method yields more points within the error tolerance and overall lower max_normalized_error values (tested with df)\n",
    "    - The 'fir' filter type also applies a Hamming window\n",
    "- There were a similar percentage of points within the error tolerance when using the scipy.signal.decimate method compared to the indexing method for subsampling\n",
    "- For later cells, the scipy.signal.decimate method will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdea4f-9ff0-431e-bc67-6b8b3eed6afa",
   "metadata": {},
   "source": [
    "***\n",
    "### Tapering the Time Series\n",
    "##### Notes:\n",
    "- a Hann window/raised cosine was used to taper the DNS time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d8297-141b-4f2a-9f4c-3d1e903bb47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder (defined in previous cell): dataframes = [df, df2, df3, df4, df5]\n",
    "def apply_hann_window(data, NS_column, EW_column, Z_column):\n",
    "    # Want to apply Hann window and return windowed data with coherent gain factor\n",
    "    window = np.hanning(len(data))\n",
    "    NS_windowed_data = data[NS_column] * window\n",
    "    EW_windowed_data = data[EW_column] * window\n",
    "    Z_windowed_data = data[Z_column] * window\n",
    "    # Coherent gain for Hann window is 0.5, so need to multiply by 2 later to make correction\n",
    "    coherent_gain = 0.5\n",
    "    #print(\"Coherent gain:\", coherent_gain)\n",
    "    return NS_windowed_data, EW_windowed_data, Z_windowed_data\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# df:\n",
    "NS_hann_result_df, EW_hann_result_df, Z_hann_result_df = apply_hann_window(df, 'NS_Normalized_Shifted', 'EW_Normalized_Shifted', 'Z_Normalized_Shifted')\n",
    "# df2:\n",
    "NS_hann_result_df2, EW_hann_result_df2, Z_hann_result_df2 = apply_hann_window(df2, 'NS_Normalized_Shifted', 'EW_Normalized_Shifted', 'Z_Normalized_Shifted')\n",
    "# df3:\n",
    "NS_hann_result_df3, EW_hann_result_df3, Z_hann_result_df3 = apply_hann_window(df3, 'NS_Normalized_Shifted', 'EW_Normalized_Shifted', 'Z_Normalized_Shifted')\n",
    "# df4:\n",
    "NS_hann_result_df4, EW_hann_result_df4, Z_hann_result_df4 = apply_hann_window(df4, 'NS_Normalized_Shifted', 'EW_Normalized_Shifted', 'Z_Normalized_Shifted')\n",
    "# df5:\n",
    "NS_hann_result_df5, EW_hann_result_df5, Z_hann_result_df5 = apply_hann_window(df5, 'NS_Normalized_Shifted', 'EW_Normalized_Shifted', 'Z_Normalized_Shifted')\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "NS_hann_results = [NS_hann_result_df, NS_hann_result_df2, NS_hann_result_df3, NS_hann_result_df4, NS_hann_result_df5]\n",
    "EW_hann_results = [EW_hann_result_df, EW_hann_result_df2, EW_hann_result_df3, EW_hann_result_df4, EW_hann_result_df5]\n",
    "Z_hann_results = [Z_hann_result_df, Z_hann_result_df2, Z_hann_result_df3, Z_hann_result_df4, Z_hann_result_df5]\n",
    "\n",
    "# Plot tapered data with full data for all dataframes:\n",
    "for i, dframe in enumerate(dataframes):\n",
    "    if i == 0:\n",
    "        print(\"dataframe: df\")\n",
    "    else:\n",
    "        print(f\"dataframe: df{i+1}\")\n",
    "    # Plot:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
    "    time_minutes = dframe['time (s)']/60\n",
    "    # North-South data:\n",
    "    axes[0].plot(time_minutes, dframe['NS_Normalized_Shifted'], label='North-South (Full)', color='red')\n",
    "    axes[0].plot(time_minutes, NS_hann_results[i], label='North-South (Tapered)', color='forestgreen')\n",
    "    axes[0].set_ylabel('North-South Component')\n",
    "    axes[0].set_title('Tapered and Full DNS North-South Data')\n",
    "    axes[0].set_xlabel('Time (min)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # East-West data:\n",
    "    axes[1].plot(time_minutes, dframe['EW_Normalized_Shifted'], label='East-West (Full)', color='red')\n",
    "    axes[1].plot(time_minutes, EW_hann_results[i], label='East-West (Tapered)', color='rebeccapurple')\n",
    "    axes[1].set_ylabel('East-West Component')\n",
    "    axes[1].set_title('Tapered and Full DNS East-West Data')\n",
    "    axes[1].set_xlabel('Time (min)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Z data:\n",
    "    axes[2].plot(time_minutes, dframe['Z_Normalized_Shifted'], label='Z (Full)', color='red')\n",
    "    axes[2].plot(time_minutes, Z_hann_results[i], label='Z (Tapered)', color='royalblue')\n",
    "    axes[2].set_ylabel('Z Component')\n",
    "    axes[2].set_title('Tapered and Full DNS Z-Component Data')\n",
    "    axes[2].set_xlabel('Time (min)')\n",
    "    axes[2].legend()\n",
    "    #axes[2].set_xlim(-0.001,0.01)\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1099f-3ce2-4697-a5af-823ec6ecadb2",
   "metadata": {},
   "source": [
    "#### 'percent_check_tapered' for tapered time series:\n",
    "- a tapering version of the 'percent_check' function that was used for subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e08a86-81f0-46dd-99aa-20c38df407be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_check_tapered(original_data, tapered_data_full, padding, tolerance=0.05):\n",
    "    \"\"\"original_data : Original unpadded time series (array)\n",
    "    tapered_data_full : Tapered time series, includes padding (array)\n",
    "    padding : Amount of padding added to each end (int)\n",
    "    tolerance : Acceptable error as fraction of data range (float)\"\"\"\n",
    "    # Extract original from tapered data (remove padding)\n",
    "    if padding > 0:\n",
    "        tapered_original_region = tapered_data_full[padding:-padding]\n",
    "    else:\n",
    "        tapered_original_region = tapered_data_full\n",
    "    \n",
    "    # Direct comparison: tapered vs original\n",
    "    abs_errors = np.abs(original_data - tapered_original_region)\n",
    "    # normalization\n",
    "    data_range = np.max(original_data) - np.min(original_data)\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    # Calculate metrics\n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance))*100\n",
    "    \n",
    "    # Mean Absolute Error (MAE) metrics\n",
    "    mae = np.mean(abs_errors)\n",
    "    std_original = np.std(original_data)\n",
    "    mae_pct_std = (mae / std_original)*100\n",
    "    \n",
    "    passes = pct_within >= 95\n",
    "    \n",
    "    results = {\n",
    "        'padding': padding,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes': passes,\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%',\n",
    "        'mean_abs_error': f'{mae: .4f}',\n",
    "        'mae_as_%_of_std': f'{mae_pct_std: .4f}%',\n",
    "        'num_points': len(original_data),\n",
    "        'data_range': f'{data_range: .4f}'}\n",
    "    \n",
    "    return results\n",
    "# df:\n",
    "NS_taper_results_1_df = percent_check_tapered(df['NS_Normalized_Shifted'], NS_hann_result_df, padding=0, tolerance=0.05)\n",
    "print(\"NS_taper_results_1 (df):\", NS_taper_results_1_df)\n",
    "EW_taper_results_1_df = percent_check_tapered(df['EW_Normalized_Shifted'], EW_hann_result_df, padding=0, tolerance=0.05)\n",
    "print(\"EW_taper_results_1 (df):\", EW_taper_results_1_df)\n",
    "Z_taper_results_1_df = percent_check_tapered(df['Z_Normalized_Shifted'], Z_hann_result_df, padding=0, tolerance=0.05)\n",
    "print(\"Z_taper_results_1 (df):\", Z_taper_results_1_df)\n",
    "print(\"\")\n",
    "# df2:\n",
    "NS_taper_results_1_df2 = percent_check_tapered(df2['NS_Normalized_Shifted'], NS_hann_result_df2, padding=0, tolerance=0.05)\n",
    "print(\"NS_taper_results_1 (df2):\", NS_taper_results_1_df2)\n",
    "EW_taper_results_1_df2 = percent_check_tapered(df2['EW_Normalized_Shifted'], EW_hann_result_df2, padding=0, tolerance=0.05)\n",
    "print(\"EW_taper_results_1 (df2):\", EW_taper_results_1_df2)\n",
    "Z_taper_results_1_df2 = percent_check_tapered(df2['Z_Normalized_Shifted'], Z_hann_result_df2, padding=0, tolerance=0.05)\n",
    "print(\"Z_taper_results_1 (df2):\", Z_taper_results_1_df2)\n",
    "print(\"\")\n",
    "# df3:\n",
    "NS_taper_results_1_df3 = percent_check_tapered(df3['NS_Normalized_Shifted'], NS_hann_result_df3, padding=0, tolerance=0.05)\n",
    "print(\"NS_taper_results_1 (df3):\", NS_taper_results_1_df3)\n",
    "EW_taper_results_1_df3 = percent_check_tapered(df3['EW_Normalized_Shifted'], EW_hann_result_df3, padding=0, tolerance=0.05)\n",
    "print(\"EW_taper_results_1 (df3):\", EW_taper_results_1_df3)\n",
    "Z_taper_results_1_df3 = percent_check_tapered(df3['Z_Normalized_Shifted'], Z_hann_result_df3, padding=0, tolerance=0.05)\n",
    "print(\"Z_taper_results_1 (df3):\", Z_taper_results_1_df3)\n",
    "print(\"\")\n",
    "# df4:\n",
    "NS_taper_results_1_df4 = percent_check_tapered(df4['NS_Normalized_Shifted'], NS_hann_result_df4, padding=0, tolerance=0.05)\n",
    "print(\"NS_taper_results_1 (df4):\", NS_taper_results_1_df4)\n",
    "EW_taper_results_1_df4 = percent_check_tapered(df4['EW_Normalized_Shifted'], EW_hann_result_df4, padding=0, tolerance=0.05)\n",
    "print(\"EW_taper_results_1 (df4):\", EW_taper_results_1_df4)\n",
    "Z_taper_results_1_df4 = percent_check_tapered(df4['Z_Normalized_Shifted'], Z_hann_result_df4, padding=0, tolerance=0.05)\n",
    "print(\"Z_taper_results_1 (df4):\", Z_taper_results_1_df4)\n",
    "print(\"\")\n",
    "# df5:\n",
    "NS_taper_results_1_df5 = percent_check_tapered(df5['NS_Normalized_Shifted'], NS_hann_result_df5, padding=0, tolerance=0.05)\n",
    "print(\"NS_taper_results_1 (df5):\", NS_taper_results_1_df5)\n",
    "EW_taper_results_1_df5 = percent_check_tapered(df5['EW_Normalized_Shifted'], EW_hann_result_df5, padding=0, tolerance=0.05)\n",
    "print(\"EW_taper_results_1 (df5):\", EW_taper_results_1_df5)\n",
    "Z_taper_results_1_df5 = percent_check_tapered(df5['Z_Normalized_Shifted'], Z_hann_result_df5, padding=0, tolerance=0.05)\n",
    "print(\"Z_taper_results_1 (df5):\", Z_taper_results_1_df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d905306-b579-45c7-b3c3-0fff8cd07e3d",
   "metadata": {},
   "source": [
    "#### 'percent_check_tapered' results:\n",
    "- The North-South and East-West data passed the percent_check_tapered test with roughly 99% of points within the 5% error tolerance (for df)\n",
    "    - However, the Up-Down/Z component data has significantly less points within the error tolerance, with approx. 78% of points within the 5% error tolerance (df)\n",
    "    - df3 also had significantly less points within the error tolerence for the Z direction, with only around 58% of points within the 5% tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf06d4b-4056-48e5-b32e-7b41e9332d3d",
   "metadata": {},
   "source": [
    "***\n",
    "### Combining Subsampling and Tapering\n",
    "##### Notes:\n",
    "- The full series was tapered before subsampling\n",
    "- A Hann window was used for tapering\n",
    "- A step size of 7 was used for subsampling to be consistent across the North-South, East-West, and Up-Down (Z) data\n",
    "    - step=7 was the largest step size thst passed the percent_check test for all three data components in all dataframes simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91e5b5-ae74-4fee-b089-04bc7427f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put tapered results into subsample function from a previous cell:\n",
    "def subsample_windowed(NS_windowed, EW_windowed, Z_windowed, sr=1024, decimation_factor=7):\n",
    "    NS_decimated_data = scipy.signal.decimate(NS_windowed, decimation_factor, ftype='iir', zero_phase=True)\n",
    "    EW_decimated_data = scipy.signal.decimate(EW_windowed, decimation_factor, ftype='iir', zero_phase=True)\n",
    "    Z_decimated_data = scipy.signal.decimate(Z_windowed, decimation_factor, ftype='iir', zero_phase=True)\n",
    "    new_sr = sr/decimation_factor\n",
    "    return NS_decimated_data, EW_decimated_data, Z_decimated_data, new_sr\n",
    "# Results for all dataframes:  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# df:\n",
    "NS_decimated_data_df, EW_decimated_data_df, Z_decimated_data_df, new_sr_df = subsample_windowed(NS_hann_result_df, EW_hann_result_df, Z_hann_result_df)\n",
    "# df2:\n",
    "NS_decimated_data_df2, EW_decimated_data_df2, Z_decimated_data_df2, new_sr_df2 = subsample_windowed(NS_hann_result_df2, EW_hann_result_df2, Z_hann_result_df2)\n",
    "# df3:\n",
    "NS_decimated_data_df3, EW_decimated_data_df3, Z_decimated_data_df3, new_sr_df3 = subsample_windowed(NS_hann_result_df3, EW_hann_result_df3, Z_hann_result_df3)\n",
    "# df4:\n",
    "NS_decimated_data_df4, EW_decimated_data_df4, Z_decimated_data_df4, new_sr_df4 = subsample_windowed(NS_hann_result_df4, EW_hann_result_df4, Z_hann_result_df4)\n",
    "# df5:\n",
    "NS_decimated_data_df5, EW_decimated_data_df5, Z_decimated_data_df5, new_sr_df5 = subsample_windowed(NS_hann_result_df5, EW_hann_result_df5, Z_hann_result_df5)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "NS_taper_sub = [NS_decimated_data_df, NS_decimated_data_df2, NS_decimated_data_df3, NS_decimated_data_df4, NS_decimated_data_df5]\n",
    "EW_taper_sub = [EW_decimated_data_df, EW_decimated_data_df2, EW_decimated_data_df3, EW_decimated_data_df4, EW_decimated_data_df5]\n",
    "Z_taper_sub = [Z_decimated_data_df, Z_decimated_data_df2, Z_decimated_data_df3, Z_decimated_data_df4, Z_decimated_data_df5]\n",
    "\n",
    "for i, dframe in enumerate(dataframes):\n",
    "    if i ==0:\n",
    "        print(\"dataframe: df\")\n",
    "    else:\n",
    "        print(f\"dataframe: df{i+1}\")\n",
    "    # Plot:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 12))\n",
    "    time_minutes = dframe['time (s)']/60\n",
    "    # North-South data:\n",
    "    axes[0].plot(time_minutes, dframe['NS_Normalized_Shifted'], label='North-South (Full)', color='red')\n",
    "    axes[0].plot(time_minutes[::7], NS_taper_sub[i], label='Tapered North-South (Step=7)', color='forestgreen') # make sure step for time_minutes=decimation_factor\n",
    "    axes[0].set_ylabel('North-South Component')\n",
    "    axes[0].set_title('Tapered/Subsampled and Full DNS North-South Data')\n",
    "    axes[0].set_xlabel('Time (min)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # East-West data:\n",
    "    axes[1].plot(time_minutes, dframe['EW_Normalized_Shifted'], label='East-West (Full)', color='red')\n",
    "    axes[1].plot(time_minutes[::7], EW_taper_sub[i], label='Tapered East-West (Step=7)', color='rebeccapurple')\n",
    "    axes[1].set_ylabel('East-West Component')\n",
    "    axes[1].set_title('Tapered/Subsampled and Full DNS East-West Data')\n",
    "    axes[1].set_xlabel('Time (min)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Z data:\n",
    "    axes[2].plot(time_minutes, dframe['Z_Normalized_Shifted'], label='Z (Full)', color='red')\n",
    "    axes[2].plot(time_minutes[::7], Z_taper_sub[i], label='Tapered Z (Step=7)', color='royalblue')\n",
    "    axes[2].set_ylabel('Z Component')\n",
    "    axes[2].set_title('Tapered/Subsampled and Full DNS Z-Component Data')\n",
    "    axes[2].set_xlabel('Time (min)')\n",
    "    axes[2].legend()\n",
    "    #axes[2].set_xlim(-0.001,0.01)\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a4945-5824-4a0f-bbec-539cebc5c317",
   "metadata": {},
   "source": [
    "***\n",
    "### Fast Fourier Transform\n",
    "##### Notes:\n",
    "- Applying the fast fourier transform to subsampled and tapered DNS data and plotting the resulting magnitude and phase spectra\n",
    "    - plotting with amplitude correction factor of 2 to compensate for coherent gain of 0.5 from windowing <br>\n",
    "<br> Effects of subsampling/tapering:\n",
    "    - removes higher frequency content\n",
    "    - reduces spectral leakage caused by discontinuities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef0041-14b0-4753-9d02-494b4a049f5c",
   "metadata": {},
   "source": [
    "#### Approach 1: Overlay FFT results for tapered/subsampled data onto single figure with full DNS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac3381-b2ff-4fb5-8cac-db4592cf182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting FFT spectra showing tapered/subsampled data overlayed onto full DNS data for a given dataframe\n",
    "def plot_fft(data, sr, fig1=None, fig2=None, fig3=None, name='', apply_window=True):\n",
    "    \"\"\"Plot FFT with windowing correction.\n",
    "    data: array\n",
    "    sr: Sampling rate\n",
    "    apply_window : bool, says whether to apply Hann window (default True)\"\"\"\n",
    "    n = len(data)\n",
    "    \n",
    "    # Apply window if requested\n",
    "    if apply_window:\n",
    "        window = np.hanning(n)\n",
    "        windowed_data = data * window\n",
    "    else:\n",
    "        windowed_data = data\n",
    "        coherent_gain=1.0\n",
    "    \n",
    "    # Compute FFT\n",
    "    fft_values = scipy.fft.rfft(windowed_data)\n",
    "    freqs = scipy.fft.rfftfreq(n, d=1/sr)\n",
    "    \n",
    "    # magnitudes WITHOUT coherent gain correction\n",
    "    magnitudes = np.abs(fft_values) / n\n",
    "\n",
    "    # Double the AC components (not DC and Nyquist)\n",
    "    magnitudes[1:] *= 2.0\n",
    "\n",
    "    # Undo doubling for Nyquist if even length\n",
    "    if n % 2 == 0:\n",
    "        magnitudes[-1] /= 2.0\n",
    "    \n",
    "    phases = np.angle(fft_values)\n",
    "    \n",
    "    # Create figures:\n",
    "    if fig1 is None:\n",
    "        fig1 = plt.figure(figsize=(10,6))\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (Linear)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig1.number)\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig2 is None:\n",
    "        fig2 = plt.figure(figsize=(10, 6))\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (log)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig2.number)\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.legend()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig3 is None:\n",
    "        fig3 = plt.figure(figsize=(10, 6))\n",
    "        plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "        plt.title('Phase Spectrum', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Phase (radians)', fontsize=14)\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        #plt.xlim(-1, 50)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.5)\n",
    "    else:\n",
    "        plt.figure(fig3.number)\n",
    "        plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.8)\n",
    "    \n",
    "    return fig1, fig2, fig3 \n",
    "#####################################################################################################################\n",
    "#Use to create figures for one dataframe at a time:\n",
    "\n",
    "#North-South for df:\n",
    "# For full NS data\n",
    "fig1, fig2, fig3 = plot_fft(df['NS_Normalized_Shifted'].values, sr=original_sampling_rate, name='Full NS Data', apply_window=False)\n",
    "# For tapered/subsampled data \n",
    "plot_fft(NS_sub_results_df, new_sr_df, fig1=fig1, fig2=fig2, fig3=fig3, name='Subsampled/Tapered NS Data', apply_window=True)\n",
    "plt.show()\n",
    "\n",
    "#East-West:\n",
    "# For full EW data\n",
    "fig1, fig2, fig3 = plot_fft(df['EW_Normalized_Shifted'].values, sr=original_sampling_rate, name='Full EW Data', apply_window=False)\n",
    "# For tapered/subsampled data \n",
    "plot_fft(EW_sub_results_df, new_sr_df, fig1=fig1, fig2=fig2, fig3=fig3, name='Subsampled/Tapered EW Data', apply_window=True)\n",
    "plt.show()\n",
    "\n",
    "#Up-Down:\n",
    "# For full Z data\n",
    "fig1, fig2, fig3 = plot_fft(df['Z_Normalized_Shifted'].values, sr=original_sampling_rate, name='Full Z Data', apply_window=False)\n",
    "# For tapered/subsampled data \n",
    "plot_fft(Z_sub_results_df, new_sr_df, fig1=fig1, fig2=fig2, fig3=fig3, name='Subsampled/Tapered Z Data', apply_window=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92600d5e-6b91-4a0c-83c0-032b4fee9176",
   "metadata": {},
   "source": [
    "#### Approach 2: Overlay FFT spectra from all DataFrames onto 1 figure for each of the NS, EW, and Z directions\n",
    "- Creates 3 figures per direction (NS, EW, Z): linear magnitude spectrum, log magnitude spectrum, and phase spectrum\n",
    "    - 9 figures showing full DNS FFT results for all dataframes\n",
    "    - 9 figures showing tapered/subsampled FFT results for all dataframes\n",
    "- x-limits need to be adjusted to see details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ae047-36c4-4857-997e-80d28827f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated FFT code, creates 9 figures total (3 for each of linear, log, phase)\n",
    "# overlays FFT spectra from all Tyendinaga dataframes onto 1 figure (plots full DNS data separate from tapered/subsampled data)\n",
    "def plot_fft(NS_data, EW_data, Z_data, sr, NS_fig1=None, NS_fig2=None, NS_fig3=None, EW_fig1=None, EW_fig2=None, EW_fig3=None, \n",
    "             Z_fig1=None, Z_fig2=None, Z_fig3=None, name='', apply_window=True, color=None):\n",
    "    \"\"\"Plot FFT with windowing correction\n",
    "    NS_data, EW_data, Z_data: numpy arrays\n",
    "    sr: Sampling rate\n",
    "    apply_window: bool, says whether to apply Hann window (default True)\"\"\"\n",
    "    n = len(NS_data)\n",
    "    \n",
    "    # Apply window if requested\n",
    "    if apply_window:\n",
    "        window = np.hanning(n)\n",
    "        NS_windowed = NS_data * window\n",
    "        EW_windowed = EW_data * window\n",
    "        Z_windowed = Z_data * window\n",
    "    else:\n",
    "        NS_windowed = NS_data\n",
    "        EW_windowed = EW_data\n",
    "        Z_windowed = Z_data\n",
    "    \n",
    "    # Compute FFT for each component\n",
    "    NS_fft = scipy.fft.rfft(NS_windowed)\n",
    "    EW_fft = scipy.fft.rfft(EW_windowed)\n",
    "    Z_fft = scipy.fft.rfft(Z_windowed)\n",
    "    \n",
    "    freqs = scipy.fft.rfftfreq(n, d=1/sr)\n",
    "    \n",
    "    # Compute magnitudes\n",
    "    NS_magnitudes = np.abs(NS_fft) / n\n",
    "    EW_magnitudes = np.abs(EW_fft) / n\n",
    "    Z_magnitudes = np.abs(Z_fft) / n\n",
    "    \n",
    "    # Double the AC components (not DC and Nyquist)\n",
    "    NS_magnitudes[1:] *= 2.0\n",
    "    EW_magnitudes[1:] *= 2.0\n",
    "    Z_magnitudes[1:] *= 2.0\n",
    "    \n",
    "    # Undo doubling for Nyquist if even length\n",
    "    if n % 2 == 0:\n",
    "        NS_magnitudes[-1] /= 2.0\n",
    "        EW_magnitudes[-1] /= 2.0\n",
    "        Z_magnitudes[-1] /= 2.0\n",
    "    \n",
    "    # Compute phases\n",
    "    NS_phases = np.angle(NS_fft)\n",
    "    EW_phases = np.angle(EW_fft)\n",
    "    Z_phases = np.angle(Z_fft)\n",
    " ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   \n",
    "    # Plot NS component - Linear\n",
    "    if NS_fig1 is None:\n",
    "        NS_fig1 = plt.figure(figsize=(10,6))\n",
    "        plt.plot(freqs, NS_magnitudes, linewidth=1, label=name if name else 'NS', color=color)\n",
    "        plt.title('FFT Magnitude Spectrum (Linear) - NS Component', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(NS_fig1.number)\n",
    "        plt.plot(freqs, NS_magnitudes, linewidth=1, label=name if name else 'NS', color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    # Plot NS component - Log\n",
    "    if NS_fig2 is None:\n",
    "        NS_fig2 = plt.figure(figsize=(10, 6))\n",
    "        plt.loglog(freqs[1:], NS_magnitudes[1:], linewidth=1, label=name if name else 'NS', color=color)\n",
    "        plt.title('FFT Magnitude Spectrum (log) - NS Component', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(NS_fig2.number)\n",
    "        plt.loglog(freqs[1:], NS_magnitudes[1:], linewidth=1, label=name if name else 'NS', color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    # Plot NS component - Phase\n",
    "    if NS_fig3 is None:\n",
    "        NS_fig3 = plt.figure(figsize=(10, 6))\n",
    "        plt.plot(freqs[1:], NS_phases[1:], linewidth=1, label=name if name else 'NS', color=color)\n",
    "        plt.title('Phase Spectrum - NS Component', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Phase (radians)', fontsize=14)\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.5)\n",
    "    else:\n",
    "        plt.figure(NS_fig3.number)\n",
    "        plt.plot(freqs[1:], NS_phases[1:], linewidth=1, label=name if name else 'NS', color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.8)\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
    "    # Repeat for EW component\n",
    "    if EW_fig1 is None:\n",
    "        EW_fig1 = plt.figure(figsize=(10,6))\n",
    "        plt.plot(freqs, EW_magnitudes, linewidth=1, label=name if name else 'EW', color=color)\n",
    "        plt.title('FFT Magnitude Spectrum (Linear) - EW Component', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(EW_fig1.number)\n",
    "        plt.plot(freqs, EW_magnitudes, linewidth=1, label=name if name else 'EW', color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if EW_fig2 is None:\n",
    "        EW_fig2 = plt.figure(figsize=(10, 6))\n",
    "        plt.loglog(freqs[1:], EW_magnitudes[1:], linewidth=1, label=name if name else 'EW', color=color)\n",
    "        plt.title('FFT Magnitude Spectrum (log) - EW Component', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(EW_fig2.number)\n",
    "        plt.loglog(freqs[1:], EW_magnitudes[1:], linewidth=1, label=name if name else 'EW', color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if EW_fig3 is None:\n",
    "        EW_fig3 = plt.figure(figsize=(10, 6))\n",
    "        plt.plot(freqs[1:], EW_phases[1:], linewidth=1, label=name if name else 'EW', color=color)\n",
    "        plt.title('Phase Spectrum - EW Component', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Phase (radians)', fontsize=14)\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.5)\n",
    "    else:\n",
    "        plt.figure(EW_fig3.number)\n",
    "        plt.plot(freqs[1:], EW_phases[1:], linewidth=1, label=name if name else 'EW', color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.8)\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    \n",
    "    # Repeat for Z component\n",
    "    if Z_fig1 is None:\n",
    "        Z_fig1 = plt.figure(figsize=(10,6))\n",
    "        plt.plot(freqs, Z_magnitudes, linewidth=1, label=name if name else 'Z', color=color)\n",
    "        plt.title('FFT Magnitude Spectrum (Linear) - Z Component', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(Z_fig1.number)\n",
    "        plt.plot(freqs, Z_magnitudes, linewidth=1, label=name if name else 'Z', color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if Z_fig2 is None:\n",
    "        Z_fig2 = plt.figure(figsize=(10, 6))\n",
    "        plt.loglog(freqs[1:], Z_magnitudes[1:], linewidth=1, label=name if name else 'Z', color=color)\n",
    "        plt.title('FFT Magnitude Spectrum (log) - Z Component', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(Z_fig2.number)\n",
    "        plt.loglog(freqs[1:], Z_magnitudes[1:], linewidth=1, label=name if name else 'Z', color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if Z_fig3 is None:\n",
    "        Z_fig3 = plt.figure(figsize=(10, 6))\n",
    "        plt.plot(freqs[1:], Z_phases[1:], linewidth=1, label=name if name else 'Z', color=color)\n",
    "        plt.title('Phase Spectrum - Z Component', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Phase (radians)', fontsize=14)\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.5)\n",
    "    else:\n",
    "        plt.figure(Z_fig3.number)\n",
    "        plt.plot(freqs[1:], Z_phases[1:], linewidth=1, label=name if name else 'Z', color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.8)\n",
    "    \n",
    "    return NS_fig1, NS_fig2, NS_fig3, EW_fig1, EW_fig2, EW_fig3, Z_fig1, Z_fig2, Z_fig3\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Define colors for each dataframe\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "original_sampling_rate = 1024\n",
    "\n",
    "# Plot all full data together:\n",
    "NS_fig1_full, NS_fig2_full, NS_fig3_full, EW_fig1_full, EW_fig2_full, EW_fig3_full, Z_fig1_full, Z_fig2_full, Z_fig3_full = None, None, None, None, None, None, None, None, None\n",
    "\n",
    "for i, dframe in enumerate(dataframes):\n",
    "    # Extract the three components as numpy arrays\n",
    "    ns_data = dframe['NS_Normalized_Shifted'].values\n",
    "    ew_data = dframe['EW_Normalized_Shifted'].values\n",
    "    z_data = dframe['Z_Normalized_Shifted'].values\n",
    "    \n",
    "    NS_fig1_full, NS_fig2_full, NS_fig3_full, EW_fig1_full, EW_fig2_full, EW_fig3_full, Z_fig1_full, Z_fig2_full, Z_fig3_full = plot_fft(\n",
    "        ns_data, ew_data, z_data, original_sampling_rate, \n",
    "        NS_fig1=NS_fig1_full, NS_fig2=NS_fig2_full, NS_fig3=NS_fig3_full,\n",
    "        EW_fig1=EW_fig1_full, EW_fig2=EW_fig2_full, EW_fig3=EW_fig3_full,\n",
    "        Z_fig1=Z_fig1_full, Z_fig2=Z_fig2_full, Z_fig3=Z_fig3_full,\n",
    "        name=f'df{i+1} (full)',\n",
    "        apply_window=False, color=colors[i])\n",
    "\n",
    "# Plot tapered/subsampled data together:\n",
    "NS_fig1_sub, NS_fig2_sub, NS_fig3_sub, EW_fig1_sub, EW_fig2_sub, EW_fig3_sub, Z_fig1_sub, Z_fig2_sub, Z_fig3_sub = None, None, None, None, None, None, None, None, None\n",
    "\n",
    "for i, (ns_data, ew_data, z_data) in enumerate(zip(NS_subsampled_data, EW_subsampled_data, Z_subsampled_data)):\n",
    "    new_sr = original_sampling_rate / 7\n",
    "    \n",
    "    NS_fig1_sub, NS_fig2_sub, NS_fig3_sub, EW_fig1_sub, EW_fig2_sub, EW_fig3_sub, Z_fig1_sub, Z_fig2_sub, Z_fig3_sub = plot_fft(\n",
    "        ns_data, ew_data, z_data, new_sr,\n",
    "        NS_fig1=NS_fig1_sub, NS_fig2=NS_fig2_sub, NS_fig3=NS_fig3_sub,\n",
    "        EW_fig1=EW_fig1_sub, EW_fig2=EW_fig2_sub, EW_fig3=EW_fig3_sub,\n",
    "        Z_fig1=Z_fig1_sub, Z_fig2=Z_fig2_sub, Z_fig3=Z_fig3_sub,\n",
    "        name=f'df{i+1} (subsampled)',\n",
    "        apply_window=True, color=colors[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d88a5-a137-4225-b487-6667b07acc02",
   "metadata": {},
   "source": [
    "### Horizontal and Vertical FFTs\n",
    "- Goal: Add NS and EW FFTs together to get one set of plots (Horizontal)\n",
    "- Leave Z FFT plots as is (Vertical), plotted from a previous cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec0bf8-04b0-4eb1-8044-508a1c9d3532",
   "metadata": {},
   "source": [
    "#### Horizontal FFT Plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74199ce6-0005-47a1-9954-9e751f8f62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlays tapered/subsampled result onto full DNS result for given dataframe\n",
    "def plot_fft_horizontal(data_ns, data_ew, sr, fig1=None, fig2=None, name='', apply_window=True):\n",
    "    \"\"\"Plot horizontal FFT spectrum from North-South and East-West components.\n",
    "    data_ns: North-South array\n",
    "    data_ew: East-West array\n",
    "    sr: Sampling rate\"\"\"\n",
    "    n = len(data_ns)\n",
    "    \n",
    "    # Apply window if requested\n",
    "    if apply_window:\n",
    "        window = np.hanning(n)\n",
    "        windowed_ns = data_ns * window\n",
    "        windowed_ew = data_ew * window\n",
    "    else:\n",
    "        windowed_ns = data_ns\n",
    "        windowed_ew = data_ew\n",
    "    \n",
    "    # Compute FFT for both components\n",
    "    fft_ns = scipy.fft.rfft(windowed_ns)\n",
    "    fft_ew = scipy.fft.rfft(windowed_ew)\n",
    "    freqs = scipy.fft.rfftfreq(n, d=1/sr)\n",
    "    \n",
    "    # Compute magnitudes WITHOUT coherent gain correction\n",
    "    mag_ns = np.abs(fft_ns) / n\n",
    "    mag_ew = np.abs(fft_ew) / n\n",
    "    \n",
    "    # Double the AC components (not DC and Nyquist)\n",
    "    mag_ns[1:] *= 2.0\n",
    "    mag_ew[1:] *= 2.0\n",
    "    \n",
    "    # Undo doubling for Nyquist if even length\n",
    "    if n % 2 == 0:\n",
    "        mag_ns[-1] /= 2.0\n",
    "        mag_ew[-1] /= 2.0\n",
    "    \n",
    "    # Combine as RMS for horizontal magnitude?\n",
    "    #magnitudes = np.sqrt((mag_ns**2 + mag_ew**2) / 2)\n",
    "    # Combine horizontal magnitudes with vector magnitude formula:\n",
    "    magnitudes = np.sqrt((mag_ns**2) + (mag_ew**2))\n",
    "\n",
    "    # Phases:\n",
    "    phases_ns = np.angle(fft_ns) \n",
    "    phases_ew = np.angle(fft_ew)\n",
    "    \n",
    "    # Create figures:\n",
    "    if fig1 is None:\n",
    "        fig1 = plt.figure(figsize=(10,6))\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (Linear)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig1.number)\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig2 is None:\n",
    "        fig2 = plt.figure(figsize=(10, 6))\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (log)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig2.number)\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.legend()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    #if fig3 is None:\n",
    "     #   fig3 = plt.figure(figsize=(10, 6))\n",
    "      #  plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "       # plt.title('Phase Spectrum', fontsize=16)\n",
    "        #plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        #plt.ylabel('Phase (radians)', fontsize=14)\n",
    "        #plt.grid(True, alpha=0.5)\n",
    "        #plt.xticks(fontsize=14)\n",
    "        #plt.yticks(fontsize=14)\n",
    "        #plt.xlim(-1, 50)\n",
    "        #plt.tight_layout()\n",
    "        #if name:\n",
    "         #   plt.legend(loc='lower right', framealpha=0.5)\n",
    "    #else:\n",
    "     #   plt.figure(fig3.number)\n",
    "      #  plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "       # if name:\n",
    "        #    plt.legend(loc='lower right', framealpha=0.8)\n",
    "    \n",
    "    return freqs, magnitudes, fig1, fig2#, fig3   Leaving phases out for now\n",
    "\n",
    "print(\"horizontal FFT for dataframe: df\")\n",
    "# First call: Full data - creates new figures\n",
    "freqs_full, mags_full, fig1, fig2 = plot_fft_horizontal(df['NS_Normalized_Shifted'].values, df['EW_Normalized_Shifted'].values, \n",
    "    sr=original_sampling_rate, name='Full Horizontal Data', apply_window=False)\n",
    "\n",
    "# Second call: Subsampled/tapered data - reuses the same figures\n",
    "freqs_sub, mags_sub, fig1, fig2 = plot_fft_horizontal(NS_sub_results_df, EW_sub_results_df, sr=new_sr_df,\n",
    "    fig1=fig1,  # Pass the existing figures\n",
    "    fig2=fig2, name='Subsampled/Tapered Horizontal Data', apply_window=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418ff9e-5a90-416c-868b-5e2e0239c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative version: Plots horizontal FFT spectra for all dataframes on same figure (keeps full and tapered/subsampled data separate)\n",
    "def plot_fft_horizontal(data_ns, data_ew, sr, fig1=None, fig2=None, name='', apply_window=True, color=None):\n",
    "    \"\"\"Plot horizontal FFT spectrum from North-South and East-West components.\n",
    "    data_ns: North-South array\n",
    "    data_ew: East-West array\n",
    "    sr: Sampling rate\"\"\"\n",
    "    n = len(data_ns)\n",
    "    \n",
    "    # Apply window if requested\n",
    "    if apply_window:\n",
    "        window = np.hanning(n)\n",
    "        windowed_ns = data_ns * window\n",
    "        windowed_ew = data_ew * window\n",
    "    else:\n",
    "        windowed_ns = data_ns\n",
    "        windowed_ew = data_ew\n",
    "    \n",
    "    # Compute FFT for both components\n",
    "    fft_ns = scipy.fft.rfft(windowed_ns)\n",
    "    fft_ew = scipy.fft.rfft(windowed_ew)\n",
    "    freqs = scipy.fft.rfftfreq(n, d=1/sr)\n",
    "    \n",
    "    # Compute magnitudes WITHOUT coherent gain correction\n",
    "    mag_ns = np.abs(fft_ns) / n\n",
    "    mag_ew = np.abs(fft_ew) / n\n",
    "    \n",
    "    # Double the AC components (not DC and Nyquist)\n",
    "    mag_ns[1:] *= 2.0\n",
    "    mag_ew[1:] *= 2.0\n",
    "    \n",
    "    # Undo doubling for Nyquist if even length\n",
    "    if n % 2 == 0:\n",
    "        mag_ns[-1] /= 2.0\n",
    "        mag_ew[-1] /= 2.0\n",
    "    \n",
    "    # Combine horizontal magnitudes with vector magnitude formula\n",
    "    magnitudes = np.sqrt((mag_ns**2) + (mag_ew**2))\n",
    "    \n",
    "    # Phases:\n",
    "    phases_ns = np.angle(fft_ns)\n",
    "    phases_ew = np.angle(fft_ew)\n",
    "    \n",
    "    # Create figures:\n",
    "    if fig1 is None:\n",
    "        fig1 = plt.figure(figsize=(10,6))\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name, color=color)\n",
    "        plt.title('FFT Magnitude Spectrum (Linear)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig1.number)\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name, color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig2 is None:\n",
    "        fig2 = plt.figure(figsize=(10, 6))\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name, color=color)\n",
    "        plt.title('FFT Magnitude Spectrum (log)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig2.number)\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name, color=color)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    return freqs, magnitudes, fig1, fig2\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Define colors for each dataframe\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# First call: full data\n",
    "fig1_full, fig2_full = None, None\n",
    "for i, dframe in enumerate(dataframes):\n",
    "    freqs_full, mags_full, fig1_full, fig2_full = plot_fft_horizontal(dframe['NS_Normalized_Shifted'].values, dframe['EW_Normalized_Shifted'].values,\n",
    "        sr=original_sampling_rate, fig1=fig1_full, fig2=fig2_full, name=f'df{i+1} (full)', apply_window=False, color=colors[i])\n",
    "\n",
    "# Second call: Subsampled/tapered data\n",
    "fig1_sub, fig2_sub = None, None\n",
    "for i, (ns_data, ew_data) in enumerate(zip(NS_subsampled_data, EW_subsampled_data)):\n",
    "    new_sr = original_sampling_rate / 7\n",
    "    freqs_sub, mags_sub, fig1_sub, fig2_sub = plot_fft_horizontal(ns_data, ew_data, sr=new_sr, fig1=fig1_sub, fig2=fig2_sub, \n",
    "        name=f'df{i+1} (subsampled)', apply_window=True, color=colors[i])\n",
    "\n",
    "print(\"horizontal FFT plots:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aab4c6-cfbf-48cf-8924-739e242092ac",
   "metadata": {},
   "source": [
    "***\n",
    "### FFT With Moving Window\n",
    "##### Notes:\n",
    "- Goal: apply moving window (20 second intervals)\n",
    "- Using short time fourier transform from scipy.signal\n",
    "- Issue with previous version of code: time was not the same dimensions as the STFT result\n",
    "    - Possible solutions: Plot spectrogram to show frequency content overtime, or plot average magnitude spectrum\n",
    "- Tried log scale for spectrogram frequency axis, did not display well for most full data plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26267b18-ad6d-4aba-bd0f-ea1511ac1969",
   "metadata": {},
   "source": [
    "#### Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649ea3e-f0a2-4027-8afe-d3647dacbf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ShortTimeFFT(win, hop, fs, *, fft_mode='onesided', mfft=None, dual_win=None, scale_to=None, phase_shift=0)\n",
    "# win = window function\n",
    "# hop = time increment in signal samples for sliding window\n",
    "# fs = sampling frequency of output signal and window\n",
    "# fft_mode = Mode of FFT to be used (default onesided)\n",
    "# mfft = Length of the FFT used, if a zero padded FFT is desired. If None (default), the length of the window win is used\n",
    "\n",
    "# Problem with previous code (deleted): time not same dimensions as STFT result\n",
    "# Possible solutions:\n",
    "# Method 1: spectrogram\n",
    "def windowed_fft_spectrogram(data, sr, plot_title, vmax, vmin, window='hann', window_duration=20):\n",
    "    \"\"\"Compute FFT with scipy short time fourier transform\n",
    "    data: Time series to perform STFT on (array)\n",
    "    sr: sampling rate\n",
    "    plot_title: title for spectrogram plot (string)\n",
    "    window: window function to taper the data with\n",
    "    window_duration: window duration in seconds\"\"\"\n",
    "    hop = int(sr*window_duration) # hop = number of samples in window_duration (20sec)\n",
    "    \n",
    "    # Generate hann window array\n",
    "    window_array = np.hanning(hop)\n",
    "    \n",
    "    STF = ShortTimeFFT(win=window_array, hop=hop, fs=sr, fft_mode='onesided', mfft=None, scale_to='magnitude', phase_shift=0)\n",
    "    STF_result = STF.stft(data)\n",
    "    \n",
    "    # Get time and frequency arrays\n",
    "    time_axis = STF.t(len(data))  # Time values for each window (sec)\n",
    "    time_minute = time_axis/60\n",
    "    freq_axis = STF.f  # Frequency values\n",
    "    \n",
    "    # Plot spectrogram\n",
    "    stft_plot = plt.figure(figsize=(12,4))\n",
    "    plt.pcolormesh(time_minute, freq_axis, np.abs(STF_result), cmap='binary', shading='gouraud', vmax=vmax, vmin=vmin)\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(\"Time (min)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    #plt.yscale('log')\n",
    "    cbar=plt.colorbar(label='Magnitude')\n",
    "    cbar.formatter.set_powerlimits((0, 0))\n",
    "    plt.grid(which='major')\n",
    "    plt.grid(which='minor')\n",
    "    \n",
    "    return stft_plot\n",
    "\n",
    "for i, dframe in enumerate(dataframes):\n",
    "    if i==0:\n",
    "        print(\"dataframe: df\")\n",
    "    else:\n",
    "        print(f\"dataframe: df{i+1}\")\n",
    "    # Plot!------------------------------------------------------------\n",
    "    # Spectrograms for NS data (df):\n",
    "    print(\"Spectrograms for North-South data\")\n",
    "    # Full NS data:\n",
    "    windowed_fft_spectrogram(dframe['NS_Normalized_Shifted'].values, sr=original_sampling_rate, \n",
    "                             plot_title='Short Time Fourier Transform With 20s Hann Window (Full NS Data)', vmax=0.001, vmin=0,\n",
    "                             window='hann', window_duration=20)\n",
    "    plt.ylim(top=500)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Tapered/subsampled NS data:\n",
    "    windowed_fft_spectrogram(NS_taper_sub[i], sr=new_sr_df, plot_title='Short Time Fourier Transform With 20s Hann Window (Tapered/Subsampled NS Data)',\n",
    "                             vmax=0.001, vmin=0, window='hann', window_duration=20) \n",
    "    # new sampling rate should be the same for all dataframes because they have been subsampled the same\n",
    "    plt.ylim(top=70)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # Spectrograms for EW data (df):\n",
    "    print(\"Spectrograms for East-West data\")\n",
    "    # Full EW data:\n",
    "    windowed_fft_spectrogram(dframe['EW_Normalized_Shifted'].values, sr=original_sampling_rate, \n",
    "                             plot_title='Short Time Fourier Transform With 20s Hann Window (Full EW Data)', vmax=0.001, vmin=0,\n",
    "                             window='hann', window_duration=20)\n",
    "    plt.ylim(top=500)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Tapered/subsampled EW data:\n",
    "    windowed_fft_spectrogram(EW_taper_sub[i], sr=new_sr_df, plot_title='Short Time Fourier Transform With 20s Hann Window (Tapered/Subsampled EW Data)',\n",
    "                             vmax=0.001, vmin=0, window='hann', window_duration=20)\n",
    "    plt.ylim(top=70)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # Spectrograms for Z-component data for df\n",
    "    print(\"Spectrograms for Z-component data\")\n",
    "    # Full Z data:\n",
    "    windowed_fft_spectrogram(dframe['Z_Normalized_Shifted'].values, sr=original_sampling_rate, \n",
    "                             plot_title='Short Time Fourier Transform With 20s Hann Window (Full Z Data)', vmax=0.001, vmin=0,\n",
    "                             window='hann', window_duration=20)\n",
    "    plt.ylim(top=500)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Tapered/subsampled Z data:\n",
    "    windowed_fft_spectrogram(Z_taper_sub[i], sr=new_sr_df, plot_title='Short Time Fourier Transform With 20s Hann Window (Tapered/Subsampled Z Data)',\n",
    "                             vmax=0.001, vmin=0, window='hann', window_duration=20)\n",
    "    plt.ylim(top=70)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4993d-f562-441b-a35a-9a326552d023",
   "metadata": {},
   "source": [
    "***\n",
    "### H/V Ratio\n",
    "#### Notes:\n",
    "- Divide horizontal magnitude by vertical magnitude to get H/V ratio\n",
    "- Used vector-magnitude formula to combine horizontal magnitudes for North-South and East-West components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f731f5ce-4485-4788-8e65-a02e60c9dc9c",
   "metadata": {},
   "source": [
    "#### Filter for Smoothing\n",
    "- applied Savitzky-Golay filter for smoothing data\n",
    "    - also tried an envelope function for smoothing using the Hilbert transform\n",
    "- limited displayed frequency range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5993c53-509f-4950-ab28-ce72a0a6e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding envelope for smoothing using Hilbert transform:\n",
    "def envelope(input_data):\n",
    "    \"\"\"Compute envelope of input_data using Hilbert transform\"\"\"\n",
    "    signal= hilbert(input_data)\n",
    "    return np.abs(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a51f4-be6a-4e7c-b0bd-9375fdddb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HV_ratio(data_ns, data_ew, data_z, sr, apply_window=True, freq_min=0.1, freq_max=None):#, clip_max=10):\n",
    "    \"\"\"Compute Horizontal-to-Vertical Spectral Ratio (HVSR)\n",
    "    data_ns: North-South component (array)\n",
    "    data_ew: East-West component (array)\n",
    "    data_z: Vertical (Z) component (array)\n",
    "    sr: Sampling rate\n",
    "    freq_min: Minimum frequency to include (Hz)\n",
    "    freq_max: Maximum frequency to include (Hz), default is 80% of Nyquist\n",
    "    clip_max: Maximum HVSR value to allow\"\"\"\n",
    "    n = len(data_ns)\n",
    "    \n",
    "    if freq_max is None:\n",
    "        freq_max = 0.8*(sr/2)  # 80% of Nyquist to avoid edge effects\n",
    "    \n",
    "    # Apply window if requested\n",
    "    if apply_window:\n",
    "        window = np.hanning(n)\n",
    "        data_ns = data_ns*window\n",
    "        data_ew = data_ew*window\n",
    "        data_z = data_z*window\n",
    "    \n",
    "    # Compute FFTs\n",
    "    fft_ns = np.fft.rfft(data_ns)\n",
    "    fft_ew = np.fft.rfft(data_ew)\n",
    "    fft_z = np.fft.rfft(data_z)\n",
    "    \n",
    "    freqs = np.fft.rfftfreq(n, d=1/sr)\n",
    "    \n",
    "    # Compute magnitudes\n",
    "    mag_ns = np.abs(fft_ns) / n\n",
    "    mag_ew = np.abs(fft_ew) / n\n",
    "    mag_z = np.abs(fft_z) / n\n",
    "    \n",
    "    # Double AC components for one-sided spectrum correction\n",
    "    mag_ns[1:] *= 2.0\n",
    "    mag_ew[1:] *= 2.0\n",
    "    mag_z[1:] *= 2.0\n",
    "    \n",
    "    if n % 2 == 0:\n",
    "        mag_ns[-1] /= 2.0\n",
    "        mag_ew[-1] /= 2.0\n",
    "        mag_z[-1] /= 2.0\n",
    "    \n",
    "    # Use vector-magnitude formula to combine horizontal magnitudes:\n",
    "    mag_horizontal = np.sqrt((mag_ns**2) + (mag_ew**2))\n",
    "    \n",
    "    # Compute HVSR with threshold to avoid division by tiny numbers\n",
    "    z_threshold = np.max(mag_z) * 1e-8\n",
    "    hvsr = np.zeros_like(mag_horizontal)\n",
    "    mask = mag_z > z_threshold\n",
    "    hvsr[mask] = mag_horizontal[mask] / mag_z[mask]\n",
    "    \n",
    "    # Clip extreme values?\n",
    "    #hvsr = np.clip(hvsr, 0, clip_max) # comment out when don't want to use\n",
    "    \n",
    "    # Apply frequency range mask\n",
    "    freq_mask = (freqs >= freq_min) & (freqs <= freq_max)\n",
    "    \n",
    "    return freqs[freq_mask], hvsr[freq_mask]\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"dataframe: df\")\n",
    "# Compute HVSR for full data (df)\n",
    "freqs1, hvsr1 = HV_ratio(df['NS_Normalized_Shifted'].values, df['EW_Normalized_Shifted'].values, df['Z_Normalized_Shifted'].values,\n",
    "                sr=original_sampling_rate, apply_window=False, freq_min=0.1, freq_max=300)#,  # Or use None for auto freq_max\n",
    "                #clip_max=10)\n",
    "\n",
    "# Compute HVSR for tapered/subsampled data (df)\n",
    "freqs2, hvsr2 = HV_ratio(NS_sub_results_df, EW_sub_results_df, Z_sub_results_df, sr=new_sr_df, apply_window=True, freq_min=0.1,\n",
    "    freq_max=70)#,  # Should be less than decimated Nyquist (~73 Hz for subsampling step=7)\n",
    "    #clip_max=10)\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Apply smoothing with Savitzky-Golay filter\n",
    "hvsr1_smooth = savgol_filter(hvsr1, window_length=20481, polyorder=2) ## For 20s window, 20s*(sampling rate in /s) = number of samples in 20 sec\n",
    "# Note: window length should be an odd integer to allow the filter window to be centered symmetrically on the current data point\n",
    "hvsr2_smooth = savgol_filter(hvsr2, window_length=2925, polyorder=2) # 20*new_sr_df = approx. 2925\n",
    "#~~~~~~~~~~~~~~~ Testing envelope with Hilbert transform ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# call envelope function from previous cell:\n",
    "#hvsr1_envelope = envelope(hvsr1_smooth)\n",
    "#hvsr2_envelope = envelope(hvsr2_smooth)\n",
    "# doesn't work well, adds spikes at edges of plot\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Try second pass through Savitzky-Golay filter instead:\n",
    "hvsr1_smooth = savgol_filter(hvsr1_smooth, window_length=20001, polyorder=2)\n",
    "hvsr2_smooth = savgol_filter(hvsr2_smooth, window_length=10001, polyorder=2)\n",
    "# third pass?\n",
    "hvsr1_smooth = savgol_filter(hvsr1_smooth, window_length=10001, polyorder=2)\n",
    "hvsr2_smooth = savgol_filter(hvsr2_smooth, window_length=10001, polyorder=2)\n",
    "hvsr2_smooth = savgol_filter(hvsr2_smooth, window_length=10001, polyorder=2) # 4th pass for tapered/subsampled data\n",
    "hvsr2_smooth = savgol_filter(hvsr2_smooth, window_length=10001, polyorder=2) # 5th pass for tapered/subsampled data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Find main peak (full data)\n",
    "peak_idx = np.argmax(hvsr1_smooth[(freqs1 > 10) & (freqs1 < 50)])\n",
    "peak_freq = freqs1[(freqs1 > 10) & (freqs1 < 50)][peak_idx]\n",
    "peak_value = hvsr1_smooth[(freqs1 > 10) & (freqs1 < 50)][peak_idx]\n",
    "print(f\"Full data peak frequency: {peak_freq} Hz\")\n",
    "print(f\"Full data peak H/V: {peak_value}\")\n",
    "# (tapered/subsampled data):\n",
    "peak_idx2 = np.argmax(hvsr2_smooth[(freqs2 > 10) & (freqs2 < 50)])\n",
    "peak_freq2 = freqs2[(freqs2 > 10) & (freqs2 < 50)][peak_idx2]\n",
    "peak_value2 = hvsr2_smooth[(freqs2 > 10) & (freqs2 < 50)][peak_idx2]\n",
    "print(f\"Tapered/Subsampled data peak frequency: {peak_freq2} Hz\")\n",
    "print(f\"Tapered/Subsampled data peak H/V: {peak_value2} Hz\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Smoothed data \n",
    "step=1 # can use data step > 1 if preferred to plot every nth point\n",
    "plt.semilogx(freqs1[::step], hvsr1_smooth[::step], label=\"H/V From Full Data\") \n",
    "plt.semilogx(freqs2[::step], hvsr2_smooth[::step], label=\"H/V From Tapered/Subsampled Data\")\n",
    "plt.axhline(y=1, color='grey', linestyle='--', alpha=0.5, label='H/V = 1')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('H/V Ratio')\n",
    "plt.title('Smoothed Horizontal-to-Vertical Spectral Ratio (HVSR)')\n",
    "plt.ylim([0, 5])  # Adjust based on your data\n",
    "plt.grid(True, which=\"both\", alpha=0.5)\n",
    "plt.axvline(x=30.63, linestyle=\"--\", color='green', label='30.63 Hz')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "print(\"Note: 30.63 +/- 3.81 Hz is the max. H/V from screenshot of Grilla average H/V plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d9f4d-c8de-4824-90a1-1f95359653ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated version - in progress:\n",
    "def HV_ratio(data_ns, data_ew, data_z, sr, apply_window=True, freq_min=0.1, freq_max=None, clip_max=10):\n",
    "    \"\"\"Compute Horizontal-to-Vertical Spectral Ratio (HVSR)\n",
    "    data_ns: North-South component (array)\n",
    "    data_ew: East-West component (array)\n",
    "    data_z: Vertical (Z) component (array)\n",
    "    sr: Sampling rate\n",
    "    freq_min: Minimum frequency to include (Hz)\n",
    "    freq_max: Maximum frequency to include (Hz), default is 80% of Nyquist\n",
    "    clip_max: Maximum HVSR value to allow\"\"\"\n",
    "    n = len(data_ns)\n",
    "    \n",
    "    if freq_max is None:\n",
    "        freq_max = 0.8*(sr/2)  # 80% of Nyquist\n",
    "    \n",
    "    # Apply window if requested\n",
    "    if apply_window:\n",
    "        window = np.hanning(n)\n",
    "        data_ns = data_ns * window\n",
    "        data_ew = data_ew * window\n",
    "        data_z = data_z * window\n",
    "    \n",
    "    # Compute FFTs\n",
    "    fft_ns = np.fft.rfft(data_ns)\n",
    "    fft_ew = np.fft.rfft(data_ew)\n",
    "    fft_z = np.fft.rfft(data_z)\n",
    "    \n",
    "    freqs = np.fft.rfftfreq(n, d=1/sr)\n",
    "    \n",
    "    # Compute magnitudes\n",
    "    mag_ns = np.abs(fft_ns) / n\n",
    "    mag_ew = np.abs(fft_ew) / n\n",
    "    mag_z = np.abs(fft_z) / n\n",
    "    \n",
    "    # Double AC components for one-sided spectrum correction\n",
    "    mag_ns[1:] *= 2.0\n",
    "    mag_ew[1:] *= 2.0\n",
    "    mag_z[1:] *= 2.0\n",
    "    \n",
    "    if n % 2 == 0:\n",
    "        mag_ns[-1] /= 2.0\n",
    "        mag_ew[-1] /= 2.0\n",
    "        mag_z[-1] /= 2.0\n",
    "    \n",
    "    # Use vector-magnitude formula to combine horizontal magnitudes:\n",
    "    mag_horizontal = np.sqrt((mag_ns**2) + (mag_ew**2))\n",
    "    \n",
    "    # Compute HVSR with threshold to avoid division by tiny numbers\n",
    "    z_threshold = np.max(mag_z) * 1e-8\n",
    "    hvsr = np.zeros_like(mag_horizontal)\n",
    "    mask = mag_z > z_threshold\n",
    "    hvsr[mask] = mag_horizontal[mask] / mag_z[mask]\n",
    "    \n",
    "    # Clip extreme values?\n",
    "    hvsr = np.clip(hvsr, 0, clip_max)  # comment out when don't want to use\n",
    "    \n",
    "    # Apply frequency range mask\n",
    "    freq_mask = (freqs >= freq_min) & (freqs <= freq_max)\n",
    "    \n",
    "    return freqs[freq_mask], hvsr[freq_mask]\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Define colors\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Compute HVSR for all dataframes\n",
    "hvsr_full_list = []\n",
    "freqs_full_list = []\n",
    "for i, dframe in enumerate(dataframes):\n",
    "    freqs_full, hvsr_full = HV_ratio(dframe['NS_Normalized_Shifted'].values, dframe['EW_Normalized_Shifted'].values, dframe['Z_Normalized_Shifted'].values,\n",
    "        sr=original_sampling_rate, apply_window=False, freq_min=0.1, freq_max=300,  # Or use None for auto\n",
    "        clip_max=10)\n",
    "    freqs_full_list.append(freqs_full)\n",
    "    hvsr_full_list.append(hvsr_full)\n",
    "\n",
    "# Compute HVSR for tapered/subsampled data\n",
    "hvsr_sub_list = []\n",
    "freqs_sub_list = []\n",
    "new_sr = original_sampling_rate / 7\n",
    "nyquist_sub = new_sr / 2  # About 73 Hz\n",
    "print(\"Nyquist for subsampled data:\", nyquist_sub)\n",
    "for i, (ns_data, ew_data, z_data) in enumerate(zip(NS_subsampled_data, EW_subsampled_data, Z_subsampled_data)):\n",
    "    freqs_sub, hvsr_sub = HV_ratio(ns_data, ew_data, z_data, sr=new_sr, apply_window=True, freq_min=0.1,\n",
    "        freq_max=70,  # Should be less than decimated Nyquist\n",
    "        clip_max=10)\n",
    "    freqs_sub_list.append(freqs_sub)\n",
    "    hvsr_sub_list.append(hvsr_sub)\n",
    "\n",
    "# Savitzky-Golay filter for smoothing ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# For 20s window at sampling rate: window_length should be odd integer\n",
    "window_length_full = 20 * original_sampling_rate  # 20 seconds worth of samples\n",
    "window_length_sub = 40 * new_sr  # 40 seconds worth of samples\n",
    "polyorder=2\n",
    "\n",
    "hvsr_full_smooth_list = []\n",
    "for hvsr in hvsr_full_list:\n",
    "    # Make sure window_length is not larger than data length and is odd\n",
    "    wl = min(int(window_length_full), len(hvsr))\n",
    "    if wl % 2 == 0:\n",
    "        wl -= 1  # Make it odd\n",
    "    if wl < polyorder + 2:\n",
    "        wl = polyorder + 2\n",
    "        if wl % 2 == 0:\n",
    "            wl += 1\n",
    "    hvsr_smooth = savgol_filter(hvsr, window_length=wl, polyorder=polyorder)\n",
    "    hvsr_smooth = savgol_filter(hvsr_smooth, window_length=wl, polyorder=polyorder) # second pass through smoothing filter\n",
    "    hvsr_full_smooth_list.append(hvsr_smooth)\n",
    "\n",
    "hvsr_sub_smooth_list = []\n",
    "for hvsr in hvsr_sub_list:\n",
    "    wl = min(int(window_length_sub), len(hvsr))\n",
    "    if wl % 2 == 0:\n",
    "        wl -= 1\n",
    "    if wl < polyorder + 2:\n",
    "        wl = polyorder + 2\n",
    "        if wl % 2 == 0:\n",
    "            wl += 1\n",
    "    hvsr_smooth = savgol_filter(hvsr, window_length=wl, polyorder=polyorder)\n",
    "    hvsr_smooth = savgol_filter(hvsr_smooth, window_length=wl, polyorder=polyorder) # second pass through smoothing filter\n",
    "    hvsr_smooth = savgol_filter(hvsr_smooth, window_length=wl, polyorder=polyorder) # third pass through smoothing filter\n",
    "    hvsr_smooth = savgol_filter(hvsr_smooth, window_length=wl, polyorder=polyorder) # fourth pass through smoothing filter\n",
    "    hvsr_sub_smooth_list.append(hvsr_smooth)\n",
    "\n",
    "# Find main peak for each dataset ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"Full Data Peak Frequencies:\")\n",
    "for i, (freqs, hvsr_smooth) in enumerate(zip(freqs_full_list, hvsr_full_smooth_list)):\n",
    "    mask = (freqs > 10) & (freqs < 50)\n",
    "    if np.any(mask):\n",
    "        peak_idx = np.argmax(hvsr_smooth[mask])\n",
    "        # Adjust index for the mask\n",
    "        mask_indices = np.where(mask)[0]\n",
    "        peak_idx_full = mask_indices[peak_idx]\n",
    "        peak_freq = freqs[peak_idx_full]\n",
    "        peak_value = hvsr_smooth[peak_idx_full]\n",
    "        print(f\"df{i+1}: {peak_freq:.2f} Hz (value: {peak_value:.2f})\")\n",
    "\n",
    "print(\"\\nTapered/Subsampled Data Peak Frequencies:\")\n",
    "for i, (freqs, hvsr_smooth) in enumerate(zip(freqs_sub_list, hvsr_sub_smooth_list)):\n",
    "    mask = (freqs > 10) & (freqs < 50)\n",
    "    if np.any(mask):\n",
    "        peak_idx = np.argmax(hvsr_smooth[mask])\n",
    "        mask_indices = np.where(mask)[0]\n",
    "        peak_idx_full = mask_indices[peak_idx]\n",
    "        peak_freq = freqs[peak_idx_full]\n",
    "        peak_value = hvsr_smooth[peak_idx_full]\n",
    "        print(f\"df{i+1}: {peak_freq:.2f} Hz (value: {peak_value:.2f})\")\n",
    "\n",
    "# Plot full data together ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "plt.figure(figsize=(12, 6))\n",
    "step = 1  # Plot every nth point to make plot cleaner\n",
    "for i, (freqs, hvsr_smooth) in enumerate(zip(freqs_full_list, hvsr_full_smooth_list)):\n",
    "    plt.semilogx(freqs[::step], hvsr_smooth[::step], label=f\"df{i+1} (full)\", color=colors[i], linewidth=1.5)\n",
    "\n",
    "plt.axhline(y=1, color='grey', linestyle='--', alpha=0.5, label='H/V = 1')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('H/V Ratio')\n",
    "plt.title('Smoothed Horizontal-to-Vertical Spectral Ratio (HVSR) - Full Data')\n",
    "#plt.ylim(0, 5)  # Adjust based on data\n",
    "plt.grid(True, which=\"both\", alpha=0.5)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot tapered/subsampled data together\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, (freqs, hvsr_smooth) in enumerate(zip(freqs_sub_list, hvsr_sub_smooth_list)):\n",
    "    plt.semilogx(freqs[::step], hvsr_smooth[::step], label=f\"df{i+1} (subsampled)\", color=colors[i], linewidth=1.5)\n",
    "\n",
    "plt.axhline(y=1, color='grey', linestyle='--', alpha=0.5, label='H/V = 1')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('H/V Ratio')\n",
    "plt.title('Smoothed Horizontal-to-Vertical Spectral Ratio (HVSR) - Tapered/Subsampled Data')\n",
    "#plt.ylim(0, 5)  # Adjust based on the data\n",
    "plt.grid(True, which=\"both\", alpha=0.5)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print max H/V values\n",
    "print(\"\\nMax H/V for Full Data:\")\n",
    "for i, hvsr_smooth in enumerate(hvsr_full_smooth_list):\n",
    "    print(f\"df{i+1}: {hvsr_smooth[::step].max():.2f}\")\n",
    "\n",
    "print(\"\\nMax H/V for Tapered/Subsampled Data:\")\n",
    "for i, hvsr_smooth in enumerate(hvsr_sub_smooth_list):\n",
    "    print(f\"df{i+1}: {hvsr_smooth[::step].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f130b-4a64-46a5-b950-340fb084d39b",
   "metadata": {},
   "source": [
    "#### Interpreting Horizontal-to-Vertical Spectral Ratios\n",
    "- Peaks should occur at fundamental and higher order resonance frequencies\n",
    "    - (fundamental frequency = lowest resonant frequency in a system)\n",
    "- Typically, the fundamental resonance frequency is the first/lowest value indicated by the highest amplitude peak on the H/V frequency spectrum\n",
    "- H/V = 1 indicates that the horizontal and vertical motions are equal\n",
    "- H/V < 1 indicates that horizontal motion is weaker than vertical motion\n",
    "- H/V > 1 indicates that horizontal motion is stronger than vertical motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d6bd7-adc7-43e9-a73e-4962736f4657",
   "metadata": {},
   "source": [
    "### Plotting H/V Ratio From Grilla .txt File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4933f5f3-8cc5-47c8-b8ff-6a7576d64801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to use H/V .txt file downloaded from Grilla:\n",
    "column_names = ['freq.', 'H/V']\n",
    "dtf = pd.read_table('Tyendinaga_HV_ratio.asc', delimiter=r'\\s+', encoding='latin-1', skiprows=31, names=column_names, usecols=column_names)\n",
    "dtf.head().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65e686-39f9-415f-84f3-b6351780620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(dtf['freq.'], dtf['H/V'], label=\"H/V Ratio from Grilla Data File\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"H/V Ratio\")\n",
    "plt.title(\"H/V Ratio from Grilla Data File\")\n",
    "plt.axvline(x=30.63, color='red', linestyle='--', label=\"30.63 Hz\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d39535-c685-4faf-91a5-18f5ebb45f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfed7ba-754c-4e90-a7aa-2f8a6817598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded columns: NS, EW, Z, nsL, ewL, zL, aY, aX, aZ, NS_Detrended, EW_Detrended, Z_Detrended, NS_Normalized, EW_Normalized, Z_Normalized\n",
    "# Will be left with DataFrame containing time (s) and the Normalized_Shifted data for NS, EW, and Z components\n",
    "df_updated = df.drop(['NS', 'EW', 'Z', 'nsL', 'ewL', 'zL', 'aY', 'aX', 'aZ', 'NS_Detrended', 'EW_Detrended', 'Z_Detrended', 'NS_Normalized', \n",
    "                      'EW_Normalized', 'Z_Normalized'], axis=1)\n",
    "df_updated.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
