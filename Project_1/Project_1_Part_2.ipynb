{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18fe871d-970f-4b5f-a32d-c62dd9edb62b",
   "metadata": {},
   "source": [
    "# Drone Audio Data\n",
    "### Code Summary:\n",
    "- Detrending, normalizing, and shifting data to zero mean\n",
    "- Fast Fourier transform magnitude and phase spectra plots\n",
    "- Continuous wavelet transform scalograms with Morlet wavelet\n",
    "- Subsampled data plots\n",
    "- Tapered data plots\n",
    "- Histograms and statistics for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c1841-c164-4135-8ec5-deaea2d664a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install librosa[all]\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.tools as tls\n",
    "import scipy.stats as ss\n",
    "import scipy.fft\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from scipy import interpolate\n",
    "from scipy.signal.windows import hann\n",
    "from scipy import signal\n",
    "from scipy.ndimage import uniform_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06196dbc-01b6-4ece-9511-b2980ff344c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# sampling rate is 48kHz\n",
    "y, sr = librosa.load('20250919_backyard_clippy.WAV', sr=48000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a4bc8-b51e-4c2a-b6c3-086dfa7d9f01",
   "metadata": {},
   "source": [
    "***\n",
    "### Plotting the Normalized, Detrended, and Shifted (DNS) Time Series\n",
    "#### Notes:\n",
    "- Data was loaded with librosa.load, which automatically normalizes the data range to [-1, 1]\n",
    "- Data was linearly detrended using signal.detrend from scipy\n",
    "- After detrending, data was shifted to ~zero mean by subtracting the mean from itself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be66d7-eb94-49a3-a58d-5437cb013694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linearly detrend the data\n",
    "y_detrended = signal.detrend(y, type='linear')\n",
    "\n",
    "# Center the data (zero mean)\n",
    "y_centered = y_detrended - np.mean(y_detrended)\n",
    "\n",
    "# PLot time series:\n",
    "drone_audio= plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(y_centered, sr=sr, axis='time')\n",
    "plt.title('Drone Audio Waveform')\n",
    "plt.xlabel('Time (M:SS)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Conversion to plotly doesn't work. Message says \"Plotly can only import path collections linked to 'data' coordinates\"\n",
    "print(f'sampling rate: {sr} samples per second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743b0b3-1a8d-44bc-9a0c-fc6d83a214f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some stats:\n",
    "print(ss.describe(y_centered))\n",
    "print(\"standard deviaiton:\", np.std(y_centered))\n",
    "print(\"median:\", np.median(y_centered))\n",
    "print(\"mode:\", ss.mode(y_centered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1509218-6e3a-4444-8be5-eb62413453e4",
   "metadata": {},
   "source": [
    "***\n",
    "### Subsampling the Time Series\n",
    "#### Notes:\n",
    "- different step sizes were applied to the normalized, detrended and mean-shifted (DNS) data for subsampling\n",
    "- comment out certain series before plotting to focus on a specific step value\n",
    "- adjust x-axis limits to zoom in on certain times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e1bae1-8662-4841-bf74-e36e5393b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y_centered (numpy array) to pandas data frome\n",
    "drone_data = pd.DataFrame(y_centered)\n",
    "drone_data.columns = ['Amplitude']\n",
    "drone_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3c4f4-5b8d-4112-aed0-5bab95ac913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for time in seconds\n",
    "time_secs = drone_data.index / sr\n",
    "drone_data['time_secs'] = time_secs\n",
    "drone_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7afba-2c35-432c-8db7-156ca5858e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample drone audio:\n",
    "# Number of data points in df1['Normalized_Shifted']: 23292\n",
    "step1 = 10\n",
    "step2 = 100\n",
    "step3 = 1000\n",
    "step4 = 10000\n",
    "\n",
    "subsamp_plot = plt.figure(figsize=(12,4))\n",
    "plt.plot(drone_data['time_secs'], drone_data['Amplitude'], label=\"Full Data\")\n",
    "#plt.plot(drone_data['time_secs'][::step1], drone_data['Amplitude'][::step1], label=f\"Step 1 = {step1}\")\n",
    "#plt.plot(drone_data['time_secs'][::step2], drone_data['Amplitude'][::step2], label=f\"Step 2 = {step2}\")\n",
    "#plt.plot(drone_data['time_secs'][::step3], drone_data['Amplitude'][::step3], label=f\"Step 3 = {step3}\")\n",
    "#plt.plot(drone_data['time_secs'][::step4], drone_data['Amplitude'][::step4], label=f\"Step 3 = {step4}\")\n",
    "plt.plot(drone_data['time_secs'][::562], drone_data['Amplitude'][::562], label=\"Supsampled Data (step=562)\")\n",
    "plt.title(\"Subsampling Drone Audio Data\")\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.xlim(83,85)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Conversion to plotly doesn't work --> try to add buttons using matplotlib\n",
    "# see what happens when you change the step size to __ points per second "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0826723e-2428-444e-86a4-a1f5cae3b195",
   "metadata": {},
   "source": [
    "### Comparing Subsampled Time Series to Full Time Series\n",
    "#### Notes:\n",
    "- The subsampled time series of different step sizes were compared to the full detrended, normalized and shifted (DNS) time series\n",
    "- A variety comparison methods were tested that could be applied elsewhere as well (e.g. for comparing tapered vs untapered data):\n",
    "    - **Comparing summary statistics** (i.e. mean, median, standard deviation) for different sampling rates against the full DNS series\n",
    "    - Calculating the **mean absolute error (MAE)** between the full DNS data and reconstructions of the subsampled data\n",
    "        - interpolation was used to reconstruct the time series after subsampling to align timestamps between the subsampled data and the original DNS data\n",
    "        - the MAE was then calculated and expressed as a percentage of the DNS series' standard deviation\n",
    "    - Defining a **'percent_check' function** to determine if the subsampled data is within 5% of the full DNS data\n",
    "        - this method also uses interpolation to compare subsampled data to the full DNS data\n",
    "        - the absolute error between the full DNS data and the reconstructed subsampled data is calculated and divided by the full data range\n",
    "        - this result is then used determine if the error is within the selected threshold (i.e. 5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1d8011-22f3-4021-be73-b0831aebe40c",
   "metadata": {},
   "source": [
    "#### Comparing Summary Statistics for Different Subsampling Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684545d-6f07-440b-9712-895fdd3fcb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare summary statistics for different sampling steps\n",
    "stats_original = {'Mean': drone_data['Amplitude'].iloc[::].mean(),\n",
    "    'Std': drone_data['Amplitude'].iloc[::].std(),\n",
    "    'Median': drone_data['Amplitude'].iloc[::].median()}\n",
    "\n",
    "stats_step1 = {'Mean': drone_data['Amplitude'].iloc[::step1].mean(),\n",
    "    'Std': drone_data['Amplitude'].iloc[::step1].std(),\n",
    "    'Median': drone_data['Amplitude'].iloc[::step1].median()}\n",
    "\n",
    "stats_step2 = {'Mean': drone_data['Amplitude'].iloc[::step2].mean(),\n",
    "    'Std': drone_data['Amplitude'].iloc[::step2].std(),\n",
    "    'Median': drone_data['Amplitude'].iloc[::step2].median()}\n",
    "\n",
    "stats_step3 = {'Mean': drone_data['Amplitude'].iloc[::step3].mean(),\n",
    "    'Std': drone_data['Amplitude'].iloc[::step3].std(),\n",
    "    'Median': drone_data['Amplitude'].iloc[::step3].median()}\n",
    "\n",
    "stats_step4 = {'Mean': drone_data['Amplitude'].iloc[::step4].mean(),\n",
    "    'Std': drone_data['Amplitude'].iloc[::step4].std(),\n",
    "    'Median': drone_data['Amplitude'].iloc[::step4].median()}\n",
    "\n",
    "# Percent differences in statistics\n",
    "for stat in ['Mean', 'Std', 'Median']:\n",
    "    pct_o1 = (abs(stats_original[stat] - stats_step1[stat]) / abs(stats_original[stat])) * 100\n",
    "    pct_o2 = (abs(stats_original[stat] - stats_step2[stat]) / abs(stats_original[stat])) * 100\n",
    "    pct_o3 = (abs(stats_original[stat] - stats_step3[stat]) / abs(stats_original[stat])) * 100\n",
    "    #pct_12 = abs(stats_step1[stat] - stats_step2[stat]) / abs(stats_step1[stat]) * 100\n",
    "    #pct_13 = abs(stats_step1[stat] - stats_step3[stat]) / abs(stats_step1[stat]) * 100\n",
    "    pct_o4 = (abs(stats_original[stat] - stats_step4[stat]) / abs(stats_original[stat])) * 100\n",
    "    print(f\"{stat} % diff (original vs step1): {pct_o1:.2f}%\")\n",
    "    print(f\"{stat} % diff (original vs step2): {pct_o2:.2f}%\")\n",
    "    print(f\"{stat} % diff (original vs step3): {pct_o3:.2f}%\")\n",
    "    print(f\"{stat} % diff (original vs step4): {pct_o4:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1684d8-80cf-4636-a2c2-4d26be1af9e0",
   "metadata": {},
   "source": [
    "#### Comparing Subsampled DNS Data to Full DNS Data Using Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7889f-fc04-4cbe-befe-b43f4c4ea2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing subsampled data to original\n",
    "# using interpolation to align timestamps\n",
    "# Original time series:\n",
    "x_original = np.arange(len(drone_data))\n",
    "y_original = drone_data['Amplitude'].values\n",
    "\n",
    "# Create interpolation functions for each subsampled version\n",
    "x_step1 = np.arange(0, len(drone_data), step1)\n",
    "y_step1 = drone_data['Amplitude'].iloc[::step1].values\n",
    "f_step1 = interpolate.interp1d(x_step1, y_step1, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "x_step2 = np.arange(0, len(drone_data), step2)\n",
    "y_step2 = drone_data['Amplitude'].iloc[::step2].values\n",
    "f_step2 = interpolate.interp1d(x_step2, y_step2, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "x_step3 = np.arange(0, len(drone_data), step3)\n",
    "y_step3 = drone_data['Amplitude'].iloc[::step3].values\n",
    "f_step3 = interpolate.interp1d(x_step3, y_step3, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "# Reconstruct time series from subsampled data:\n",
    "reconstructed_step1 = f_step1(x_original)\n",
    "reconstructed_step2 = f_step2(x_original)\n",
    "reconstructed_step3 = f_step3(x_original)\n",
    "\n",
    "# Trying mean absolute error (MAE), then can also express as a percentage of the data's standard deviation\n",
    "# Calculate MAE for each taper:\n",
    "mae_s1 = np.mean(np.abs(drone_data['Amplitude'] - reconstructed_step1))\n",
    "mae_s2 = np.mean(np.abs(drone_data['Amplitude'] - reconstructed_step2))\n",
    "mae_s3 = np.mean(np.abs(drone_data['Amplitude'] - reconstructed_step3))\n",
    "\n",
    "# Express as percentage of original data's standard deviation\n",
    "original_std = np.std(drone_data['Amplitude'])\n",
    "print(f\"Standard deviation of full data: {original_std: .4f}\")\n",
    "percent_diff_s1 = (mae_s1 / original_std) * 100\n",
    "percent_diff_s2 = (mae_s2 / original_std) * 100\n",
    "percent_diff_s3 = (mae_s3 / original_std) * 100\n",
    "\n",
    "print(f\"Step 1 Subsample: Mean abs error: {mae_s1:.4f}, {percent_diff_s1:.2f}% of the original data's standard deviation\")\n",
    "print(f\"Step 2 Subsample: Mean abs error: {mae_s2:.4f}, {percent_diff_s2:.2f}% of the original data's standard deviation\")\n",
    "print(f\"Step 3 Subsample: Mean abs error: {mae_s3:.4f}, {percent_diff_s3:.2f}% of the original data's standard deviation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8b2f1-6211-4239-899e-8ae14374c21e",
   "metadata": {},
   "source": [
    "#### Comparing Subsampled DNS Data to Full DNS Data Using 'percent_check' Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb0fd9-9e9c-49dc-8f3e-28eaaf495b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if subsampled data is within 5% of original\n",
    "def percent_check(data, column, step, tolerance=0.05):\n",
    "    # Get original series\n",
    "    x_original = np.arange(len(data))\n",
    "    y_original = data[column].values\n",
    "    \n",
    "    # Get subsampled series\n",
    "    x_subsampled = np.arange(0, len(data), step)\n",
    "    y_subsampled = data[column].iloc[::step].values\n",
    "    \n",
    "    # Interpolate subsampled data back to original timestamps\n",
    "    f_interp = interpolate.interp1d(x_subsampled, y_subsampled, kind='linear', fill_value='extrapolate')\n",
    "    y_reconstructed = f_interp(x_original)\n",
    "    \n",
    "    # Calculate absolute errors\n",
    "    abs_errors = np.abs(y_original - y_reconstructed)\n",
    "    \n",
    "    # Calculate data range (the scale of the data)\n",
    "    data_range = np.max(y_original) - np.min(y_original)\n",
    "    print(\"data_range:\", data_range)\n",
    "    # Normalize errors by data range instead of individual values\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    # After calculating normalized_errors\n",
    "    # plt.figure(figsize=(12, 4))\n",
    "    # plt.plot(normalized_errors*100, alpha=0.5)\n",
    "    # plt.axhline(tolerance*100, color='r', linestyle='--', label=f'{tolerance*100}% tolerance')\n",
    "    # plt.ylabel('Normalized Error (%)')\n",
    "    # plt.xlabel('Data Point')\n",
    "    # plt.title(f'Reconstruction Error (Step={step})')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    \n",
    "    # Test if within tolerance\n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance)) * 100\n",
    "    \n",
    "    # Overall pass/fail\n",
    "    passes = pct_within >= 95  # At least 95% of points within tolerance\n",
    "    \n",
    "    results = {\n",
    "        'step': step,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes': passes,\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'num_original_points': len(y_original),\n",
    "        'num_subsampled_points': len(y_subsampled),\n",
    "        'data_range': f'{data_range: .4f}',  \n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%' }\n",
    "    \n",
    "    return results\n",
    "\n",
    "#results_step1 = percent_check(drone_data, 'Amplitude', step1, tolerance=0.05)\n",
    "#results_step2 = percent_check(drone_data, 'Amplitude', step2, tolerance=0.05)\n",
    "#results_step3 = percent_check(drone_data, 'Amplitude', step3, tolerance=0.05)\n",
    "#results_step4 = percent_check(drone_data, 'Amplitude', step4, tolerance=0.05)\n",
    "\n",
    "#print(\"results1:\", results_step1)\n",
    "#print(\"results2:\", results_step2)\n",
    "#print(\"results3:\", results_step3)\n",
    "#print(\"results4:\", results_step4)\n",
    "results_step_test = percent_check(drone_data, 'Amplitude', 562, tolerance=0.05)\n",
    "print(\"results_test:\", results_step_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7758a04b-f62d-4178-a6c0-76024184b931",
   "metadata": {},
   "source": [
    "***\n",
    "### Tapering the Time Series\n",
    "#### Notes:\n",
    "- a Hann window/raised cosine was used to taper the DNS time series\n",
    "- the time series was padded with zeros to create different tapers:\n",
    "    - no padding\n",
    "    - padding with half the length of the original time series\n",
    "    - padding with the full length of the original time series\n",
    "    - etc.\n",
    "- comment out certain data before plotting to focus on specific series, or adjust axes limits to zoom in on certain features\n",
    "- the same methods of comparison that were used to compare subsampled to full data were used to compare the tapered data to the original DNS series\n",
    "- a goal of tapering: reduce spectral leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c7602-26c0-4e63-ac87-72ce42eb1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tapering Drone Audio\n",
    "L = len(drone_data['Amplitude'].values)\n",
    "data = drone_data['Amplitude'].values\n",
    "time_s = drone_data['time_secs'].values\n",
    "# time delta\n",
    "time_delta = (time_s[1] - time_s[0])\n",
    "\n",
    "# 1L - original taper\n",
    "window1 = hann(L)\n",
    "tapered_data1 = window1 * data\n",
    "padding1 = 0\n",
    "\n",
    "# 2L - gentler taper\n",
    "padding2 = L // 2\n",
    "data2_padded = np.concatenate([np.zeros(padding2), data, np.zeros(padding2)])\n",
    "window2 = hann(len(data2_padded))\n",
    "tapered_data2_full = window2 * data2_padded\n",
    "time_s2 = np.arange(len(data2_padded)) * time_delta - (padding2 * time_delta)\n",
    "\n",
    "# 3L - very gentle taper\n",
    "padding3 = L\n",
    "data3_padded = np.concatenate([np.zeros(padding3), data, np.zeros(padding3)])\n",
    "window3 = hann(len(data3_padded))\n",
    "tapered_data3_full = window3 * data3_padded\n",
    "time_s3 = np.arange(len(data3_padded)) * time_delta - (padding3 * time_delta)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(time_s, drone_data['Amplitude'], label=\"Full Data (1L)\")\n",
    "plt.plot(time_s, tapered_data1, label=\"1L Tapered Series\")\n",
    "plt.plot(time_s2, tapered_data2_full, label=\"2L Tapered Series\")\n",
    "plt.plot(time_s3, tapered_data3_full, label=\"3L Tapered Series\")\n",
    "plt.title(\"Tapering Drone Audio Data\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.xlim(-0.01, 0.025)\n",
    "plt.ylim(-0.025, 0.025)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# taper subsampled data once you know that things are working individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9abff31-63ce-4055-a642-b77f1927b073",
   "metadata": {},
   "source": [
    "#### Comparing Tapered DNS Data to Full DNS Data Using 'percent_check_tapered' Function\n",
    "- This version of the 'percent_check' function includes MAE as an output in the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a7dad-fb40-40c1-8660-2e6cd4056f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = drone_data['Amplitude'].values\n",
    "def percent_check_tapered(original_data, tapered_data_full, padding, tolerance=0.05):\n",
    "    \"\"\"Compare tapered time series to original time series\n",
    "    Parameters:\n",
    "    original_data : array\n",
    "        Original unpadded time series\n",
    "    tapered_data_full : array\n",
    "        Tapered time series (includes padding)\n",
    "    padding : int\n",
    "        Amount of padding added to each end\n",
    "    tolerance : float\n",
    "        Acceptable error as fraction of data range\"\"\"\n",
    "    # Extract the original region from tapered data (remove padding)\n",
    "    if padding > 0:\n",
    "        tapered_original_region = tapered_data_full[padding:-padding]\n",
    "    else:\n",
    "        tapered_original_region = tapered_data_full\n",
    "    \n",
    "    # Direct comparison: tapered vs original\n",
    "    abs_errors = np.abs(original_data - tapered_original_region)\n",
    "    # normalization\n",
    "    data_range = np.max(original_data) - np.min(original_data)\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance))*100\n",
    "    \n",
    "    # Mean absolute error (MAE), compare to standard deviaiton of original data\n",
    "    mae = np.mean(abs_errors)\n",
    "    std_original = np.std(original_data)\n",
    "    mae_pct_std = (mae / std_original)*100\n",
    "    \n",
    "    passes = pct_within >= 95\n",
    "    \n",
    "    results = {\n",
    "        'padding': padding,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes_pointwise': passes, # pointwise?\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%',\n",
    "        'mean_abs_error': f'{mae: .4f}',\n",
    "        'mae_as_%_of_std': f'{mae_pct_std: .4f}%',\n",
    "        'num_points': len(original_data),\n",
    "        'data_range': f'{data_range: .4f}'}\n",
    "    \n",
    "    return results\n",
    "\n",
    "results_1 = percent_check_tapered(data, tapered_data1, padding1, tolerance=0.05)\n",
    "results_2 = percent_check_tapered(data, tapered_data2_full, padding2, tolerance=0.05)\n",
    "results_3 = percent_check_tapered(data, tapered_data3_full, padding3, tolerance=0.05)\n",
    "print(\"results1:\", results_1)\n",
    "print(\"\")\n",
    "print(\"results2:\", results_2)\n",
    "print(\"\")\n",
    "print(\"results3:\", results_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94efafea-940e-45d4-a74b-29fcdb2d4621",
   "metadata": {},
   "source": [
    "***\n",
    "### Combining Subsampling and Tapering\n",
    "#### Notes:\n",
    "- Tapering with Hann window and using step=562 based on results from percent_check function for subsampled data\n",
    "- Taper applied with no padding to prevent discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3978ed7-4942-44c1-91ad-4e4ab85597df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_step = 562 # data step for subsampling\n",
    "# Tapering Drone Audio:\n",
    "L = len(drone_data['Amplitude'][::sub_step])\n",
    "data = drone_data['Amplitude'][::sub_step].values\n",
    "time_s = drone_data['time_secs'].values\n",
    "# time delta\n",
    "time_delta = (time_s[1] - time_s[0])\n",
    "# 1L taper\n",
    "window1 = hann(L)\n",
    "tapered_sub1 = window1 * data\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(time_s, drone_data['Amplitude'], label=\"Full Data\")\n",
    "plt.plot(time_s[::sub_step], tapered_sub1, label=\"Tapered Data (Step=562)\")\n",
    "plt.title(\"Tapered and Subsampled Drone Audio Data\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb4f97-c4d8-498d-9491-d8013392d3b8",
   "metadata": {},
   "source": [
    "***\n",
    "### Fast Fourier Transform Plots\n",
    "#### Notes:\n",
    "- The fast fourier transform was applied to the original detrended, normalized and shifted time series to obtain magnitude and phase spectra\n",
    "- Only positive frequencies are included in the plots since the input is real and will produce symmetric results\n",
    "- Also applied the fast fourier transform to subsampled and tapered DNS data to plot the resulting magnitude and phase spectra\n",
    "- Change x-limits to zoom in on certain areas\n",
    "<br> Effects of subsampling/tapering:\n",
    "    - Removes higher frequency content\n",
    "    - Reduces spectral leakage caused by discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5f813-98dc-4ce0-9177-4ce8ac16a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hann_window(data):\n",
    "    # Want to apply Hann window and return windowed data with coherent gain factor\n",
    "    window = np.hanning(len(data))\n",
    "    windowed_data = data * window\n",
    "    # Coherent gain for Hann window is 0.5, so need to multiply by 2 later on to make correction\n",
    "    coherent_gain = 0.5\n",
    "    return windowed_data, coherent_gain\n",
    "\n",
    "def subsample_with_antialiasing(data, decimation_factor, sr):\n",
    "    \"\"\"Subsample data using scipy.signal.decimate with anti-aliasing filter.\n",
    "    data: array\n",
    "    decimation_factor: factor by which to reduce sampling rate\n",
    "    sr: Original sampling rate\"\"\"\n",
    "    # scipy.signal.decimate applies an anti-aliasing filter automatically\n",
    "    # Use a higher order filter for better anti-aliasing (default is 8)\n",
    "    decimated_data = scipy.signal.decimate(data, decimation_factor, ftype='iir', zero_phase=True)\n",
    "    # get new sampling rate:\n",
    "    new_sr = sr / decimation_factor\n",
    "    return decimated_data, new_sr\n",
    "\n",
    "def plot_fft2(data, sr, fig1=None, fig2=None, fig3=None, name='', apply_window=True):\n",
    "    \"\"\"Plot FFT with windowing correction.\n",
    "    data: array\n",
    "    sr: Sampling rate\n",
    "    apply_window : bool, says whether to apply Hann window (default True)\"\"\"\n",
    "    n = len(data)\n",
    "    \n",
    "    # Apply window if requested\n",
    "    if apply_window:\n",
    "        windowed_data, coherent_gain = apply_hann_window(data)\n",
    "    else:\n",
    "        windowed_data = data\n",
    "        coherent_gain = 1.0\n",
    "    \n",
    "    # Compute FFT\n",
    "    fft_values = scipy.fft.rfft(windowed_data)\n",
    "    freqs = scipy.fft.rfftfreq(n, d=1/sr)\n",
    "\n",
    "    # magnitudes WITHOUT coherent gain correction\n",
    "    magnitudes = np.abs(fft_values) / n\n",
    "\n",
    "    # Double the AC components (not DC and Nyquist)\n",
    "    magnitudes[1:] *= 2.0\n",
    "\n",
    "    # Undo doubling for Nyquist if even length\n",
    "    if n % 2 == 0:\n",
    "        magnitudes[-1] /= 2.0\n",
    "    \n",
    "    phases = np.angle(fft_values)\n",
    "    \n",
    "    # Create figures:\n",
    "    if fig1 is None:\n",
    "        fig1 = plt.figure(figsize=(10, 6))\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (Linear)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig1.number)\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig2 is None:\n",
    "        fig2 = plt.figure(figsize=(10, 6))\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (log)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig2.number)\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        #plt.axvline(x=15, label='15 Hz', linestyle=\":\", color=\"green\", alpha=0.7)\n",
    "        #plt.axvline(x=30, label='30 Hz', linestyle=\":\", color=\"purple\", alpha=0.7)\n",
    "        plt.legend()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig3 is None:\n",
    "        fig3 = plt.figure(figsize=(10, 6))\n",
    "        plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "        plt.title('Phase Spectrum', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Phase (radians)', fontsize=14)\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        #plt.xlim(-1, 50)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.5)\n",
    "    else:\n",
    "        plt.figure(fig3.number)\n",
    "        plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.8)\n",
    "    \n",
    "    return fig1, fig2, fig3\n",
    " \n",
    "# y_centered = drone_audio_data\n",
    "# sr = sampling_rate\n",
    "decimation_factor = 562  # step for subsampling\n",
    "\n",
    "# For full data\n",
    "fig1, fig2, fig3 = plot_fft2(y_centered, sr, name='Full Data', apply_window=False) #apply_window=False for no tapering\n",
    "\n",
    "# For subsampled data with anti-aliasing\n",
    "tapered_sub1, new_sr = subsample_with_antialiasing(y_centered, decimation_factor, sr)\n",
    "plot_fft2(tapered_sub1, new_sr, fig1=fig1, fig2=fig2, fig3=fig3, name='Subsampled/Tapered Data', apply_window=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66dfee2-e0de-47b1-a93d-17bbe2c90afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original sampling rate: {sr} Hz\")\n",
    "print(f\"Original Nyquist: {sr/2} Hz\")\n",
    "print(f\"Decimation factor: {decimation_factor}\")\n",
    "print(f\"New sampling rate: {new_sr} Hz\")\n",
    "print(f\"New Nyquist: {new_sr/2} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0895a-2b4f-45be-ad37-b6c8940a5208",
   "metadata": {},
   "source": [
    "***\n",
    "### Adding Sine Waves to Full DNS Data\n",
    "#### Notes:\n",
    "- two data columns containing sine waves are added to the data frame containing the full DNS data (not tapered or subsampled yet), along with additional columns for the combined sine waves and the DNS data combined with both sine waves\n",
    "- the first 0.5 second of DNS data is also plotted alongside the individual sine waves before combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629be011-0083-4c05-88f2-b14b4c1b3d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two columns of sine waves to data\n",
    "def add_sine_waves(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    data['time_column'] = np.arange(len(data))\n",
    "    t = data['time_secs'].values\n",
    "    \n",
    "    # Define sine wave parameters\n",
    "    frequencies = {\n",
    "        'Sine 1': 30, # Frequencies in Hz\n",
    "        'Sine 2': 15}\n",
    "    \n",
    "    amplitudes = {\n",
    "        'Sine 1': 0.15,\n",
    "        'Sine 2': 0.15}\n",
    "    \n",
    "    phases = {\n",
    "        'Sine 1': 0,\n",
    "        'Sine 2': 0}\n",
    "    \n",
    "    # Add sine wave columns\n",
    "    for wave_name, freq in frequencies.items():\n",
    "        amplitude = amplitudes[wave_name]\n",
    "        phase = phases[wave_name]\n",
    "        \n",
    "        # Calculate sine wave: A * sin(2π * f * t + φ)\n",
    "        data[wave_name] = amplitude * np.sin(2 * np.pi * freq * t + phase)\n",
    "        \n",
    "    # Add combined sine waves column\n",
    "    sine_columns = list(frequencies.keys())\n",
    "    data['Combined_Sines'] = data[sine_columns].sum(axis=1)\n",
    "\n",
    "    # Add sine waves to original data        \n",
    "    if 'Amplitude' in data.columns:\n",
    "        data['Data_With_Sines'] = data['Amplitude'] + data['Combined_Sines']\n",
    "\n",
    "    return data\n",
    "\n",
    "add_sine_waves(drone_data)\n",
    "# Combined_Sines = Sine 1 + Sine 2\n",
    "# Data_With_Sines = Amplitude + Combined_Sines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8cf4f7-768f-448a-a678-f2eaaa4d6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(add_sine_waves(drone_data).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071bb42-e424-45f0-8cd2-a4b7bea974ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series alongside sine waves\n",
    "data_with_sines = add_sine_waves(drone_data)\n",
    "data_with_sines['time_seconds'] = data_with_sines['time_column'] / sr # to get time in seconds\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_with_sines['time_seconds'][:48000//2], data_with_sines['Amplitude'][:48000//2], label='Time Series', zorder=10) # [start:stop:step]\n",
    "plt.plot(data_with_sines['time_seconds'][:48000//2], data_with_sines['Sine 1'][:48000//2], label='Sine 1')\n",
    "plt.plot(data_with_sines['time_seconds'][:48000//2], data_with_sines['Sine 2'][:48000//2], label='Sine 2', linestyle=\":\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Sine Waves Before Adding to Data (First 0.5 Seconds)\")\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fbd5de-c477-4644-8a44-c7790dd82f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_sines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6104c6a2-173d-4f4b-a8f3-cb1f243b1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_removed = data_with_sines.drop('time_seconds', axis=1) # axis: 1 = columns\n",
    "df_removed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9992306-97b0-4aba-845c-f6b97d547809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_removed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53952998-ffe2-4e84-90e1-83babb22fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a22f27-8aef-49e8-91fc-cfc6abf3bc43",
   "metadata": {},
   "source": [
    "***\n",
    "### Adding Sine Waves to Subsampled/Tapered Time Series\n",
    "#### Notes:\n",
    "- using add_sine_waves function from previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9629f7b-fa4d-4c8e-b7ec-7765b68f280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas data frame from numpy array\n",
    "t_sub_df = pd.DataFrame(tapered_sub1)\n",
    "# need same starting columns to use add_sine_waves\n",
    "t_sub_df.columns = ['Amplitude']\n",
    "time_secs = drone_data.index / sr\n",
    "t_sub_df['time_secs'] = time_secs[::sub_step]\n",
    "t_sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85cb296-5bff-44ab-a8c9-02341daac39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_sine_waves(t_sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa987b68-4d36-47c6-8dda-4a12b093b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_t_sines = add_sine_waves(t_sub_df)\n",
    "\n",
    "# Plot:\n",
    "# (trying plotly again)\n",
    "pre_2sines = go.Figure()\n",
    "pre_2sines.add_trace(go.Scatter(x= list(t_sub_df['time_secs']), y= list(t_sub_df['Amplitude']), mode='lines', \n",
    "                                name='Tapered Time Series (step = 562)', zorder=10))\n",
    "pre_2sines.add_trace(go.Scatter(x= list(t_sub_df['time_secs']), y= list(sub_t_sines['Sine 1']), mode='lines', \n",
    "                                name='Sine 1', line=dict(dash='solid')))\n",
    "pre_2sines.add_trace(go.Scatter(x= list(t_sub_df['time_secs']), y= list(sub_t_sines['Sine 2']), mode='lines', \n",
    "                                name='Sine 2', line=dict(dash='solid')))\n",
    "# Set title\n",
    "pre_2sines.update_layout(title_text=\"Subsampled and Tapered Data Before Adding Sine Waves\", width=1100, height=600, \n",
    "                  xaxis_title='Time (s)', yaxis_title='Amplitude', title_x=0.5, showlegend=True)\n",
    "# Add range slider\n",
    "pre_2sines.update_layout(xaxis=dict(rangeslider=dict(visible=True)))\n",
    "pre_2sines.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(t_sub_df['time_secs'][:48000//100], t_sub_df['Amplitude'][:48000//100], label='Tapered Time Series (step=562)', zorder=10)\n",
    "plt.plot(t_sub_df['time_secs'][:48000//100], sub_t_sines['Sine 1'][:48000//100], label='Sine 1')\n",
    "plt.plot(t_sub_df['time_secs'][:48000//100], sub_t_sines['Sine 2'][:48000//100], label='Sine 2', linestyle=\":\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Sine Waves Before Adding to Data (First 5 Seconds)\")\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# use slider to see more than a green blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297244ec-5804-4c76-9915-9b72c93abbb0",
   "metadata": {},
   "source": [
    "***\n",
    "### Fast Fourier Transform for Full DNS Data with Added Sine Waves\n",
    "#### Notes:\n",
    "- magnitude spectrum for the DNS data combined with two sine waves of differing frequencies\n",
    "- a magnitude spectrum with period on the x-axis instead of frequency is also included\n",
    "- a data step > 1 can be used to make running the code faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c0df1a-7a59-4d49-9f30-6d9b30964f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT plots with sines:\n",
    "def plot_fft_with_sines(data):\n",
    "    data = data.values\n",
    "    n = len(data) # Data points\n",
    "    fft_values = scipy.fft.rfft(data)\n",
    "    freqs = scipy.fft.rfftfreq(n, d = 1/sr) # corresponding frequencies in Hz, d is inverse of sampling frequency\n",
    "    magnitudes = np.abs(fft_values)\n",
    "    phases = np.angle(fft_values)\n",
    "    #step= sr//10\n",
    "    step=1\n",
    "\n",
    "    # remove 0 frequency component to prevent division by zero error:\n",
    "    non_zero_mask = freqs > 0\n",
    "    freqs_plot = freqs[non_zero_mask]\n",
    "    mags_plot = magnitudes[non_zero_mask]\n",
    "    periods_plot = 1/freqs_plot\n",
    "    \n",
    "    # Frequency spectrum (linear)\n",
    "    # plt.figure(figsize=(11, 6)) \n",
    "    # plt.plot(freqs[::step], magnitudes[::step], 'r-', linewidth = 1)\n",
    "    # plt.title('FFT Magnitude Spectrum (Linear)', fontsize=14)\n",
    "    # plt.xlabel('Frequency (Hz)', fontsize=12)\n",
    "    # plt.ylabel('Magnitude', fontsize=12)\n",
    "    # plt.grid(True, which='major' ,alpha=0.5)\n",
    "    # plt.minorticks_on()\n",
    "    # plt.grid(True, which='minor', alpha=0.5)\n",
    "    # plt.xticks(fontsize=12)\n",
    "    # plt.yticks(fontsize=12)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # Frequency spectrum (log)\n",
    "    fig, ax = plt.subplots(figsize=(11, 6))   \n",
    "    plt.semilogy(freqs[1::step], magnitudes[1::step], 'g-', linewidth = 1)\n",
    "    plt.semilogx(freqs[1::step], magnitudes[1::step], 'g-', linewidth = 1)\n",
    "    plt.title('FFT Magnitude Spectrum (log)', fontsize=14)\n",
    "    plt.xlabel('Frequency (Hz)', fontsize=12)\n",
    "    plt.ylabel('Magnitude', fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    #plt.axvline(x=15, color='orange', linestyle='--', label= '15 Hz')\n",
    "    #plt.axvline(x=30, color='blue', linestyle='--', label= '30 Hz')\n",
    "    #plt.legend()\n",
    "    plt.grid(True, which='major', alpha=0.5)\n",
    "    plt.grid(True, which='minor', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Alternative: plot against period instead of frequency\n",
    "    fig, ax = plt.subplots(figsize=(11, 6))\n",
    "    plt.loglog(periods_plot[::step], mags_plot[::step], 'g-', linewidth=1)\n",
    "    plt.title('FFT Magnitude Spectrum (log)', fontsize=14)\n",
    "    plt.xlabel('Period (s)', fontsize=12)\n",
    "    plt.ylabel('Magnitude', fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    #plt.axvline(x=1/100, color='orange', linestyle='--', label= '0.01 s')\n",
    "    #plt.axvline(x=1/200, color='blue', linestyle='--', label= '0.005 s')\n",
    "    #plt.legend()\n",
    "    plt.grid(True, which='major', alpha=0.5)\n",
    "    plt.grid(True, which='minor', alpha=0.5)\n",
    "    ax = plt.gca()\n",
    "    ax.invert_xaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Phase spectrum\n",
    "    # plt.figure(figsize=(11, 6))\n",
    "    # plt.plot(freqs[1::step], phases[1::step], 'm-', linewidth = 1)\n",
    "    # plt.title('Phase Spectrum', fontsize=14)\n",
    "    # plt.xlabel('Frequency (Hz)', fontsize=12)\n",
    "    # plt.ylabel('Phase (radians)', fontsize=12)\n",
    "    # plt.grid(True, alpha=0.5)\n",
    "    # plt.xticks(fontsize=12)\n",
    "    # plt.yticks(fontsize=12)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    return None\n",
    "plot_fft_with_sines(df_removed['Data_With_Sines']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf80136-fa76-4f8e-b5e5-e44bbc0b0df5",
   "metadata": {},
   "source": [
    "***\n",
    "### Fast Fourier Transform for Data with Added Sine Waves\n",
    "#### Notes:\n",
    "- Magnitude and phase spectra for the DNS data combined with two sine waves of differing frequencies\n",
    "- Includes full (blue) and tapered/subsampled (orange) data on the same plot\n",
    "- Calling plot_fft2 function from a previous cell, including Hann window correction factor and scipy.signal.decimate method for subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347e704-f3f9-412c-a751-ca8e08d4fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to fix graph display as before:\n",
    "decimation_factor = 562  # same step for subsampling\n",
    "\n",
    "# For full data\n",
    "fig1, fig2, fig3 = plot_fft2(data_with_sines['Data_With_Sines'].values, sr, name='Full Data', apply_window=False)\n",
    "\n",
    "# For subsampled data with anti-aliasing\n",
    "tapered_sub1, new_sr = subsample_with_antialiasing(data_with_sines['Data_With_Sines'].values, decimation_factor, sr)\n",
    "plot_fft2(tapered_sub1, new_sr, fig1=fig1, fig2=fig2, fig3=fig3, name='Subsampled/Tapered Data', apply_window=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c178dc-9727-424a-8bef-298dc1ee145b",
   "metadata": {},
   "source": [
    "***\n",
    "### Continuous Wavelet Transform\n",
    "#### Notes:\n",
    "- the Morlet wavelet, given by $\\psi(t)=\\exp(\\frac{-t^2}{2})\\cos(5t)$, is used for the wavelet transform\n",
    "- scalograms are created using the full DNS data and the full DNS data combined with sine waves\n",
    "- histograms of scalogram magnitudes are also plotted showing the probability density corresponding to certain magnitude ranges in addition to other statistics (i.e. mean, median, mode, etc.)\n",
    "- a difference map was also created to compare scalograms\n",
    "- scales have been determined based on the formula $f=\\frac{F_c}{a\\cdot\\Delta t}$, where $f$ is the pseudo-frequency corresponding to the scale, $F_c$ is the approx. center frequency of the wavelet, $a$ is the wavelet scale, and $\\Delta t$ is the sampling period of the signal\n",
    "- additionally, scales are chosen so that the frequency range of the plots do not exceed the Nyquist frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7cd81-cf15-4627-be2e-aae7c0dd1e53",
   "metadata": {},
   "source": [
    "### Increasing Scalogram Frequency Resolution\n",
    "#### Notes:\n",
    "- **goal**: increase frequency resolution of scalograms\n",
    "  \n",
    "    **Consequences of increasing frequency resolution:**\n",
    "    - increasing the frequency resolution will decrease the time resolution\n",
    "    - will change appearance of added sine waves\n",
    "      \n",
    "    <br>**Possible Methods for increasing frequency resolution:**\n",
    "    - increasing the number of scales will provide more frequency bins to sample, which will show finer differences between frequencies\n",
    "    - Adjust spacing to linear instead of logarithmic and focus on a specific frequency range of interest\n",
    "    - Decrease time resolution\n",
    "      <br>**Effective Methods:**\n",
    "      - Increasing the number of scales showed a slight difference compared to the starting scalogram\n",
    "      - Decreasing time resolution by applying a uniform filter from scipy.ndimage had the greatest effect\n",
    "          - The filter is set up to only smooth in time and leave frequency unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd80cd0c-f716-450e-8a34-d835e69fedd2",
   "metadata": {},
   "source": [
    "#### DNS Data Without Added Sine Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2dc0ab-b63b-486a-80de-03d998f07a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous Wavelet Transform (without sine waves added)\n",
    "step=20 # step added to reduce cell run time\n",
    "data = drone_data['Amplitude'].values[::step]\n",
    "data = data.flatten()\n",
    "print(f\"Data shape: {data.shape}\") # Check data shape\n",
    "\n",
    "drone_data['time_column'] = np.arange(len(drone_data))\n",
    "drone_data['time_seconds'] = drone_data['time_column'] / sr # to get time in seconds\n",
    "t = drone_data['time_seconds'].values[::step]\n",
    "dt = t[1] - t[0]  # Time step in seconds\n",
    "print(f\"dt: {dt}\")\n",
    "print(f\"Data step: {step}\")\n",
    "\n",
    "# Convert frequencies to scales: scale = ~center_freq / (a * dt)\n",
    "# center frequency for Morlet wavelet ~1.0\n",
    "scale_min = 1.0 / (250 * dt)  # Small scale for high freq, use freq_max=250\n",
    "scale_max = 1.0 / (10 * dt)  # Large scale for low freq, use freq_min=10\n",
    "scales = np.logspace(np.log10(scale_min), np.log10(scale_max), 60) # increased number of scales\n",
    "# Wavelet transform:\n",
    "coefficients, frequencies = pywt.cwt(data, scales, 'morl', sampling_period=dt)\n",
    "print(f\"Coefficients shape: {coefficients.shape}\")\n",
    "print(f\"Frequency range: {frequencies.min():.2f} to {frequencies.max():.2f} Hz\")\n",
    "\n",
    "# Smooth only in the TIME direction (axis=1), not frequency (axis=0)\n",
    "smoothed_coefficients = uniform_filter(np.abs(coefficients), size=(1, 50))\n",
    "\n",
    "# Plot:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.pcolormesh(t, frequencies, np.log10(smoothed_coefficients), cmap='plasma', shading='auto', vmin=-5)\n",
    "plt.colorbar(label='log\\u2081\\u2080(Magnitude)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title('Drone Audio')\n",
    "plt.show()\n",
    "\n",
    "# Try to make histogram:\n",
    "magnitudes = smoothed_coefficients\n",
    "magnitude_values = magnitudes.flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "plt.hist(magnitude_values, bins=50, density = True, facecolor='skyblue', edgecolor='grey')\n",
    "plt.title(\"Histogram of Scalogram Magnitudes\")\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.yscale('log')\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.axvline(x=np.mean(magnitude_values), color='r', linestyle='--', label=f'Mean: {np.mean(magnitude_values): .2e}')\n",
    "plt.axvline(x=np.median(magnitude_values), color='orange', linestyle='--', label=f'Median: {np.median(magnitude_values): .2e}')\n",
    "# get mode:\n",
    "hist_counts, bin_edges = np.histogram(magnitude_values, bins=50)\n",
    "mode_bin_index = np.argmax(hist_counts)\n",
    "# Mode is the center of the bin with the highest count:\n",
    "mode_value = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "plt.axvline(x=mode_value, color='b', linestyle='--', label=f'Mode: {mode_value: .2e}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(ss.describe(magnitude_values))\n",
    "std_dev = np.std(magnitude_values)\n",
    "print(f\"Standard Deviation: {std_dev:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7a54b-2c96-4c0d-900b-97affb5a5367",
   "metadata": {},
   "source": [
    "#### DNS Data With Added Sine Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3ad28-527e-4edd-bbb0-e74ce7a5cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous Wavelet Transform (with sine waves added)\n",
    "step=20 # step added to reduce cell run time\n",
    "data = data_with_sines['Data_With_Sines'].values[::step]\n",
    "data = data.flatten()  # Need data to be 1D\n",
    "print(f\"Data shape: {data.shape}\") # Check data shape\n",
    "t = data_with_sines['time_seconds'].values[::step]\n",
    "dt = t[1] - t[0]  # Time step in seconds\n",
    "print(f\"Data step: {step}\")\n",
    "\n",
    "# Convert frequencies to scales: scale = ~center_freq / (a * dt)\n",
    "scales=np.logspace(np.log10(1.0/(250*dt)), np.log10(1.0/(10*dt)), 60)\n",
    "coefficients1, frequencies = pywt.cwt(data, scales, 'morl', sampling_period=dt)\n",
    "\n",
    "print(f\"Scale range: {scale_min:.6f} to {scale_max:.6f}\")\n",
    "print(f\"Frequency range: {frequencies.min():.2f} to {frequencies.max():.2f} Hz\")\n",
    "\n",
    "# Smooth only in the TIME direction (axis=1), not frequency (axis=0)\n",
    "coefficients_smoothed = uniform_filter(np.abs(coefficients1), size=(1, 50))\n",
    "\n",
    "# Plot:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.pcolormesh(t, frequencies, np.abs(coefficients_smoothed), cmap='plasma', shading='auto', vmax=2.0) \n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title('Drone Audio Scalogram With Sines Added')\n",
    "plt.show()\n",
    "\n",
    "# Make histogram:\n",
    "magnitudes = np.abs(coefficients_smoothed)\n",
    "magnitude_values = magnitudes.flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "plt.hist(magnitude_values, bins=50, density = True, facecolor='skyblue', edgecolor='grey')\n",
    "plt.title(\"Histogram of Scalogram Magnitudes\")\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.yscale('log')\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.axvline(x=np.mean(magnitude_values), color='r', linestyle='--', label=f'Mean: {np.mean(magnitude_values): .2e}')\n",
    "plt.axvline(x=np.median(magnitude_values), color='orange', linestyle='--', label=f'Median: {np.median(magnitude_values): .2e}')\n",
    "# get mode:\n",
    "hist_counts, bin_edges = np.histogram(magnitude_values, bins=50)\n",
    "mode_bin_index = np.argmax(hist_counts)\n",
    "# Mode is the center of the bin with the highest count:\n",
    "mode_value = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "plt.axvline(x=mode_value, color='b', linestyle='--', label=f'Mode: {mode_value: .2e}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(ss.describe(magnitude_values))\n",
    "std_dev = np.std(magnitude_values)\n",
    "print(f\"Standard Deviation: {std_dev:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154afb9-3fee-4e4d-a6d7-1a52a2036408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference map for full data plots\n",
    "# difference map for sub/tap with(out) sine waves\n",
    "data_original = drone_data['Amplitude'].values[::20].flatten() # WITHOUT sine waves\n",
    "data_sines = data_with_sines['Data_With_Sines'].values[::20].flatten() # WITH sine waves\n",
    "# time:\n",
    "t = data_with_sines['time_seconds'].values[::20]\n",
    "dt = t[1] - t[0]  # Time step in seconds\n",
    "print(f\"dt: {dt}\")\n",
    "\n",
    "scales = np.logspace(np.log10(1.0/(250*dt)), np.log10(1.0/(10*dt)), 60)\n",
    "# Verify that this gives you the right frequency range:\n",
    "test_freqs = pywt.scale2frequency('morl', scales) / dt # used to fix display problem\n",
    "print(f\"Expected frequency range: {test_freqs.min():.2f} to {test_freqs.max():.2f} Hz\")\n",
    "# CWT\n",
    "sines_coeffs, sines_freqs = pywt.cwt(data_sines, scales, 'morl', sampling_period=delta_t)\n",
    "coeffs_orig, freqs_orig = pywt.cwt(data_original, scales, 'morl', sampling_period=delta_t)\n",
    "# Smooth only in the TIME direction (axis=1), not frequency (axis=0)\n",
    "coefficients_smoothed = uniform_filter(np.abs(sines_coeffs), size=(1, 50))\n",
    "smoothed_coefficients = uniform_filter(np.abs(coeffs_orig), size=(1, 50))\n",
    "\n",
    "# Plot:\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "# Scalogram 1 - use log scale like original\n",
    "im1 = axes[0].pcolormesh(t, test_freqs, np.log10(smoothed_coefficients), cmap='plasma', shading='auto', vmin=-5)\n",
    "axes[0].set_title('Scalogram 1')\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('Frequency (Hz)')\n",
    "axes[0].set_yscale('log')  # Use log scale for frequency axis\n",
    "plt.colorbar(im1, ax=axes[0], label='log\\u2081\\u2080(Magnitude)')\n",
    "\n",
    "# Scalogram 2 - linear scale\n",
    "im2 = axes[1].pcolormesh(t, test_freqs, np.abs(coefficients_smoothed), cmap='plasma', shading='auto', vmax=2.0)\n",
    "axes[1].set_title('Scalogram 2')\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_ylabel('Frequency (Hz)')\n",
    "axes[1].axhline(y=15, linestyle=\"--\", color='white')\n",
    "axes[1].axhline(y=30, linestyle=\"--\", color='cyan')\n",
    "axes[1].set_yscale('log')\n",
    "plt.colorbar(im2, ax=axes[1], label='Magnitude')\n",
    "\n",
    "# Normalize each scalogram\n",
    "coeff_norm = (np.abs(smoothed_coefficients) - np.abs(smoothed_coefficients).min()) / (np.abs(smoothed_coefficients).max() - np.abs(smoothed_coefficients).min())\n",
    "coeff1_norm = (np.abs(coefficients_smoothed) - np.abs(coefficients_smoothed).min()) / (np.abs(coefficients_smoothed).max() - np.abs(coefficients_smoothed).min())\n",
    "\n",
    "difference = coeff_norm - coeff1_norm\n",
    "# Difference map\n",
    "max_diff = np.max(np.abs(difference))\n",
    "im3 = axes[2].pcolormesh(t, test_freqs, difference, cmap='RdBu', vmin=-max_diff, vmax=max_diff, shading='auto')\n",
    "axes[2].set_title('Difference (1 - 2)')\n",
    "axes[2].set_xlabel('Time (s)')\n",
    "axes[2].set_ylabel('Frequency (Hz)')\n",
    "axes[2].set_yscale('log')\n",
    "plt.colorbar(im3, ax=axes[2], label='Difference')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6780ddc-87a4-4de9-b537-5a016e82c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Frequency range: {freqs_orig.min():.2f} to {freqs_orig.max():.2f} Hz\")\n",
    "print(f\"Number of frequency bins: {len(freqs_orig)}\")\n",
    "print(f\"Frequencies near 15 Hz: {freqs_orig[(freqs_orig > 14) & (freqs_orig < 16)]}\")\n",
    "print(f\"Frequencies near 30 Hz: {freqs_orig[(freqs_orig > 29) & (freqs_orig < 31)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74838ed4-30c2-444f-9951-b494d7bba7db",
   "metadata": {},
   "source": [
    "#### Subsampled and Tapered DNS Data Without Added Sine Waves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef33c2-19aa-413e-9e07-c47d854e2836",
   "metadata": {},
   "source": [
    "##### Add corrections for Hann window coherent gain and subsample with anti-aliasing filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e150d-8c7a-4617-890d-0b31cb84fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hann_window(data):\n",
    "    # Want to apply Hann window and return windowed data with coherent gain factor\n",
    "    window = np.hanning(len(data))\n",
    "    windowed_data = data * window\n",
    "    # Coherent gain for Hann window is 0.5, so need to multiply by 2 to make correction\n",
    "    coherent_gain = 0.5\n",
    "    return windowed_data/coherent_gain\n",
    "\n",
    "def subsample_with_antialiasing(data, decimation_factor, sr):\n",
    "    \"\"\"Subsample data using scipy.signal.decimate with anti-aliasing filter.\n",
    "    data: array\n",
    "    decimation_factor: factor by which to reduce sampling rate\n",
    "    sr: Original sampling rate\"\"\"\n",
    "    # scipy.signal.decimate applies an anti-aliasing filter automatically\n",
    "    # Use a higher order filter for better anti-aliasing (default is 8)\n",
    "    decimated_data = scipy.signal.decimate(data, decimation_factor, ftype='iir', zero_phase=True)\n",
    "    # get new sampling rate:\n",
    "    new_sr = sr / decimation_factor\n",
    "    return decimated_data\n",
    "\n",
    "hann_windowed_data = apply_hann_window(drone_data['Amplitude'].values)\n",
    "hann_windowed_sines = apply_hann_window(data_with_sines['Data_With_Sines'].values)\n",
    "subsample_with_antialiasing(hann_windowed_data, 562, sr)\n",
    "subsample_with_antialiasing(hann_windowed_sines, 562, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d8dec0-25a5-4c97-9b99-b71a6a3722e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsampled/tapered without sine waves:\n",
    "#sub_tap_data = sub_t_sines['Amplitude'].values.flatten()\n",
    "sub_tap_data = subsample_with_antialiasing(hann_windowed_data, 562, sr)\n",
    "# time:\n",
    "time_in_sec = sub_t_sines['time_secs'].values\n",
    "subsampling_interval = 562\n",
    "delta_t = time_in_sec[1] - time_in_sec[0]  # Time step in seconds\n",
    "print(\"delta_t:\", delta_t)\n",
    "\n",
    "freq_max = 50 # below Nyquist limit of ~42\n",
    "scale_min = 1.0/(freq_max*delta_t)\n",
    "scales=np.logspace(np.log10(scale_min), np.log10(1.0/(5*delta_t)), 60)\n",
    "# CWT\n",
    "subt_coeffs, subt_freqs = pywt.cwt(sub_tap_data, scales, 'morl', sampling_period=delta_t)\n",
    "print(f\"Coefficients shape: {subt_coeffs.shape}\")\n",
    "print(f\"Frequency range: {subt_freqs.min():.2f} to {subt_freqs.max():.2f} Hz\")\n",
    "\n",
    "subt_smoothed_coefficients = uniform_filter(np.abs(subt_coeffs), size=(1, 50))\n",
    "\n",
    "# Plot:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.pcolormesh(time_in_sec, subt_freqs, np.log10(np.abs(subt_smoothed_coefficients)), cmap='plasma', shading='auto', vmin=-5)\n",
    "plt.colorbar(label='log\\u2081\\u2080(Magnitude)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.yscale('log')\n",
    "plt.yticks(minor=True)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title('Subsampled and Tapered Drone Audio')\n",
    "plt.show()\n",
    "\n",
    "# Make histogram:\n",
    "magnitudes = np.abs(subt_smoothed_coefficients)\n",
    "magnitude_values = magnitudes.flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "plt.hist(magnitude_values, bins=50, density = True, facecolor='skyblue', edgecolor='grey')\n",
    "plt.title(\"Histogram of Scalogram Magnitudes\")\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.yscale('log')\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.axvline(x=np.mean(magnitude_values), color='r', linestyle='--', label=f'Mean: {np.mean(magnitude_values): .2e}')\n",
    "plt.axvline(x=np.median(magnitude_values), color='orange', linestyle='--', label=f'Median: {np.median(magnitude_values): .2e}')\n",
    "# get mode:\n",
    "hist_counts, bin_edges = np.histogram(magnitude_values, bins=50)\n",
    "mode_bin_index = np.argmax(hist_counts)\n",
    "# Mode is the center of the bin with the highest count:\n",
    "mode_value = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "plt.axvline(x=mode_value, color='b', linestyle='--', label=f'Mode: {mode_value: .2e}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(ss.describe(magnitude_values))\n",
    "std_dev = np.std(magnitude_values)\n",
    "print(f\"Standard Deviation: {std_dev:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d170b-1a31-4fbe-97fa-f1967fd4b129",
   "metadata": {},
   "source": [
    "#### Subsampled and Tapered DNS Data With Added Sine Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef8c557-f956-4046-b657-381a63174c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsampled/tapered WITH sine waves:\n",
    "#sub_tap_with_sines = sub_t_sines['Data_With_Sines'].values.flatten()\n",
    "sub_tap_with_sines = subsample_with_antialiasing(hann_windowed_sines, 562, sr)\n",
    "\n",
    "# time:\n",
    "time_in_sec = sub_t_sines['time_secs'].values\n",
    "subsampling_interval = 562\n",
    "delta_t = time_in_sec[1] - time_in_sec[0]  # Time step in seconds\n",
    "print(\"delta_t:\", delta_t)\n",
    "\n",
    "freq_max = 50 # to get freq range below Nyquist limit of ~42\n",
    "scale_min = 1.0/(freq_max*delta_t)\n",
    "scales=np.logspace(np.log10(scale_min), np.log10(1.0/(5*delta_t)), 60)\n",
    "# CWT\n",
    "subt_sines_coeffs, subt_sines_freqs = pywt.cwt(sub_tap_with_sines, scales, 'morl', sampling_period=delta_t)\n",
    "print(f\"Coefficients shape: {subt_sines_coeffs.shape}\")\n",
    "print(f\"Frequency range: {subt_sines_freqs.min():.2f} to {subt_sines_freqs.max():.2f} Hz\")\n",
    "\n",
    "tsub_smoothed_coefficients = uniform_filter(np.abs(subt_sines_coeffs), size=(1, 50))\n",
    "\n",
    "# Plot:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.pcolormesh(time_in_sec, subt_sines_freqs, np.abs(tsub_smoothed_coefficients), cmap='plasma', shading='auto')\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title('Subsampled and Tapered Drone Audio With Added Sines')\n",
    "plt.show()\n",
    "\n",
    "# Try to make histogram:\n",
    "magnitudes = np.abs(tsub_smoothed_coefficients)\n",
    "magnitude_values = magnitudes.flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "plt.hist(magnitude_values, bins=50, density = True, facecolor='skyblue', edgecolor='grey')\n",
    "plt.title(\"Histogram of Scalogram Magnitudes\")\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.yscale('log')\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.axvline(x=np.mean(magnitude_values), color='r', linestyle='--', label=f'Mean: {np.mean(magnitude_values): .2e}')\n",
    "plt.axvline(x=np.median(magnitude_values), color='orange', linestyle='--', label=f'Median: {np.median(magnitude_values): .2e}')\n",
    "# get mode:\n",
    "hist_counts, bin_edges = np.histogram(magnitude_values, bins=50)\n",
    "mode_bin_index = np.argmax(hist_counts)\n",
    "# Mode is the center of the bin with the highest count:\n",
    "mode_value = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "plt.axvline(x=mode_value, color='b', linestyle='--', label=f'Mode: {mode_value: .2e}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(ss.describe(magnitude_values))\n",
    "std_dev = np.std(magnitude_values)\n",
    "print(f\"Standard Deviation: {std_dev:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf116684-1e8d-4f5f-8d56-b418e95d68d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference maps again\n",
    "# difference map for sub/tap with(out) sine waves\n",
    "subt_original = subsample_with_antialiasing(hann_windowed_data, 562, sr) # WITHOUT sine waves\n",
    "subt_with_sines = subsample_with_antialiasing(hann_windowed_sines, 562, sr) # WITH sine waves\n",
    "# time:\n",
    "time_in_sec = sub_t_sines['time_secs'].values\n",
    "subsampling_interval = 562\n",
    "delta_t = time_in_sec[1] - time_in_sec[0]  # Time step in seconds\n",
    "\n",
    "\n",
    "freq_max = 50 # to get freq range below Nyquist limit of ~42\n",
    "scale_min = 1.0/(freq_max*delta_t)\n",
    "scales=np.logspace(np.log10(scale_min), np.log10(1.0/(5*delta_t)), 60) # increase number of scales\n",
    "\n",
    "# CWT\n",
    "sub_t_sines_coeffs, sub_t_sines_freqs = pywt.cwt(subt_with_sines, scales, 'morl', sampling_period=delta_t)\n",
    "coefficients_smoothed = uniform_filter(np.abs(sub_t_sines_coeffs), size=(1, 50))\n",
    "sub_t_coeffs, sub_t_freqs = pywt.cwt(subt_original, scales, 'morl', sampling_period=delta_t)\n",
    "# Smooth only in the TIME direction (axis=1), not frequency (axis=0)\n",
    "smoothed_coefficients = uniform_filter(np.abs(sub_t_coeffs), size=(1, 50))\n",
    "\n",
    "# Plot:\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "# Scalogram 1 - use log scale like original\n",
    "im1 = axes[0].pcolormesh(time_in_sec, sub_t_freqs, np.log10(smoothed_coefficients), cmap='plasma', shading='auto', vmin=-5)\n",
    "axes[0].set_title('Scalogram 1')\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('Frequency (Hz)')\n",
    "axes[0].set_yscale('log')  # Use log scale for frequency axis\n",
    "plt.colorbar(im1, ax=axes[0], label='log\\u2081\\u2080(Magnitude)')\n",
    "\n",
    "# Scalogram 2 - linear scale\n",
    "im2 = axes[1].pcolormesh(time_in_sec, sub_t_sines_freqs, np.abs(coefficients_smoothed), cmap='plasma', shading='auto')\n",
    "axes[1].set_title('Scalogram 2')\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_ylabel('Frequency (Hz)')\n",
    "axes[1].set_yscale('log')\n",
    "plt.colorbar(im2, ax=axes[1], label='Magnitude')\n",
    "\n",
    "# Normalize each scalogram\n",
    "coeff_norm = (np.abs(smoothed_coefficients) - np.abs(smoothed_coefficients).min()) / (np.abs(smoothed_coefficients).max() - np.abs(smoothed_coefficients).min())\n",
    "coeff1_norm = (np.abs(coefficients_smoothed) - np.abs(coefficients_smoothed).min()) / (np.abs(coefficients_smoothed).max() - np.abs(coefficients_smoothed).min())\n",
    "\n",
    "difference = coeff_norm - coeff1_norm\n",
    "# Difference map\n",
    "max_diff = np.max(np.abs(difference))\n",
    "im3 = axes[2].pcolormesh(time_in_sec, sub_t_freqs, difference, cmap='RdBu', vmin=-max_diff, vmax=max_diff, shading='auto')\n",
    "axes[2].set_title('Difference (1 - 2)')\n",
    "axes[2].set_xlabel('Time (s)')\n",
    "axes[2].set_ylabel('Frequency (Hz)')\n",
    "axes[2].set_yscale('log')\n",
    "plt.colorbar(im3, ax=axes[2], label='Difference')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
