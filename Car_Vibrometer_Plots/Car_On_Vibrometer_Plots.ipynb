{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ea31e5-537e-4231-8632-8cdf1526df40",
   "metadata": {},
   "source": [
    "### Vibrometer Measurements of Car\n",
    "##### Measurement Summary:\n",
    "- car off\n",
    "- **car on**\n",
    "- **car on, music playing**\n",
    "- revving car engine\n",
    "\n",
    "This notebook creates plots for when the car is on/not playing music and when it is on/playing music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55cbd5-dd25-45c8-9e1e-e391c22bc96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import scipy.stats as ss\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.fft\n",
    "import pywt\n",
    "from scipy.signal.windows import hann\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage import uniform_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310630f4-b50d-49da-acca-da07a222d071",
   "metadata": {},
   "source": [
    "***\n",
    "### Car on, no music\n",
    "##### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774877a-a3c9-4d96-b653-b7a936043018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "# (make sure the .ipynb file is in the same folder as the data)\n",
    "column_names1 = ['Time1 (s)', 'Signal1 (m)']\n",
    "df1 = pd.read_table(\"oncar1.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names1)\n",
    "#print(df1.head())\n",
    "\n",
    "column_names2 = ['Time2 (s)', 'Signal2 (m)']\n",
    "df2 = pd.read_table(\"caron2.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names2)\n",
    "#print(df2.head())\n",
    "\n",
    "column_names3 = ['Time3 (s)', 'Signal3 (m)']\n",
    "df3 = pd.read_table(\"caron3.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names3)\n",
    "#print(df3.head())\n",
    "\n",
    "column_names4 = ['Time4 (s)', 'Signal4 (m)']\n",
    "df4 = pd.read_table(\"caron4.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names4)\n",
    "#print(df4.head())\n",
    "\n",
    "column_names5 = ['Time5 (s)', 'Signal5 (m)']\n",
    "df5 = pd.read_table(\"caron5.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names5)\n",
    "#print(df5.head())\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Then file naming convention changes... Clarify with Mika\n",
    "column_names6 = ['Time6 (s)', 'Signal6 (m)']\n",
    "df6 = pd.read_table(\"caronr1.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names6)\n",
    "\n",
    "column_names7 = ['Time7 (s)', 'Signal7 (m)']\n",
    "df7 = pd.read_table(\"caronr2.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names7)\n",
    "\n",
    "column_names8 = ['Time8 (s)', 'Signal8 (m)']\n",
    "df8 = pd.read_table(\"caronr3.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names8)\n",
    "\n",
    "column_names9 = ['Time9 (s)', 'Signal9 (m)']\n",
    "df9 = pd.read_table(\"caronw1.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names9)\n",
    "\n",
    "column_names10 = ['Time10 (s)', 'Signal10 (m)']\n",
    "df10 = pd.read_table(\"caronw2.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names10)\n",
    "\n",
    "column_names11 = ['Time11 (s)', 'Signal11 (m)']\n",
    "df11 = pd.read_table(\"caronw3.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37adafd7-8bcb-4ec9-b50d-20d0fca07c79",
   "metadata": {},
   "source": [
    "##### Plot Time Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2aede4-8c04-47c3-830d-1e2658fcddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_on_dataframes = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11] # add more after loading more dataframes\n",
    "for i, dframe in enumerate(car_on_dataframes):\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    signal_column = f\"Signal{i+1} (m)\"\n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[signal_column], label=f\"Car On Measurement {i+1} - Full Data\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True,alpha=0.5)\n",
    "    plt.title(f\"Car On Measurement {i+1} - Full Data\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc286f-4485-47ce-86f8-ea6749d52c26",
   "metadata": {},
   "source": [
    "##### Detrending and Shifting Data to Zero Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e59250-f0f6-497c-be73-293c5974ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dframe in enumerate(car_on_dataframes):\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    signal_column = f\"Signal{i+1} (m)\"\n",
    "    detrended_signal_column = f\"Signal{i+1} Detrended (m)\"\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    \n",
    "    # Detrend\n",
    "    dframe[detrended_signal_column] = signal.detrend(dframe[signal_column], type='linear') \n",
    "    # Shift Mean to ~Zero (without normalizing)\n",
    "    dframe[mean_shifted_column] = dframe[detrended_signal_column] - dframe[detrended_signal_column].mean()\n",
    "\n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Car On Measurement {i+1} - Full Data\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True,alpha=0.5)\n",
    "    plt.axhline(y=0.0, label=\"0.0\", color='red', linestyle=\":\")\n",
    "    plt.title(f\"Car On Measurement {i+1} - Detrended and Shifted to Zero Mean\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4fb98a-7410-4ad5-820e-fbcda4a13e7d",
   "metadata": {},
   "source": [
    "##### Tapering Detrended and Shifted (DS) Time Series\n",
    "- A Hann window is used for tapering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03daf3ec-c31c-435e-aab4-7bc88427c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hann_window(data, column):\n",
    "    window = np.hanning(len(data))\n",
    "    windowed_data = data[column] * window\n",
    "    return windowed_data\n",
    "    \n",
    "for i, dframe in enumerate(car_on_dataframes):\n",
    "    tapered_data = []\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    hann_result = apply_hann_window(dframe, mean_shifted_column) # taper all dataframes\n",
    "    tapered_data.append(hann_result)\n",
    "    time_column = f\"Time{i+1} (s)\" # need time column for plotting\n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Full Data\")\n",
    "    plt.plot(dframe[time_column], tapered_data[-1], label=f\"Tapered Data\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True,alpha=0.5)\n",
    "    plt.title(f\"Car On Measurement {i+1} - Full and Tapered DS Data\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81edfdb3-d45a-4d24-988e-d370052cd231",
   "metadata": {},
   "source": [
    "##### 'percent_check' function for tapering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea31489-bea2-4b30-8ddd-9a62662a1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_check_tapered(original_data, tapered_data_full, padding, tolerance=0.05):\n",
    "    \"\"\"original_data : Original unpadded time series (array)\n",
    "    tapered_data_full : Tapered time series, includes padding (array)\n",
    "    padding : Amount of padding added to each end (int)\n",
    "    tolerance : Acceptable error as fraction of data range (float)\"\"\"\n",
    "    # Extract original from tapered data (remove padding)\n",
    "    if padding > 0:\n",
    "        tapered_original_region = tapered_data_full[padding:-padding]\n",
    "    else:\n",
    "        tapered_original_region = tapered_data_full\n",
    "    \n",
    "    # Direct comparison: tapered vs original\n",
    "    abs_errors = np.abs(original_data - tapered_original_region)\n",
    "    # normalization\n",
    "    data_range = np.max(original_data) - np.min(original_data)\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    # Calculate metrics\n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance))*100\n",
    "    \n",
    "    # Mean Absolute Error (MAE) metrics\n",
    "    mae = np.mean(abs_errors)\n",
    "    std_original = np.std(original_data)\n",
    "    mae_pct_std = (mae / std_original)*100\n",
    "    \n",
    "    passes = pct_within >= 95\n",
    "    \n",
    "    results = {'padding': padding,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes': passes,\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%',\n",
    "        'mean_abs_error': f'{mae: .4f}',\n",
    "        'mae_as_%_of_std': f'{mae_pct_std: .4f}%',\n",
    "        'num_points': len(original_data),\n",
    "        'data_range': f'{data_range: .4f}'}\n",
    "    \n",
    "    return results\n",
    "    \n",
    "for i, dframe in enumerate(car_on_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    tapered_data = []\n",
    "    hann_result = apply_hann_window(dframe, mean_shifted_column) # taper all dataframes\n",
    "    tapered_data.append(hann_result)\n",
    "    percent_check_tapered_results = percent_check_tapered(dframe[mean_shifted_column], tapered_data[-1], padding=0, tolerance=0.05)\n",
    "    print(f\"dataframe: df{i+1}\")\n",
    "    print(percent_check_tapered_results)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c2ebb-10a8-4be9-aa3c-4fb34980efe2",
   "metadata": {},
   "source": [
    "##### Subsampling DS Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0198f61d-6ed6-4452-93a5-955918ee43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling the tapered time series\n",
    "#Sampling Rate = Total Number of Samples / Total Time (in seconds)\n",
    "def subsample(data, column, decimation_factor):\n",
    "    \"\"\"Subsample data using scipy.signal.decimate with anti-aliasing filter.\n",
    "    data: input data e.g. df1\n",
    "    column: column to subsample (e.g. \"Signal1 Zero Mean (m)\"), string\n",
    "    decimation_factor: factor by which to reduce sampling rate\"\"\"\n",
    "    num_samples=len(data[column])\n",
    "    sampling_time=data.iloc[-1, 0] #get last value in first column (time (s))\n",
    "    original_sampling_rate = int(num_samples/sampling_time)\n",
    "    print(f\"Original sampling rate for {column}: {original_sampling_rate} Hz\")\n",
    "    # scipy.signal.decimate applies an anti-aliasing filter automatically\n",
    "    # Use a higher order filter for better anti-aliasing (default is 8)\n",
    "    decimated_data = scipy.signal.decimate(data[column], decimation_factor, ftype='iir', zero_phase=True) # \n",
    "    # get new sampling rate:\n",
    "    new_sr = int(original_sampling_rate / decimation_factor)\n",
    "    print(f\"New sampling rate for {column}: {new_sr} Hz\")\n",
    "    return decimated_data, new_sr, original_sampling_rate\n",
    "\n",
    "for i, dframe in enumerate(car_on_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    subsample_result = subsample(dframe, mean_shifted_column, decimation_factor=50)\n",
    "    subsampled_data = subsample_result[0]\n",
    "    # sub_list = []\n",
    "    # sub_list.append(subsampled_data)\n",
    "    \n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Full Data\")\n",
    "    plt.plot(dframe[time_column][::50], subsampled_data, label=f\"Subsampled Data\") # Make sure time step is same as decimation_factor\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True, alpha=0.5)\n",
    "    plt.title(f\"Car On Measurement {i+1} - Full and Subsampled DS Data\")\n",
    "    plt.legend()\n",
    "    #plt.xlim(4,5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb514c-2928-457d-a6a0-2ed2495500d0",
   "metadata": {},
   "source": [
    "##### 'percent_check' function for subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05bc6cb-32c1-4d8f-a447-6df684aedc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_check_scipy_decimate(data, column, step, tolerance=0.05):\n",
    "    x_original = np.arange(len(data))\n",
    "    y_original = data[column].values\n",
    "    \n",
    "    # Get subsampled series\n",
    "    x_subsampled = np.arange(0, len(data), step)\n",
    "    y_subsampled=scipy.signal.decimate(data[column].values, step, ftype='iir', zero_phase=True)\n",
    "    \n",
    "    # Interpolate subsampled data back to original timestamps\n",
    "    f_interp = interpolate.interp1d(x_subsampled, y_subsampled, kind='linear', fill_value='extrapolate')\n",
    "    y_reconstructed = f_interp(x_original)\n",
    "    \n",
    "    # Calculate absolute errors\n",
    "    abs_errors = np.abs(y_original - y_reconstructed)\n",
    "    \n",
    "    # Calculate data range (the scale of the data)\n",
    "    data_range = np.max(y_original) - np.min(y_original)\n",
    "    #print(\"data_range:\", data_range)\n",
    "    # Normalize errors by data range instead of individual values\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    # Test if within tolerance\n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance)) * 100\n",
    "    \n",
    "    # Overall pass/fail\n",
    "    passes = pct_within >= 95  # At least 95% of points within tolerance\n",
    "    \n",
    "    results = {'step': step,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes': passes,\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'num_original_points': len(y_original),\n",
    "        'num_subsampled_points': len(y_subsampled),\n",
    "        'data_range': f'{data_range: .4f}',  \n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%' }\n",
    "    return results\n",
    "\n",
    "for i, dframe in enumerate(car_on_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    print(f\"dataframe: df{i+1}\")\n",
    "    scipy_decimate_pct_check_results = percent_check_scipy_decimate(dframe, mean_shifted_column, step=50, tolerance=0.05)\n",
    "    print(scipy_decimate_pct_check_results)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a2b8b-fb44-4f2e-9433-9dee58d390fb",
   "metadata": {},
   "source": [
    "##### Subsampling the Tapered DS Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14327d8b-d2aa-4cf6-acf9-3aa70fcce31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_tapered(tapered_data, decimation_factor):\n",
    "    sub_tap_data = scipy.signal.decimate(tapered_data, decimation_factor, ftype='iir', zero_phase=True)\n",
    "    return sub_tap_data\n",
    "\n",
    "for i, dframe in enumerate(car_on_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    sub_tap_result = sub_tapered(apply_hann_window(dframe, mean_shifted_column), decimation_factor=50)\n",
    "    # PLot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Full Data\")\n",
    "    plt.plot(dframe[time_column][::50], sub_tap_result, label=f\"Subsampled/Tapered Data\") # Make sure time step is same as decimation_factor\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True, alpha=0.5)\n",
    "    plt.title(f\"Car On Measurement {i+1} - Full and Subsampled/Tapered DS Data\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01dde00-0073-4347-8ee0-fba15385b9dd",
   "metadata": {},
   "source": [
    "##### Fast Fourier Transform\n",
    "- Plotting FFT spectra showing tapered/subsampled data overlayed onto full DS data for a given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3360958-7c9f-488a-8a87-80024e20bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting FFT spectra showing tapered/subsampled data overlayed onto full DNS data for a given dataframe\n",
    "def plot_fft(data, sr, fig1=None, fig2=None, fig3=None, name='', apply_window=True):\n",
    "    \"\"\"Plot FFT with windowing correction.\n",
    "    data: array\n",
    "    sr: Sampling rate\n",
    "    apply_window : bool, says whether to apply Hann window (default True)\"\"\"\n",
    "    n = len(data)\n",
    "    \n",
    "    # Apply window if requested\n",
    "    if apply_window:\n",
    "        window = np.hanning(n)\n",
    "        windowed_data = data * window\n",
    "    else:\n",
    "        windowed_data = data\n",
    "        coherent_gain=1.0\n",
    "    \n",
    "    # Compute FFT\n",
    "    fft_values = scipy.fft.rfft(windowed_data)\n",
    "    freqs = scipy.fft.rfftfreq(n, d=1/sr)\n",
    "    \n",
    "    # magnitudes WITHOUT coherent gain correction\n",
    "    magnitudes = np.abs(fft_values) / n\n",
    "\n",
    "    # Double the AC components (not DC and Nyquist)\n",
    "    magnitudes[1:] *= 2.0\n",
    "\n",
    "    # Undo doubling for Nyquist if even length\n",
    "    if n % 2 == 0:\n",
    "        magnitudes[-1] /= 2.0\n",
    "    \n",
    "    phases = np.angle(fft_values)\n",
    "    \n",
    "    # Create figures:\n",
    "    if fig1 is None:\n",
    "        fig1 = plt.figure(figsize=(10,6))\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (Linear)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig1.number)\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig2 is None:\n",
    "        fig2 = plt.figure(figsize=(10, 6))\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (log)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig2.number)\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.legend()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig3 is None:\n",
    "        fig3 = plt.figure(figsize=(10, 6))\n",
    "        plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "        plt.title('Phase Spectrum', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Phase (radians)', fontsize=14)\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        #plt.xlim(-1, 50)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.5)\n",
    "    else:\n",
    "        plt.figure(fig3.number)\n",
    "        plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.8)\n",
    "    \n",
    "    return fig1, fig2, fig3\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "for i, dframe in enumerate(car_on_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    decimation_factor=50 # step used for subsampling\n",
    "    print(f\"dataframe: df{i+1}\")\n",
    "    # For full data\n",
    "    fig1, fig2, fig3 = plot_fft(dframe[mean_shifted_column].values, sr=25000, name='Full Data', apply_window=False)\n",
    "    # For tapered/subsampled data\n",
    "    sub_tap_results=[]\n",
    "    sub_tap_result = sub_tapered(apply_hann_window(dframe, mean_shifted_column), decimation_factor=50)\n",
    "    sub_tap_results.append(sub_tap_result)\n",
    "    plot_fft(sub_tap_results[-1], sr=25000//decimation_factor, fig1=fig1, fig2=fig2, fig3=fig3, name='Subsampled/Tapered Data', apply_window=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6084db96-164a-4219-90fa-0e0ad57d1076",
   "metadata": {},
   "source": [
    "##### Continuous Wavelet Transform\n",
    "- The Morlet wavelet, given by $\\psi(t)=\\exp(\\frac{-t^2}{2})\\cos(5t)$, is used for the wavelet transform\n",
    "##### Full DS Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffd073-7e2d-4cf7-b603-fd383c4f7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dframe in enumerate(car_on_dataframes):\n",
    "    mean_shifted_column=f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    data = dframe[mean_shifted_column].values\n",
    "    #print(f\"Data shape: {data.shape}\")\n",
    "    time_sec = dframe[time_column].values\n",
    "    delta_t = time_sec[1] - time_sec[0] # time step in seconds\n",
    "    #print(delta_t)\n",
    "\n",
    "    scale_min = 1.0 / (10000 * delta_t)  # Small scale for high freq, use freq_max=10000\n",
    "    scale_max = 1.0 / (10 * delta_t)  # Large scale for low freq, use freq_min=10\n",
    "    scales = np.logspace(np.log10(scale_min), np.log10(scale_max), 60) \n",
    "    # Wavelet transform:\n",
    "    coefficients, frequencies = pywt.cwt(data, scales, 'morl', sampling_period=delta_t)\n",
    "    print(f\"Frequency range: {frequencies.min():.2f} to {frequencies.max():.2f} Hz\")\n",
    "    print(f\"Coefficients shape: {coefficients.shape}\")\n",
    "    print(f\"Frequencies shape: {frequencies.shape}\")\n",
    "    print(f\"Time_sec shape: {time_sec.shape}\")\n",
    "    # Smooth in time direction (axis=1), not frequency (axis=0)\n",
    "    smoothed_coefficients = uniform_filter(np.abs(coefficients), size=(1, 200)) # changed size from (1,50) to (1,200)\n",
    "    # Add small epsilon (if needed) to avoid log(0)\n",
    "    #epsilon = 1e-10  # Small value to prevent log(0)\n",
    "    #coeffs = (coefficients + epsilon)\n",
    "    \n",
    "    # Plot:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.pcolormesh(time_sec, frequencies, np.log10(smoothed_coefficients), cmap='magma', shading='auto')#, vmin=-5)\n",
    "    plt.colorbar(label='log\\u2081\\u2080(Magnitude)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title(f'Car On Measurement {i+1} - Full DS Data')\n",
    "    plt.show()\n",
    "\n",
    "    # Try to make histograms ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    magnitudes = np.abs(smoothed_coefficients)\n",
    "    magnitude_values = magnitudes.flatten()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    plt.hist(magnitude_values, bins=50, density = True, facecolor='skyblue', edgecolor='grey')\n",
    "    plt.title(\"Histogram of Scalogram Magnitudes\")\n",
    "    plt.xlabel(\"Magnitude\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    plt.yscale('log')\n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    plt.axvline(x=np.mean(magnitude_values), color='r', linestyle='--', label=f'Mean: {np.mean(magnitude_values): .2e}')\n",
    "    plt.axvline(x=np.median(magnitude_values), color='orange', linestyle='--', label=f'Median: {np.median(magnitude_values): .2e}')\n",
    "    # get mode:\n",
    "    hist_counts, bin_edges = np.histogram(magnitude_values, bins=50)\n",
    "    mode_bin_index = np.argmax(hist_counts)\n",
    "    # Mode is the center of the bin with the highest count:\n",
    "    mode_value = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "    plt.axvline(x=mode_value, color='b', linestyle='--', label=f'Mode: {mode_value: .2e}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # some other stats:\n",
    "    print(ss.describe(magnitude_values))\n",
    "    std_dev = np.std(magnitude_values)\n",
    "    print(f\"Standard Deviation: {std_dev:.4f}\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8db3f-ec29-490e-92a4-f1b42dc6060e",
   "metadata": {},
   "source": [
    "##### Continuous Wavelet Transform\n",
    "##### Tapered/Subsampled DS Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397e7ab-a625-47d4-a155-c4a5e1ca4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dframe in enumerate(car_on_dataframes):\n",
    "    mean_shifted_column=f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    sub_tap_data = sub_tapered(apply_hann_window(dframe, mean_shifted_column), decimation_factor=50)\n",
    "    print(f\"Data shape: {sub_tap_data.shape}\")\n",
    "    time_sec = dframe[time_column][::50].values # use step == decimation_factor \n",
    "    delta_t = time_sec[1] - time_sec[0] # time step in seconds\n",
    "    #print(delta_t)\n",
    "\n",
    "    scale_min = 1.0 / (250 * delta_t)  # Small scale for high freq, use freq_max=250\n",
    "    scale_max = 1.0 / (10 * delta_t)  # Large scale for low freq, use freq_min=10\n",
    "    scales = np.logspace(np.log10(scale_min), np.log10(scale_max), 60) \n",
    "    # Wavelet transform:\n",
    "    coefficients, frequencies = pywt.cwt(sub_tap_data, scales, 'morl', sampling_period=delta_t)\n",
    "    print(f\"Frequency range: {frequencies.min():.2f} to {frequencies.max():.2f} Hz\")\n",
    "    print(f\"Coefficients shape: {coefficients.shape}\")\n",
    "    print(f\"Frequencies shape: {frequencies.shape}\")\n",
    "    print(f\"Time_sec shape: {time_sec.shape}\")\n",
    "    # Smooth in time direction (axis=1), not frequency (axis=0)\n",
    "    smoothed_coefficients = uniform_filter(np.abs(coefficients), size=(1, 50))\n",
    "    # Add small epsilon (if needed) to avoid log(0)\n",
    "    #epsilon = 1e-10  # Small value to prevent log(0)\n",
    "    #coeffs = (coefficients + epsilon)\n",
    "    \n",
    "    # Plot:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.pcolormesh(time_sec, frequencies, np.log10(smoothed_coefficients), cmap='magma', shading='auto')#, vmin=-5)\n",
    "    plt.colorbar(label='log\\u2081\\u2080(Magnitude)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title(f'Car On Measurement {i+1} - Full DS Data')\n",
    "    plt.show()\n",
    "\n",
    "    # Try to make histograms ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    magnitudes = np.abs(smoothed_coefficients)\n",
    "    magnitude_values = magnitudes.flatten()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    plt.hist(magnitude_values, bins=50, density = True, facecolor='skyblue', edgecolor='grey')\n",
    "    plt.title(\"Histogram of Scalogram Magnitudes\")\n",
    "    plt.xlabel(\"Magnitude\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    plt.yscale('log')\n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    plt.axvline(x=np.mean(magnitude_values), color='r', linestyle='--', label=f'Mean: {np.mean(magnitude_values): .2e}')\n",
    "    plt.axvline(x=np.median(magnitude_values), color='orange', linestyle='--', label=f'Median: {np.median(magnitude_values): .2e}')\n",
    "    # get mode:\n",
    "    hist_counts, bin_edges = np.histogram(magnitude_values, bins=50)\n",
    "    mode_bin_index = np.argmax(hist_counts)\n",
    "    # Mode is the center of the bin with the highest count:\n",
    "    mode_value = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "    plt.axvline(x=mode_value, color='b', linestyle='--', label=f'Mode: {mode_value: .2e}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # some other stats:\n",
    "    print(ss.describe(magnitude_values))\n",
    "    std_dev = np.std(magnitude_values)\n",
    "    print(f\"Standard Deviation: {std_dev:.4f}\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f1405b-ebd2-41d2-912a-4086e3a902e9",
   "metadata": {},
   "source": [
    "***\n",
    "### Car on, music playing\n",
    "##### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044370b4-fc00-4f47-ad61-02100e8c8615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "columns_music1 = ['Time1 (s)', 'Signal1 (m)']\n",
    "dfm1 = pd.read_table(\"musiccar1.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=columns_music1)\n",
    "#print(dfm1.head())\n",
    "\n",
    "columns_music2 = ['Time2 (s)', 'Signal2 (m)']\n",
    "dfm2 = pd.read_table(\"musiccar2.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=columns_music2)\n",
    "#print(dfm2.head())\n",
    "\n",
    "columns_music3 = ['Time3 (s)', 'Signal3 (m)']\n",
    "dfm3 = pd.read_table(\"musiccar3.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=columns_music3)\n",
    "#print(dfm3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535380be-1d9c-4191-babf-373e14b27726",
   "metadata": {},
   "source": [
    "##### Plot Time Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee948b2-fb94-4fd6-b48d-6d23a90554b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_on_music_dataframes = [dfm1, dfm2, dfm3] # add more after loading more dataframes\n",
    "for i, dframe in enumerate(car_on_music_dataframes):\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    signal_column = f\"Signal{i+1} (m)\"\n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[signal_column], label=f\"Car On Playing Music Measurement {i+1} - Full Data\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True,alpha=0.5)\n",
    "    plt.title(f\"Car On Playing Music Measurement {i+1} - Full Data\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44209a5-8f0e-43bc-a54c-25e47fc6237e",
   "metadata": {},
   "source": [
    "##### Detrending and Shifting Data to Zero Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba6d3c2-7ff0-4427-b9cf-e07b020a0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dframe in enumerate(car_on_music_dataframes):\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    signal_column = f\"Signal{i+1} (m)\"\n",
    "    detrended_signal_column = f\"Signal{i+1} Detrended (m)\"\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    \n",
    "    # Detrend\n",
    "    dframe[detrended_signal_column] = signal.detrend(dframe[signal_column], type='linear') \n",
    "    # Shift Mean to ~Zero (without normalizing)\n",
    "    dframe[mean_shifted_column] = dframe[detrended_signal_column] - dframe[detrended_signal_column].mean()\n",
    "\n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Car On Playing Music Measurement {i+1} - Full Data\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True,alpha=0.5)\n",
    "    plt.axhline(y=0.0, label=\"0.0\", color='red', linestyle=\":\")\n",
    "    plt.title(f\"Car On Playing Music Measurement {i+1} - Detrended and Shifted to Zero Mean\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f964493b-6f3a-41f0-87fd-d995ef83757d",
   "metadata": {},
   "source": [
    "##### Tapering Detrended and Shifted (DS) Time Series\n",
    "- A Hann window is used for tapering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f288b0cf-215c-4e59-b6b2-2a30bef4e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dframe in enumerate(car_on_music_dataframes):\n",
    "    tapered_data = []\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    hann_result = apply_hann_window(dframe, mean_shifted_column) # taper all dataframes\n",
    "    tapered_data.append(hann_result)\n",
    "    time_column = f\"Time{i+1} (s)\" # need time column for plotting\n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Full Data\")\n",
    "    plt.plot(dframe[time_column], tapered_data[-1], label=f\"Tapered Data\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True,alpha=0.5)\n",
    "    plt.title(f\"Car On Playing Music Measurement {i+1} - Full and Tapered DS Data\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0eadba-225f-487a-8107-afa9ce877f8a",
   "metadata": {},
   "source": [
    "##### 'percent_check' function for tapering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1597d-5384-494f-9e30-dc8a9b729009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_check_tapered(original_data, tapered_data_full, padding, tolerance=0.05):\n",
    "    \"\"\"original_data : Original unpadded time series (array)\n",
    "    tapered_data_full : Tapered time series, includes padding (array)\n",
    "    padding : Amount of padding added to each end (int)\n",
    "    tolerance : Acceptable error as fraction of data range (float)\"\"\"\n",
    "    # Extract original from tapered data (remove padding)\n",
    "    if padding > 0:\n",
    "        tapered_original_region = tapered_data_full[padding:-padding]\n",
    "    else:\n",
    "        tapered_original_region = tapered_data_full\n",
    "    \n",
    "    # Direct comparison: tapered vs original\n",
    "    abs_errors = np.abs(original_data - tapered_original_region)\n",
    "    # normalization\n",
    "    data_range = np.max(original_data) - np.min(original_data)\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    # Calculate metrics\n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance))*100\n",
    "    \n",
    "    # Mean Absolute Error (MAE) metrics\n",
    "    mae = np.mean(abs_errors)\n",
    "    std_original = np.std(original_data)\n",
    "    mae_pct_std = (mae / std_original)*100\n",
    "    \n",
    "    passes = pct_within >= 95\n",
    "    \n",
    "    results = {'padding': padding,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes': passes,\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%',\n",
    "        'mean_abs_error': f'{mae: .4f}',\n",
    "        'mae_as_%_of_std': f'{mae_pct_std: .4f}%',\n",
    "        'num_points': len(original_data),\n",
    "        'data_range': f'{data_range: .4f}'}\n",
    "    \n",
    "    return results\n",
    "    \n",
    "for i, dframe in enumerate(car_on_music_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    tapered_data = []\n",
    "    hann_result = apply_hann_window(dframe, mean_shifted_column) # taper all dataframes\n",
    "    tapered_data.append(hann_result)\n",
    "    percent_check_tapered_results = percent_check_tapered(dframe[mean_shifted_column], tapered_data[-1], padding=0, tolerance=0.05)\n",
    "    print(f\"dataframe: dfm{i+1}\")\n",
    "    print(percent_check_tapered_results)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21772f5b-7a6a-4a20-990b-8fa947eeb0a6",
   "metadata": {},
   "source": [
    "##### Subsampling DS Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c43d1c-0842-4120-9ef2-089a3a745c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling the tapered time series\n",
    "#Sampling Rate = Total Number of Samples / Total Time (in seconds)\n",
    "def subsample(data, column, decimation_factor):\n",
    "    \"\"\"Subsample data using scipy.signal.decimate with anti-aliasing filter.\n",
    "    data: input data e.g. df1\n",
    "    column: column to subsample (e.g. \"Signal1 Zero Mean (m)\"), string\n",
    "    decimation_factor: factor by which to reduce sampling rate\"\"\"\n",
    "    num_samples=len(data[column])\n",
    "    sampling_time=data.iloc[-1, 0] #get last value in first column (time (s))\n",
    "    original_sampling_rate = int(num_samples/sampling_time)\n",
    "    print(f\"Original sampling rate for {column}: {original_sampling_rate} Hz\")\n",
    "    # scipy.signal.decimate applies an anti-aliasing filter automatically\n",
    "    # Use a higher order filter for better anti-aliasing (default is 8)\n",
    "    decimated_data = scipy.signal.decimate(data[column], decimation_factor, ftype='iir', zero_phase=True) # \n",
    "    # get new sampling rate:\n",
    "    new_sr = int(original_sampling_rate / decimation_factor)\n",
    "    print(f\"New sampling rate for {column}: {new_sr} Hz\")\n",
    "    return decimated_data, new_sr, original_sampling_rate\n",
    "\n",
    "for i, dframe in enumerate(car_on_music_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    subsample_result = subsample(dframe, mean_shifted_column, decimation_factor=50)\n",
    "    subsampled_data = subsample_result[0]\n",
    "    # sub_list = []\n",
    "    # sub_list.append(subsampled_data)\n",
    "    \n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Full Data\")\n",
    "    plt.plot(dframe[time_column][::50], subsampled_data, label=f\"Subsampled Data\") # Make sure time step is same as decimation_factor\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True, alpha=0.5)\n",
    "    plt.title(f\"Car On Playing Music Measurement {i+1} - Full and Subsampled DS Data\")\n",
    "    plt.legend()\n",
    "    #plt.xlim(4,5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e773b-3b24-41b8-b32b-7a1c6941f73a",
   "metadata": {},
   "source": [
    "##### 'percent_check' function for subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640646d-29e7-474e-9235-8613cbf62b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_check_scipy_decimate(data, column, step, tolerance=0.05):\n",
    "    x_original = np.arange(len(data))\n",
    "    y_original = data[column].values\n",
    "    \n",
    "    # Get subsampled series\n",
    "    x_subsampled = np.arange(0, len(data), step)\n",
    "    y_subsampled=scipy.signal.decimate(data[column].values, step, ftype='iir', zero_phase=True)\n",
    "    \n",
    "    # Interpolate subsampled data back to original timestamps\n",
    "    f_interp = interpolate.interp1d(x_subsampled, y_subsampled, kind='linear', fill_value='extrapolate')\n",
    "    y_reconstructed = f_interp(x_original)\n",
    "    \n",
    "    # Calculate absolute errors\n",
    "    abs_errors = np.abs(y_original - y_reconstructed)\n",
    "    \n",
    "    # Calculate data range (the scale of the data)\n",
    "    data_range = np.max(y_original) - np.min(y_original)\n",
    "    #print(\"data_range:\", data_range)\n",
    "    # Normalize errors by data range instead of individual values\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    # Test if within tolerance\n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance)) * 100\n",
    "    \n",
    "    # Overall pass/fail\n",
    "    passes = pct_within >= 95  # At least 95% of points within tolerance\n",
    "    \n",
    "    results = {'step': step,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes': passes,\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'num_original_points': len(y_original),\n",
    "        'num_subsampled_points': len(y_subsampled),\n",
    "        'data_range': f'{data_range: .4f}',  \n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%' }\n",
    "    return results\n",
    "\n",
    "for i, dframe in enumerate(car_on_music_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    print(f\"dataframe: dfm{i+1}\")\n",
    "    scipy_decimate_pct_check_results = percent_check_scipy_decimate(dframe, mean_shifted_column, step=50, tolerance=0.05)\n",
    "    print(scipy_decimate_pct_check_results)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c887ca-e854-4c4b-80a9-6eabdae0dcf3",
   "metadata": {},
   "source": [
    "##### Subsampling the Tapered DS Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e3776-4ec2-4c97-8274-00bce907e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_tapered(tapered_data, decimation_factor):\n",
    "    sub_tap_data = scipy.signal.decimate(tapered_data, decimation_factor, ftype='iir', zero_phase=True)\n",
    "    return sub_tap_data\n",
    "\n",
    "for i, dframe in enumerate(car_on_music_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    sub_tap_result = sub_tapered(apply_hann_window(dframe, mean_shifted_column), decimation_factor=50)\n",
    "    \n",
    "    # PLot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Full Data\")\n",
    "    plt.plot(dframe[time_column][::50], sub_tap_result, label=f\"Subsampled/Tapered Data\") # Make sure time step is same as decimation_factor\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True, alpha=0.5)\n",
    "    plt.title(f\"Car On Playing Music Measurement {i+1} - Full and Subsampled/Tapered DS Data\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fab6db-eb32-4333-b245-c4751ed0de2e",
   "metadata": {},
   "source": [
    "##### Fast Fourier Transform\n",
    "- Plotting FFT spectra showing tapered/subsampled data overlayed onto full DS data for a given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca39b5-833d-4312-aa80-b31afdc0fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting FFT spectra showing tapered/subsampled data overlayed onto full DNS data for a given dataframe\n",
    "def plot_fft(data, sr, fig1=None, fig2=None, fig3=None, name='', apply_window=True):\n",
    "    \"\"\"Plot FFT with windowing correction.\n",
    "    data: array\n",
    "    sr: Sampling rate\n",
    "    apply_window : bool, says whether to apply Hann window (default True)\"\"\"\n",
    "    n = len(data)\n",
    "    \n",
    "    # Apply window if requested\n",
    "    if apply_window:\n",
    "        window = np.hanning(n)\n",
    "        windowed_data = data * window\n",
    "    else:\n",
    "        windowed_data = data\n",
    "        coherent_gain=1.0\n",
    "    \n",
    "    # Compute FFT\n",
    "    fft_values = scipy.fft.rfft(windowed_data)\n",
    "    freqs = scipy.fft.rfftfreq(n, d=1/sr)\n",
    "    \n",
    "    # magnitudes WITHOUT coherent gain correction\n",
    "    magnitudes = np.abs(fft_values) / n\n",
    "\n",
    "    # Double the AC components (not DC and Nyquist)\n",
    "    magnitudes[1:] *= 2.0\n",
    "\n",
    "    # Undo doubling for Nyquist if even length\n",
    "    if n % 2 == 0:\n",
    "        magnitudes[-1] /= 2.0\n",
    "    \n",
    "    phases = np.angle(fft_values)\n",
    "    \n",
    "    # Create figures:\n",
    "    if fig1 is None:\n",
    "        fig1 = plt.figure(figsize=(10,6))\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (Linear)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig1.number)\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig2 is None:\n",
    "        fig2 = plt.figure(figsize=(10, 6))\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (log)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig2.number)\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.legend()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig3 is None:\n",
    "        fig3 = plt.figure(figsize=(10, 6))\n",
    "        plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "        plt.title('Phase Spectrum', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Phase (radians)', fontsize=14)\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        #plt.xlim(-1, 50)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.5)\n",
    "    else:\n",
    "        plt.figure(fig3.number)\n",
    "        plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.8)\n",
    "    \n",
    "    return fig1, fig2, fig3\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "for i, dframe in enumerate(car_on_music_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    decimation_factor=50 # step used for subsampling\n",
    "    print(f\"dataframe: dfm{i+1}\")\n",
    "    # For full data\n",
    "    fig1, fig2, fig3 = plot_fft(dframe[mean_shifted_column].values, sr=25000, name='Full Data', apply_window=False)\n",
    "    # For tapered/subsampled data\n",
    "    sub_tap_results=[]\n",
    "    sub_tap_result = sub_tapered(apply_hann_window(dframe, mean_shifted_column), decimation_factor=50)\n",
    "    sub_tap_results.append(sub_tap_result)\n",
    "    plot_fft(sub_tap_results[-1], sr=25000//decimation_factor, fig1=fig1, fig2=fig2, fig3=fig3, name='Subsampled/Tapered Data', apply_window=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd9dd5-99ec-4233-8340-2d6724430339",
   "metadata": {},
   "source": [
    "##### Continuous Wavelet Transform\n",
    "- The Morlet wavelet, given by $\\psi(t)=\\exp(\\frac{-t^2}{2})\\cos(5t)$, is used for the wavelet transform\n",
    "##### Full DS Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad969e3f-e63c-4b71-ada6-28d15a361e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dframe in enumerate(car_on_music_dataframes):\n",
    "    mean_shifted_column=f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    data = dframe[mean_shifted_column].values\n",
    "    #print(f\"Data shape: {data.shape}\")\n",
    "    time_sec = dframe[time_column].values\n",
    "    delta_t = time_sec[1] - time_sec[0] # time step in seconds\n",
    "    #print(delta_t)\n",
    "\n",
    "    scale_min = 1.0 / (10000 * delta_t)  # Small scale for high freq, use freq_max=10000\n",
    "    scale_max = 1.0 / (10 * delta_t)  # Large scale for low freq, use freq_min=10\n",
    "    scales = np.logspace(np.log10(scale_min), np.log10(scale_max), 60) \n",
    "    # Wavelet transform:\n",
    "    coefficients, frequencies = pywt.cwt(data, scales, 'morl', sampling_period=delta_t)\n",
    "    print(f\"Frequency range: {frequencies.min():.2f} to {frequencies.max():.2f} Hz\")\n",
    "    print(f\"Coefficients shape: {coefficients.shape}\")\n",
    "    print(f\"Frequencies shape: {frequencies.shape}\")\n",
    "    print(f\"Time_sec shape: {time_sec.shape}\")\n",
    "    # Smooth in time direction (axis=1), not frequency (axis=0)\n",
    "    smoothed_coefficients = uniform_filter(np.abs(coefficients), size=(1, 300)) # changed size from (1,50) to (1,300)\n",
    "    # Add small epsilon (if needed) to avoid log(0)\n",
    "    #epsilon = 1e-10  # Small value to prevent log(0)\n",
    "    #coeffs = (coefficients + epsilon)\n",
    "    \n",
    "    # Plot:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.pcolormesh(time_sec, frequencies, np.log10(smoothed_coefficients), cmap='magma', shading='auto')\n",
    "    plt.colorbar(label='log\\u2081\\u2080(Magnitude)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title(f'Car On Playing Music Measurement {i+1} - Full DS Data')\n",
    "    plt.show()\n",
    "    \n",
    "    # Try to make histograms ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    magnitudes = np.abs(smoothed_coefficients)\n",
    "    magnitude_values = magnitudes.flatten()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    plt.hist(magnitude_values, bins=50, density = True, facecolor='skyblue', edgecolor='grey')\n",
    "    plt.title(\"Histogram of Scalogram Magnitudes\")\n",
    "    plt.xlabel(\"Magnitude\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    plt.yscale('log')\n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    plt.axvline(x=np.mean(magnitude_values), color='r', linestyle='--', label=f'Mean: {np.mean(magnitude_values): .2e}')\n",
    "    plt.axvline(x=np.median(magnitude_values), color='orange', linestyle='--', label=f'Median: {np.median(magnitude_values): .2e}')\n",
    "    # get mode:\n",
    "    hist_counts, bin_edges = np.histogram(magnitude_values, bins=50)\n",
    "    mode_bin_index = np.argmax(hist_counts)\n",
    "    # Mode is the center of the bin with the highest count:\n",
    "    mode_value = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "    plt.axvline(x=mode_value, color='b', linestyle='--', label=f'Mode: {mode_value: .2e}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # some other stats:\n",
    "    print(ss.describe(magnitude_values))\n",
    "    std_dev = np.std(magnitude_values)\n",
    "    print(f\"Standard Deviation: {std_dev:.4f}\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a601fe1-a508-41e7-83fa-c920814309cd",
   "metadata": {},
   "source": [
    "##### Continuous Wavelet Transform\n",
    "##### Tapered/Subsampled DS Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b5b2e7-a871-4913-b06f-1e1fba4f79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dframe in enumerate(car_on_music_dataframes):\n",
    "    mean_shifted_column=f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    sub_tap_data = sub_tapered(apply_hann_window(dframe, mean_shifted_column), decimation_factor=50)\n",
    "    print(f\"Data shape: {sub_tap_data.shape}\")\n",
    "    time_sec = dframe[time_column][::50].values # use step == decimation_factor \n",
    "    delta_t = time_sec[1] - time_sec[0] # time step in seconds\n",
    "    #print(delta_t)\n",
    "\n",
    "    scale_min = 1.0 / (250 * delta_t)  # Small scale for high freq, use freq_max=250\n",
    "    scale_max = 1.0 / (10 * delta_t)  # Large scale for low freq, use freq_min=10\n",
    "    scales = np.logspace(np.log10(scale_min), np.log10(scale_max), 60) \n",
    "    # Wavelet transform:\n",
    "    coefficients, frequencies = pywt.cwt(sub_tap_data, scales, 'morl', sampling_period=delta_t)\n",
    "    print(f\"Frequency range: {frequencies.min():.2f} to {frequencies.max():.2f} Hz\")\n",
    "    print(f\"Coefficients shape: {coefficients.shape}\")\n",
    "    print(f\"Frequencies shape: {frequencies.shape}\")\n",
    "    print(f\"Time_sec shape: {time_sec.shape}\")\n",
    "    # Smooth in time direction (axis=1), not frequency (axis=0)\n",
    "    smoothed_coefficients = uniform_filter(np.abs(coefficients), size=(1, 50))\n",
    "    # Add small epsilon (if needed) to avoid log(0)\n",
    "    #epsilon = 1e-10  # Small value to prevent log(0)\n",
    "    #coeffs = (coefficients + epsilon)\n",
    "    \n",
    "    # Plot:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.pcolormesh(time_sec, frequencies, np.log10(smoothed_coefficients), cmap='magma', shading='auto')\n",
    "    plt.colorbar(label='log\\u2081\\u2080(Magnitude)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title(f'Car On Music Playing Measurement {i+1} - Full DS Data')\n",
    "    plt.show()\n",
    "\n",
    "    # Try to make histograms ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    magnitudes = np.abs(smoothed_coefficients)\n",
    "    magnitude_values = magnitudes.flatten()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    plt.hist(magnitude_values, bins=50, density = True, facecolor='skyblue', edgecolor='grey')\n",
    "    plt.title(\"Histogram of Scalogram Magnitudes\")\n",
    "    plt.xlabel(\"Magnitude\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    plt.yscale('log')\n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    plt.axvline(x=np.mean(magnitude_values), color='r', linestyle='--', label=f'Mean: {np.mean(magnitude_values): .2e}')\n",
    "    plt.axvline(x=np.median(magnitude_values), color='orange', linestyle='--', label=f'Median: {np.median(magnitude_values): .2e}')\n",
    "    # get mode:\n",
    "    hist_counts, bin_edges = np.histogram(magnitude_values, bins=50)\n",
    "    mode_bin_index = np.argmax(hist_counts)\n",
    "    # Mode is the center of the bin with the highest count:\n",
    "    mode_value = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "    plt.axvline(x=mode_value, color='b', linestyle='--', label=f'Mode: {mode_value: .2e}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # some other stats:\n",
    "    print(ss.describe(magnitude_values))\n",
    "    std_dev = np.std(magnitude_values)\n",
    "    print(f\"Standard Deviation: {std_dev:.4f}\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
