{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64414e83-f285-4b38-a528-99d8b6b2d2b3",
   "metadata": {},
   "source": [
    "### Vibrometer Measurements of Car\n",
    "##### Measurement Summary:\n",
    "- **car off**\n",
    "- car on\n",
    "- car on, music playing\n",
    "- revving car engine\n",
    "\n",
    "This notebook creates plots for the case that the car is off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f18c96-a82e-435b-bee8-f8754385fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import scipy.stats as ss\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.fft\n",
    "import pywt\n",
    "from scipy.signal.windows import hann\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage import uniform_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ce15e-8089-4f00-ad65-5cba8fcd8409",
   "metadata": {},
   "source": [
    "***\n",
    "### Car off\n",
    "##### Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7701cb4-bb84-4857-ac7f-ffe15169d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "# (make sure the .ipynb file is in the same folder as the data)\n",
    "column_names1 = ['Time1 (s)', 'Signal1 (m)']\n",
    "df1 = pd.read_table(\"background1car.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names1)\n",
    "#print(df1.head())\n",
    "\n",
    "column_names2 = ['Time2 (s)', 'Signal2 (m)']\n",
    "df2 = pd.read_table(\"background2car.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names2)\n",
    "#print(df2.head())\n",
    "\n",
    "column_names3 = ['Time3 (s)', 'Signal3 (m)']\n",
    "df3 = pd.read_table(\"background3car.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names3)\n",
    "#print(df3.head())\n",
    "\n",
    "column_names4 = ['Time4 (s)', 'Signal4 (m)']\n",
    "df4 = pd.read_table(\"background4car.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names4)\n",
    "#print(df4.head())\n",
    "\n",
    "column_names5 = ['Time5 (s)', 'Signal5 (m)']\n",
    "df5 = pd.read_table(\"background5car.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names5)\n",
    "#print(df5.head())\n",
    "\n",
    "column_names6 = ['Time6 (s)', 'Signal6 (m)']\n",
    "df6 = pd.read_table(\"background6car.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names6)\n",
    "#print(df6.head())\n",
    "\n",
    "column_names7 = ['Time7 (s)', 'Signal7 (m)']\n",
    "df7 = pd.read_table(\"background7.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names7)\n",
    "#print(df7.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e00af1-baed-47bd-bce2-4b84c64b58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data with different naming convention:\n",
    "column_names8 = ['Time8 (s)', 'Signal8 (m)']\n",
    "df8 = pd.read_table(\"backgroundr1car.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names8)\n",
    "#print(df8.head())\n",
    "\n",
    "column_names9 = ['Time9 (s)', 'Signal9 (m)']\n",
    "df9 = pd.read_table(\"backgroundr2car.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names9)\n",
    "#print(df9.head())\n",
    "\n",
    "column_names10 = ['Time10 (s)', 'Signal10 (m)']\n",
    "df10 = pd.read_table(\"backgroundr3car.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names10)\n",
    "#print(df10.head())\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "column_names11 = ['Time11 (s)', 'Signal11 (m)']\n",
    "df11 = pd.read_table(\"backgroundw1.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names11)\n",
    "#print(df11.head())\n",
    "\n",
    "column_names12 = ['Time12 (s)', 'Signal12 (m)']\n",
    "df12 = pd.read_table(\"backgroundw2.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names12)\n",
    "#print(df12.head())\n",
    "\n",
    "column_names13 = ['Time13 (s)', 'Signal13 (m)']\n",
    "df13 = pd.read_table(\"backgroundw3.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names13)\n",
    "#print(df13.head())\n",
    "\n",
    "column_names14 = ['Time14 (s)', 'Signal14 (m)']\n",
    "df14 = pd.read_table(\"backgroundw4.txt\", delimiter=r'\\s+', encoding='latin-1', skiprows=5, names=column_names14)\n",
    "#print(df14.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267e4ee-1f6f-4162-8ec7-916db9120cc9",
   "metadata": {},
   "source": [
    "##### Plot Time Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456aff7-b922-409a-a7d7-78ade1de0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_off_dataframes = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14]\n",
    "for i, dframe in enumerate(car_off_dataframes):\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    signal_column = f\"Signal{i+1} (m)\"\n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[signal_column], label=f\"Car off Measurement {i+1} - Full Data\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True,alpha=0.5)\n",
    "    plt.title(f\"Car off Measurement {i+1} - Full Data\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b264573-0f97-4e3a-82dd-74303b61b2c3",
   "metadata": {},
   "source": [
    "##### Detrending and Shifting Data to Zero Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ee799-2720-43aa-993f-75d4060c2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dframe in enumerate(car_off_dataframes):\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    signal_column = f\"Signal{i+1} (m)\"\n",
    "    detrended_signal_column = f\"Signal{i+1} Detrended (m)\"\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    \n",
    "    # Detrend\n",
    "    dframe[detrended_signal_column] = signal.detrend(dframe[signal_column], type='linear') \n",
    "    # Shift Mean to ~Zero (without normalizing)\n",
    "    dframe[mean_shifted_column] = dframe[detrended_signal_column] - dframe[detrended_signal_column].mean()\n",
    "\n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Car Off Measurement {i+1} - Full Data\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True,alpha=0.5)\n",
    "    plt.axhline(y=0.0, label=\"0.0\", color='red', linestyle=\":\")\n",
    "    plt.title(f\"Car Off Measurement {i+1} - Detrended and Shifted to Zero Mean\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6882918-081c-4701-b000-9bd0b5ab9665",
   "metadata": {},
   "source": [
    "##### Tapering Detrended and Shifted (DS) Time Series\n",
    "- A Hann window is used for tapering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baaf5a2-0c45-42ad-ad39-c8ee3d2a5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder: car_off_dataframes = [df1, df2, df3, df4, df5, df6, df7]\n",
    "def apply_hann_window(data, column):\n",
    "    window = np.hanning(len(data))\n",
    "    windowed_data = data[column] * window\n",
    "    return windowed_data\n",
    "    \n",
    "for i, dframe in enumerate(car_off_dataframes):\n",
    "    tapered_data = []\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    hann_result = apply_hann_window(dframe, mean_shifted_column) # taper all dataframes\n",
    "    tapered_data.append(hann_result)\n",
    "    time_column = f\"Time{i+1} (s)\" # need time column for plotting\n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Full Data\")\n",
    "    plt.plot(dframe[time_column], tapered_data[-1], label=f\"Tapered Data\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True,alpha=0.5)\n",
    "    plt.title(f\"Car Off Measurement {i+1} - Full and Tapered DS Data\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b006ed9-bfff-40a8-9e63-0ab1bb39470c",
   "metadata": {},
   "source": [
    "##### 'percent_check' function for tapering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fe7205-f606-448a-87af-4d9ef76e4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_check_tapered(original_data, tapered_data_full, padding, tolerance=0.05):\n",
    "    \"\"\"original_data : Original unpadded time series (array)\n",
    "    tapered_data_full : Tapered time series, includes padding (array)\n",
    "    padding : Amount of padding added to each end (int)\n",
    "    tolerance : Acceptable error as fraction of data range (float)\"\"\"\n",
    "    # Extract original from tapered data (remove padding)\n",
    "    if padding > 0:\n",
    "        tapered_original_region = tapered_data_full[padding:-padding]\n",
    "    else:\n",
    "        tapered_original_region = tapered_data_full\n",
    "    \n",
    "    # Direct comparison: tapered vs original\n",
    "    abs_errors = np.abs(original_data - tapered_original_region)\n",
    "    # normalization\n",
    "    data_range = np.max(original_data) - np.min(original_data)\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    # Calculate metrics\n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance))*100\n",
    "    \n",
    "    # Mean Absolute Error (MAE) metrics\n",
    "    mae = np.mean(abs_errors)\n",
    "    std_original = np.std(original_data)\n",
    "    mae_pct_std = (mae / std_original)*100\n",
    "    \n",
    "    passes = pct_within >= 95\n",
    "    \n",
    "    results = {'padding': padding,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes': passes,\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%',\n",
    "        'mean_abs_error': f'{mae: .4f}',\n",
    "        'mae_as_%_of_std': f'{mae_pct_std: .4f}%',\n",
    "        'num_points': len(original_data),\n",
    "        'data_range': f'{data_range: .4f}'}\n",
    "    \n",
    "    return results\n",
    "    \n",
    "for i, dframe in enumerate(car_off_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    tapered_data = []\n",
    "    hann_result = apply_hann_window(dframe, mean_shifted_column) # taper all dataframes\n",
    "    tapered_data.append(hann_result)\n",
    "    percent_check_tapered_results = percent_check_tapered(dframe[mean_shifted_column], tapered_data[-1], padding=0, tolerance=0.05)\n",
    "    print(f\"dataframe: df{i+1}\")\n",
    "    print(percent_check_tapered_results)\n",
    "    print(\"\")\n",
    "# Checking that this is working properly, comparing to output from longer way of writing it\n",
    "#print(percent_check_tapered(df1['Signal1 Zero Mean (m)'], apply_hann_window(df1, 'Signal1 Zero Mean (m)'), padding=0, tolerance=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279dc95b-1116-4156-9f87-50a1ea36eaf2",
   "metadata": {},
   "source": [
    "##### Subsampling DS Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b865e-87dd-4a7b-bed7-a0df0e2fc753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling the tapered time series\n",
    "#Sampling Rate = Total Number of Samples / Total Time (in seconds)\n",
    "def subsample(data, column, decimation_factor):\n",
    "    \"\"\"Subsample data using scipy.signal.decimate with anti-aliasing filter.\n",
    "    data: input data e.g. df1\n",
    "    column: column to subsample (e.g. \"Signal1 Zero Mean (m)\"), string\n",
    "    decimation_factor: factor by which to reduce sampling rate\"\"\"\n",
    "    num_samples=len(data[column])\n",
    "    sampling_time=data.iloc[-1, 0] #get last value in first column (time (s))\n",
    "    original_sampling_rate = int(num_samples/sampling_time)\n",
    "    print(f\"Original sampling rate for {column}: {original_sampling_rate} Hz\")\n",
    "    # scipy.signal.decimate applies an anti-aliasing filter automatically\n",
    "    # Use a higher order filter for better anti-aliasing (default is 8)\n",
    "    decimated_data = scipy.signal.decimate(data[column], decimation_factor, ftype='iir', zero_phase=True) \n",
    "    # get new sampling rate:\n",
    "    new_sr = int(original_sampling_rate / decimation_factor)\n",
    "    print(f\"New sampling rate for {column}: {new_sr} Hz\")\n",
    "    return decimated_data, new_sr, original_sampling_rate\n",
    "\n",
    "for i, dframe in enumerate(car_off_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    subsample_result = subsample(dframe, mean_shifted_column, decimation_factor=50)\n",
    "    subsampled_data = subsample_result[0]\n",
    "    # sub_list = []\n",
    "    # sub_list.append(subsampled_data)\n",
    "    \n",
    "    # Plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Full Data\")\n",
    "    plt.plot(dframe[time_column][::50], subsampled_data, label=f\"Subsampled Data\") # Make sure time step is same as decimation_factor\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True, alpha=0.5)\n",
    "    plt.title(f\"Car Off Measurement {i+1} - Full and Subsampled DS Data\")\n",
    "    plt.legend()\n",
    "    #plt.xlim(4,5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98649eac-022d-4b04-a588-8fe2b8d81aca",
   "metadata": {},
   "source": [
    "##### 'percent_check' function for subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767fd02-4ceb-44ca-8fdf-b05f6dd774b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_check_scipy_decimate(data, column, step, tolerance=0.05):\n",
    "    x_original = np.arange(len(data))\n",
    "    y_original = data[column].values\n",
    "    \n",
    "    # Get subsampled series\n",
    "    x_subsampled = np.arange(0, len(data), step)\n",
    "    y_subsampled=scipy.signal.decimate(data[column].values, step, ftype='iir', zero_phase=True)\n",
    "    \n",
    "    # Interpolate subsampled data back to original timestamps\n",
    "    f_interp = interpolate.interp1d(x_subsampled, y_subsampled, kind='linear', fill_value='extrapolate')\n",
    "    y_reconstructed = f_interp(x_original)\n",
    "    \n",
    "    # Calculate absolute errors\n",
    "    abs_errors = np.abs(y_original - y_reconstructed)\n",
    "    \n",
    "    # Calculate data range (the scale of the data)\n",
    "    data_range = np.max(y_original) - np.min(y_original)\n",
    "    #print(\"data_range:\", data_range)\n",
    "    # Normalize errors by data range instead of individual values\n",
    "    normalized_errors = abs_errors / data_range\n",
    "    \n",
    "    # Test if within tolerance\n",
    "    within_tolerance = normalized_errors <= tolerance\n",
    "    pct_within = (np.sum(within_tolerance) / len(within_tolerance)) * 100\n",
    "    \n",
    "    # Overall pass/fail\n",
    "    passes = pct_within >= 95  # At least 95% of points within tolerance\n",
    "    \n",
    "    results = {'step': step,\n",
    "        'tolerance': f'{tolerance*100}%',\n",
    "        'passes': passes,\n",
    "        'points_within_tolerance': f'{pct_within: .4f}%',\n",
    "        'num_original_points': len(y_original),\n",
    "        'num_subsampled_points': len(y_subsampled),\n",
    "        'data_range': f'{data_range: .4f}',  \n",
    "        'max_normalized_error': f'{(np.max(normalized_errors)*100): .4f}%' }\n",
    "    return results\n",
    "\n",
    "for i, dframe in enumerate(car_off_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    print(f\"dataframe: df{i+1}\")\n",
    "    scipy_decimate_pct_check_results = percent_check_scipy_decimate(dframe, mean_shifted_column, step=50, tolerance=0.05)\n",
    "    print(scipy_decimate_pct_check_results)\n",
    "    print(\"\")\n",
    "\n",
    "#print(percent_check_scipy_decimate(df3, 'Signal3 Zero Mean (m)', step=50, tolerance=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aec693-f2bf-4ee4-808c-c722e79fbbb1",
   "metadata": {},
   "source": [
    "##### Subsampling the Tapered DS Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7ee14-2016-4463-8022-f18272f92cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_tapered(tapered_data, decimation_factor):\n",
    "    sub_tap_data = scipy.signal.decimate(tapered_data, decimation_factor, ftype='iir', zero_phase=True)\n",
    "    return sub_tap_data\n",
    "\n",
    "for i, dframe in enumerate(car_off_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    sub_tap_result = sub_tapered(apply_hann_window(dframe, mean_shifted_column), decimation_factor=50)\n",
    "    \n",
    "    # PLot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(dframe[time_column], dframe[mean_shifted_column], label=f\"Full Data\")\n",
    "    plt.plot(dframe[time_column][::50], sub_tap_result, label=f\"Subsampled/Tapered Data\") # Make sure time step is same as decimation_factor\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (m)\")\n",
    "    plt.grid(True, alpha=0.5)\n",
    "    plt.title(f\"Car Off Measurement {i+1} - Full and Subsampled/Tapered DS Data\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5819883f-0e55-4a91-9e4e-1ecedda3bcba",
   "metadata": {},
   "source": [
    "##### Fast Fourier Transform\n",
    "- Plotting FFT spectra showing tapered/subsampled data overlayed onto full DS data for a given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32058617-2389-4e88-895c-72bbe17d5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting FFT spectra showing tapered/subsampled data overlayed onto full DNS data for a given dataframe\n",
    "def plot_fft(data, sr, fig1=None, fig2=None, fig3=None, name='', apply_window=True):\n",
    "    \"\"\"Plot FFT with windowing correction.\n",
    "    data: array\n",
    "    sr: Sampling rate\n",
    "    apply_window : bool, says whether to apply Hann window (default True)\"\"\"\n",
    "    n = len(data)\n",
    "    \n",
    "    # Apply window if requested\n",
    "    if apply_window:\n",
    "        window = np.hanning(n)\n",
    "        windowed_data = data * window\n",
    "    else:\n",
    "        windowed_data = data\n",
    "        coherent_gain=1.0\n",
    "    \n",
    "    # Compute FFT\n",
    "    fft_values = scipy.fft.rfft(windowed_data)\n",
    "    freqs = scipy.fft.rfftfreq(n, d=1/sr)\n",
    "    \n",
    "    # magnitudes WITHOUT coherent gain correction\n",
    "    magnitudes = np.abs(fft_values) / n\n",
    "\n",
    "    # Double the AC components (not DC and Nyquist)\n",
    "    magnitudes[1:] *= 2.0\n",
    "\n",
    "    # Undo doubling for Nyquist if even length\n",
    "    if n % 2 == 0:\n",
    "        magnitudes[-1] /= 2.0\n",
    "    \n",
    "    phases = np.angle(fft_values)\n",
    "    \n",
    "    # Create figures:\n",
    "    if fig1 is None:\n",
    "        fig1 = plt.figure(figsize=(10,6))\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (Linear)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig1.number)\n",
    "        plt.plot(freqs, magnitudes, linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig2 is None:\n",
    "        fig2 = plt.figure(figsize=(10, 6))\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.title('FFT Magnitude Spectrum (log)', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Magnitude', fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.grid(True, which='major', alpha=0.5)\n",
    "        plt.grid(True, which='minor', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.figure(fig2.number)\n",
    "        plt.loglog(freqs[1:], magnitudes[1:], linewidth=1, label=name)\n",
    "        plt.legend()\n",
    "        if name:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    if fig3 is None:\n",
    "        fig3 = plt.figure(figsize=(10, 6))\n",
    "        plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "        plt.title('Phase Spectrum', fontsize=16)\n",
    "        plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "        plt.ylabel('Phase (radians)', fontsize=14)\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        #plt.xlim(-1, 50)\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.5)\n",
    "    else:\n",
    "        plt.figure(fig3.number)\n",
    "        plt.plot(freqs[1:], phases[1:], linewidth=1, label=name)\n",
    "        if name:\n",
    "            plt.legend(loc='lower right', framealpha=0.8)\n",
    "    \n",
    "    return fig1, fig2, fig3\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "for i, dframe in enumerate(car_off_dataframes):\n",
    "    mean_shifted_column = f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    decimation_factor=50 # step used for subsampling\n",
    "    print(f\"dataframe: df{i+1}\")\n",
    "    # For full data\n",
    "    fig1, fig2, fig3 = plot_fft(dframe[mean_shifted_column].values, sr=25000, name='Full Data', apply_window=False)\n",
    "    # For tapered/subsampled data\n",
    "    sub_tap_results=[]\n",
    "    sub_tap_result = sub_tapered(apply_hann_window(dframe, mean_shifted_column), decimation_factor=50)\n",
    "    sub_tap_results.append(sub_tap_result)\n",
    "    plot_fft(sub_tap_results[-1], sr=25000//decimation_factor, fig1=fig1, fig2=fig2, fig3=fig3, name='Subsampled/Tapered Data', apply_window=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463d318-b680-4544-949c-98f31bfc67ed",
   "metadata": {},
   "source": [
    "##### Continuous Wavelet Transform\n",
    "- The Morlet wavelet, given by $\\psi(t)=\\exp(\\frac{-t^2}{2})\\cos(5t)$, is used for the wavelet transform\n",
    "##### Full DS Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ee395-f14a-4294-917d-ca18b7890e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pywt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af5a1d9-4fdd-472e-9370-c1a7fd263347",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dframe in enumerate(car_off_dataframes):\n",
    "    mean_shifted_column=f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    data = dframe[mean_shifted_column].values\n",
    "    #print(f\"Data shape: {data.shape}\")\n",
    "    time_sec = dframe[time_column].values\n",
    "    delta_t = time_sec[1] - time_sec[0] # time step in seconds\n",
    "    #print(delta_t)\n",
    "\n",
    "    scale_min = 1.0 / (10000 * delta_t)  # Small scale for high freq, use freq_max=10000\n",
    "    scale_max = 1.0 / (10 * delta_t)  # Large scale for low freq, use freq_min=10\n",
    "    scales = np.logspace(np.log10(scale_min), np.log10(scale_max), 60) \n",
    "    # Wavelet transform:\n",
    "    coefficients, frequencies = pywt.cwt(data, scales, 'morl', sampling_period=delta_t)\n",
    "    print(f\"Frequency range: {frequencies.min():.2f} to {frequencies.max():.2f} Hz\")\n",
    "    print(f\"Coefficients shape: {coefficients.shape}\")\n",
    "    print(f\"Frequencies shape: {frequencies.shape}\")\n",
    "    print(f\"Time_sec shape: {time_sec.shape}\")\n",
    "    # Smooth in time direction (axis=1), not frequency (axis=0)\n",
    "    smoothed_coefficients = uniform_filter(np.abs(coefficients), size=(1, 400)) # increased time filter size from 50 to 400\n",
    "    # Add small epsilon (if needed) to avoid log(0)\n",
    "    #epsilon = 1e-10  # Small value to prevent log(0)\n",
    "    #coeffs = (coefficients + epsilon)\n",
    "    \n",
    "    # Plot:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.pcolormesh(time_sec, frequencies, np.log10(smoothed_coefficients), cmap='magma', shading='auto')\n",
    "    plt.colorbar(label='log\\u2081\\u2080(Magnitude)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title(f'Car Off Measurement {i+1} - Full DS Data')\n",
    "    plt.show()\n",
    "\n",
    "    # Try to make histograms ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    magnitudes = np.abs(smoothed_coefficients)\n",
    "    magnitude_values = magnitudes.flatten()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    plt.hist(magnitude_values, bins=50, density = True, facecolor='skyblue', edgecolor='grey')\n",
    "    plt.title(\"Histogram of Scalogram Magnitudes\")\n",
    "    plt.xlabel(\"Magnitude\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    plt.yscale('log')\n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    plt.axvline(x=np.mean(magnitude_values), color='r', linestyle='--', label=f'Mean: {np.mean(magnitude_values): .2e}')\n",
    "    plt.axvline(x=np.median(magnitude_values), color='orange', linestyle='--', label=f'Median: {np.median(magnitude_values): .2e}')\n",
    "    # get mode:\n",
    "    hist_counts, bin_edges = np.histogram(magnitude_values, bins=50)\n",
    "    mode_bin_index = np.argmax(hist_counts)\n",
    "    # Mode is the center of the bin with the highest count:\n",
    "    mode_value = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "    plt.axvline(x=mode_value, color='b', linestyle='--', label=f'Mode: {mode_value: .2e}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # some other stats:\n",
    "    print(ss.describe(magnitude_values))\n",
    "    std_dev = np.std(magnitude_values)\n",
    "    print(f\"Standard Deviation: {std_dev:.4f}\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d510d3-ecb3-4d51-9045-26f5fa293f2f",
   "metadata": {},
   "source": [
    "##### Continuous Wavelet Transform\n",
    "##### Tapered/Subsampled DS Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b9ab6-b766-4d9c-bcb6-1f638e6789a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dframe in enumerate(car_off_dataframes):\n",
    "    mean_shifted_column=f\"Signal{i+1} Zero Mean (m)\"\n",
    "    time_column = f\"Time{i+1} (s)\"\n",
    "    sub_tap_data = sub_tapered(apply_hann_window(dframe, mean_shifted_column), decimation_factor=50)\n",
    "    print(f\"Data shape: {sub_tap_data.shape}\")\n",
    "    time_sec = dframe[time_column][::50].values # use step == decimation_factor \n",
    "    delta_t = time_sec[1] - time_sec[0] # time step in seconds\n",
    "    #print(delta_t)\n",
    "\n",
    "    scale_min = 1.0 / (250 * delta_t)  # Small scale for high freq, use freq_max=250\n",
    "    scale_max = 1.0 / (10 * delta_t)  # Large scale for low freq, use freq_min=10\n",
    "    scales = np.logspace(np.log10(scale_min), np.log10(scale_max), 60) \n",
    "    # Wavelet transform:\n",
    "    coefficients, frequencies = pywt.cwt(sub_tap_data, scales, 'morl', sampling_period=delta_t)\n",
    "    print(f\"Frequency range: {frequencies.min():.2f} to {frequencies.max():.2f} Hz\")\n",
    "    print(f\"Coefficients shape: {coefficients.shape}\")\n",
    "    print(f\"Frequencies shape: {frequencies.shape}\")\n",
    "    print(f\"Time_sec shape: {time_sec.shape}\")\n",
    "    # Smooth in time direction (axis=1), not frequency (axis=0)\n",
    "    smoothed_coefficients = uniform_filter(np.abs(coefficients), size=(1, 50))\n",
    "    # Add small epsilon (if needed) to avoid log(0)\n",
    "    #epsilon = 1e-10  # Small value to prevent log(0)\n",
    "    #coeffs = (coefficients + epsilon)\n",
    "    \n",
    "    # Plot:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.pcolormesh(time_sec, frequencies, np.log10(smoothed_coefficients), cmap='magma', shading='auto')#, vmin=-5)\n",
    "    plt.colorbar(label='log\\u2081\\u2080(Magnitude)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title(f'Car Off Measurement {i+1} - Full DS Data')\n",
    "    plt.show()\n",
    "    \n",
    "    # Try to make histograms ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    magnitudes = np.abs(smoothed_coefficients)\n",
    "    magnitude_values = magnitudes.flatten()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    plt.hist(magnitude_values, bins=50, density = True, facecolor='skyblue', edgecolor='grey')\n",
    "    plt.title(\"Histogram of Scalogram Magnitudes\")\n",
    "    plt.xlabel(\"Magnitude\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    plt.yscale('log')\n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    plt.axvline(x=np.mean(magnitude_values), color='r', linestyle='--', label=f'Mean: {np.mean(magnitude_values): .2e}')\n",
    "    plt.axvline(x=np.median(magnitude_values), color='orange', linestyle='--', label=f'Median: {np.median(magnitude_values): .2e}')\n",
    "    # get mode:\n",
    "    hist_counts, bin_edges = np.histogram(magnitude_values, bins=50)\n",
    "    mode_bin_index = np.argmax(hist_counts)\n",
    "    # Mode is the center of the bin with the highest count:\n",
    "    mode_value = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "    plt.axvline(x=mode_value, color='b', linestyle='--', label=f'Mode: {mode_value: .2e}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # some other stats:\n",
    "    print(ss.describe(magnitude_values))\n",
    "    std_dev = np.std(magnitude_values)\n",
    "    print(f\"Standard Deviation: {std_dev:.4f}\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
